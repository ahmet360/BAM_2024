2024-07-31 08:51:56,100 WARNING  * Debugger is active!
2024-07-31 08:51:56,105 INFO  * Debugger PIN: 116-389-750
2024-07-31 08:55:19,135 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-07-31 08:55:19,136 INFO [33mPress CTRL+C to quit[0m
2024-07-31 08:55:19,138 INFO  * Restarting with stat
2024-07-31 08:55:20,019 WARNING  * Debugger is active!
2024-07-31 08:55:20,025 INFO  * Debugger PIN: 116-389-750
2024-07-31 08:55:25,744 INFO 127.0.0.1 - - [31/Jul/2024 08:55:25] "GET / HTTP/1.1" 200 -
2024-07-31 08:55:31,037 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 08:55:31,102 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 08:55:31,103 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 08:55:31,260 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000233ADC11B90>
2024-07-31 08:55:31,261 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x00000233AD96C5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 08:55:31,380 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000233ADC11B10>
2024-07-31 08:55:31,381 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 08:55:31,382 DEBUG send_request_headers.complete
2024-07-31 08:55:31,383 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 08:55:31,383 DEBUG send_request_body.complete
2024-07-31 08:55:31,384 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 08:55:31,621 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'832'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'29a2f253-e554-410f-b5c8-6f4baccb384d'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'93e8474a-7f9d-4d56-bc39-b2bbcc07ab43'), (b'x-ms-client-request-id', b'29a2f253-e554-410f-b5c8-6f4baccb384d'), (b'azureml-model-session', b'turbo-0613-dc0dcef4'), (b'Date', b'Wed, 31 Jul 2024 12:55:32 GMT')])
2024-07-31 08:55:31,624 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 08:55:31,625 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 08:55:31,626 DEBUG receive_response_body.complete
2024-07-31 08:55:31,627 DEBUG response_closed.started
2024-07-31 08:55:31,628 DEBUG response_closed.complete
2024-07-31 08:55:31,629 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '832', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '29a2f253-e554-410f-b5c8-6f4baccb384d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '93e8474a-7f9d-4d56-bc39-b2bbcc07ab43', 'x-ms-client-request-id': '29a2f253-e554-410f-b5c8-6f4baccb384d', 'azureml-model-session': 'turbo-0613-dc0dcef4', 'date': 'Wed, 31 Jul 2024 12:55:32 GMT'})
2024-07-31 08:55:31,631 DEBUG request_id: 93e8474a-7f9d-4d56-bc39-b2bbcc07ab43
2024-07-31 08:55:31,640 INFO 127.0.0.1 - - [31/Jul/2024 08:55:31] "POST /chat HTTP/1.1" 200 -
2024-07-31 08:55:31,671 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 08:55:32,392 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 08:55:32,395 INFO 127.0.0.1 - - [31/Jul/2024 08:55:32] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 08:58:41,496 INFO 127.0.0.1 - - [31/Jul/2024 08:58:41] "GET / HTTP/1.1" 200 -
2024-07-31 08:58:45,724 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 08:58:45,727 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 08:58:45,728 DEBUG close.started
2024-07-31 08:58:45,730 DEBUG close.complete
2024-07-31 08:58:45,731 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 08:58:45,809 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000233ADC4CFD0>
2024-07-31 08:58:45,809 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x00000233AD96C5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 08:58:45,979 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000233ADC4DD10>
2024-07-31 08:58:45,981 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 08:58:45,981 DEBUG send_request_headers.complete
2024-07-31 08:58:45,982 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 08:58:45,984 DEBUG send_request_body.complete
2024-07-31 08:58:45,984 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 08:58:46,206 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'835'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'158cf252-bcd3-4e40-a46d-099c38071fa7'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'ec6a5355-67b5-47c0-abd5-a57d8f7c87b5'), (b'x-ms-client-request-id', b'158cf252-bcd3-4e40-a46d-099c38071fa7'), (b'azureml-model-session', b'turbo-0613-6c073fe4'), (b'Date', b'Wed, 31 Jul 2024 12:58:46 GMT')])
2024-07-31 08:58:46,208 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 08:58:46,209 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 08:58:46,210 DEBUG receive_response_body.complete
2024-07-31 08:58:46,210 DEBUG response_closed.started
2024-07-31 08:58:46,212 DEBUG response_closed.complete
2024-07-31 08:58:46,212 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '835', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '158cf252-bcd3-4e40-a46d-099c38071fa7', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'ec6a5355-67b5-47c0-abd5-a57d8f7c87b5', 'x-ms-client-request-id': '158cf252-bcd3-4e40-a46d-099c38071fa7', 'azureml-model-session': 'turbo-0613-6c073fe4', 'date': 'Wed, 31 Jul 2024 12:58:46 GMT'})
2024-07-31 08:58:46,214 DEBUG request_id: ec6a5355-67b5-47c0-abd5-a57d8f7c87b5
2024-07-31 08:58:46,215 INFO 127.0.0.1 - - [31/Jul/2024 08:58:46] "POST /chat HTTP/1.1" 200 -
2024-07-31 08:58:46,240 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 08:58:46,733 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 08:58:46,736 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 08:58:46,752 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 08:58:46,755 DEBUG send_request_headers.complete
2024-07-31 08:58:46,756 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 08:58:46,759 DEBUG send_request_body.complete
2024-07-31 08:58:46,760 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 08:58:46,944 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 08:58:46,947 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 08:58:46,949 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 08:58:46,965 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 08:58:46,968 INFO 127.0.0.1 - - [31/Jul/2024 08:58:46] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 08:58:46,974 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'832'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'701bace3-4fb5-4c8d-aa53-207c49177f0c'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'148'), (b'x-ratelimit-remaining-tokens', b'149000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'089fdb1b-88f6-4bc9-9c67-40538d8c810f'), (b'x-ms-client-request-id', b'701bace3-4fb5-4c8d-aa53-207c49177f0c'), (b'azureml-model-session', b'turbo-0613-cf02972a'), (b'Date', b'Wed, 31 Jul 2024 12:58:46 GMT')])
2024-07-31 08:58:46,981 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 08:58:46,981 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 08:58:46,982 DEBUG receive_response_body.complete
2024-07-31 08:58:46,983 DEBUG response_closed.started
2024-07-31 08:58:46,984 DEBUG response_closed.complete
2024-07-31 08:58:46,985 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '832', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '701bace3-4fb5-4c8d-aa53-207c49177f0c', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '148', 'x-ratelimit-remaining-tokens': '149000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '089fdb1b-88f6-4bc9-9c67-40538d8c810f', 'x-ms-client-request-id': '701bace3-4fb5-4c8d-aa53-207c49177f0c', 'azureml-model-session': 'turbo-0613-cf02972a', 'date': 'Wed, 31 Jul 2024 12:58:46 GMT'})
2024-07-31 08:58:46,987 DEBUG request_id: 089fdb1b-88f6-4bc9-9c67-40538d8c810f
2024-07-31 08:58:46,990 INFO 127.0.0.1 - - [31/Jul/2024 08:58:46] "POST /chat HTTP/1.1" 200 -
2024-07-31 08:58:46,992 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000233ADC37CD0>
2024-07-31 08:58:46,993 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x00000233AD96C5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 08:58:47,006 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 08:58:47,113 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 08:58:47,117 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 08:58:47,119 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 08:58:47,123 DEBUG send_request_headers.complete
2024-07-31 08:58:47,124 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 08:58:47,126 DEBUG send_request_body.complete
2024-07-31 08:58:47,127 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 08:58:47,263 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 08:58:47,265 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 08:58:47,266 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 08:58:47,273 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000233ADC37850>
2024-07-31 08:58:47,275 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 08:58:47,276 DEBUG send_request_headers.complete
2024-07-31 08:58:47,277 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 08:58:47,279 DEBUG send_request_body.complete
2024-07-31 08:58:47,280 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 08:58:47,313 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000233ADC70110>
2024-07-31 08:58:47,317 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x00000233AD96C5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 08:58:47,372 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'832'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'6be3b571-0f5d-49ef-9ea9-9baea9d51b0f'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'147'), (b'x-ratelimit-remaining-tokens', b'148500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'c22851de-9f72-45d6-8195-c17cdc3e3b7b'), (b'x-ms-client-request-id', b'6be3b571-0f5d-49ef-9ea9-9baea9d51b0f'), (b'azureml-model-session', b'turbo-0613-f12dda4f'), (b'Date', b'Wed, 31 Jul 2024 12:58:47 GMT')])
2024-07-31 08:58:47,386 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 08:58:47,388 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 08:58:47,389 DEBUG receive_response_body.complete
2024-07-31 08:58:47,392 DEBUG response_closed.started
2024-07-31 08:58:47,394 DEBUG response_closed.complete
2024-07-31 08:58:47,395 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '832', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '6be3b571-0f5d-49ef-9ea9-9baea9d51b0f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '147', 'x-ratelimit-remaining-tokens': '148500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'c22851de-9f72-45d6-8195-c17cdc3e3b7b', 'x-ms-client-request-id': '6be3b571-0f5d-49ef-9ea9-9baea9d51b0f', 'azureml-model-session': 'turbo-0613-f12dda4f', 'date': 'Wed, 31 Jul 2024 12:58:47 GMT'})
2024-07-31 08:58:47,400 DEBUG request_id: c22851de-9f72-45d6-8195-c17cdc3e3b7b
2024-07-31 08:58:47,403 INFO 127.0.0.1 - - [31/Jul/2024 08:58:47] "POST /chat HTTP/1.1" 200 -
2024-07-31 08:58:47,432 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 08:58:47,476 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'832'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'8b2345e0-96dd-442a-958e-a5fe817103fe'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'146'), (b'x-ratelimit-remaining-tokens', b'148000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'1061d15e-bbd9-447f-b5c8-85f733455729'), (b'x-ms-client-request-id', b'8b2345e0-96dd-442a-958e-a5fe817103fe'), (b'azureml-model-session', b'turbo-0613-6c073fe4'), (b'Date', b'Wed, 31 Jul 2024 12:58:47 GMT')])
2024-07-31 08:58:47,479 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 08:58:47,480 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 08:58:47,481 DEBUG receive_response_body.complete
2024-07-31 08:58:47,484 DEBUG response_closed.started
2024-07-31 08:58:47,485 DEBUG response_closed.complete
2024-07-31 08:58:47,488 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '832', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '8b2345e0-96dd-442a-958e-a5fe817103fe', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '146', 'x-ratelimit-remaining-tokens': '148000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '1061d15e-bbd9-447f-b5c8-85f733455729', 'x-ms-client-request-id': '8b2345e0-96dd-442a-958e-a5fe817103fe', 'azureml-model-session': 'turbo-0613-6c073fe4', 'date': 'Wed, 31 Jul 2024 12:58:47 GMT'})
2024-07-31 08:58:47,490 DEBUG request_id: 1061d15e-bbd9-447f-b5c8-85f733455729
2024-07-31 08:58:47,492 INFO 127.0.0.1 - - [31/Jul/2024 08:58:47] "POST /chat HTTP/1.1" 200 -
2024-07-31 08:58:47,529 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 08:58:47,799 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 08:58:47,803 INFO 127.0.0.1 - - [31/Jul/2024 08:58:47] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 08:58:47,813 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000233ADC37910>
2024-07-31 08:58:47,813 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 08:58:47,815 DEBUG send_request_headers.complete
2024-07-31 08:58:47,816 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 08:58:47,817 DEBUG send_request_body.complete
2024-07-31 08:58:47,818 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 08:58:48,163 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'832'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'522426a6-141a-4714-b29f-0675cf806f71'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'145'), (b'x-ratelimit-remaining-tokens', b'147500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'663e47a6-3a61-42fd-8f1a-ecf3284ecd09'), (b'x-ms-client-request-id', b'522426a6-141a-4714-b29f-0675cf806f71'), (b'azureml-model-session', b'turbo-0613-dd218034'), (b'Date', b'Wed, 31 Jul 2024 12:58:48 GMT')])
2024-07-31 08:58:48,163 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 08:58:48,166 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 08:58:48,169 INFO 127.0.0.1 - - [31/Jul/2024 08:58:48] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 08:58:48,169 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 08:58:48,171 DEBUG receive_response_body.complete
2024-07-31 08:58:48,172 DEBUG response_closed.started
2024-07-31 08:58:48,172 DEBUG response_closed.complete
2024-07-31 08:58:48,173 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '832', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '522426a6-141a-4714-b29f-0675cf806f71', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '145', 'x-ratelimit-remaining-tokens': '147500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '663e47a6-3a61-42fd-8f1a-ecf3284ecd09', 'x-ms-client-request-id': '522426a6-141a-4714-b29f-0675cf806f71', 'azureml-model-session': 'turbo-0613-dd218034', 'date': 'Wed, 31 Jul 2024 12:58:48 GMT'})
2024-07-31 08:58:48,174 DEBUG request_id: 663e47a6-3a61-42fd-8f1a-ecf3284ecd09
2024-07-31 08:58:48,175 INFO 127.0.0.1 - - [31/Jul/2024 08:58:48] "POST /chat HTTP/1.1" 200 -
2024-07-31 08:58:48,210 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 08:58:48,416 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 08:58:48,434 INFO 127.0.0.1 - - [31/Jul/2024 08:58:48] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 08:58:49,028 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 08:58:49,031 INFO 127.0.0.1 - - [31/Jul/2024 08:58:49] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 08:58:55,291 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'how is your day'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 08:58:55,294 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 08:58:55,297 DEBUG close.started
2024-07-31 08:58:55,302 DEBUG close.complete
2024-07-31 08:58:55,304 DEBUG close.started
2024-07-31 08:58:55,305 DEBUG close.complete
2024-07-31 08:58:55,307 DEBUG close.started
2024-07-31 08:58:55,313 DEBUG close.complete
2024-07-31 08:58:55,315 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 08:58:55,385 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000233ADC1E890>
2024-07-31 08:58:55,386 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x00000233AD96C5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 08:58:55,508 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000233ADC72450>
2024-07-31 08:58:55,510 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 08:58:55,511 DEBUG send_request_headers.complete
2024-07-31 08:58:55,511 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 08:58:55,512 DEBUG send_request_body.complete
2024-07-31 08:58:55,512 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 08:58:56,455 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'1041'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'9dad73f4-1a3e-4a8e-bab6-f77660fbc63a'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'144'), (b'x-ratelimit-remaining-tokens', b'147000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'68e0dd2a-e772-4cfa-a2c5-e34760e2a1a1'), (b'x-ms-client-request-id', b'9dad73f4-1a3e-4a8e-bab6-f77660fbc63a'), (b'azureml-model-session', b'turbo-0613-ee42533b'), (b'Date', b'Wed, 31 Jul 2024 12:58:56 GMT')])
2024-07-31 08:58:56,457 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 08:58:56,458 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 08:58:56,458 DEBUG receive_response_body.complete
2024-07-31 08:58:56,459 DEBUG response_closed.started
2024-07-31 08:58:56,459 DEBUG response_closed.complete
2024-07-31 08:58:56,460 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '1041', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '9dad73f4-1a3e-4a8e-bab6-f77660fbc63a', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '144', 'x-ratelimit-remaining-tokens': '147000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '68e0dd2a-e772-4cfa-a2c5-e34760e2a1a1', 'x-ms-client-request-id': '9dad73f4-1a3e-4a8e-bab6-f77660fbc63a', 'azureml-model-session': 'turbo-0613-ee42533b', 'date': 'Wed, 31 Jul 2024 12:58:56 GMT'})
2024-07-31 08:58:56,461 DEBUG request_id: 68e0dd2a-e772-4cfa-a2c5-e34760e2a1a1
2024-07-31 08:58:56,463 INFO 127.0.0.1 - - [31/Jul/2024 08:58:56] "POST /chat HTTP/1.1" 200 -
2024-07-31 08:58:56,484 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 08:58:57,155 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 08:58:57,157 INFO 127.0.0.1 - - [31/Jul/2024 08:58:57] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 09:01:00,437 INFO  * Detected change in 'C:\\Users\\ahmtt\\OneDrive\\Documents\\VS\\BAM_HACKATHON_2024\\tts_test.py', reloading
2024-07-31 09:01:00,538 INFO  * Restarting with stat
2024-07-31 09:01:01,481 WARNING  * Debugger is active!
2024-07-31 09:01:01,486 INFO  * Debugger PIN: 116-389-750
2024-07-31 14:35:36,528 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-07-31 14:35:36,528 INFO [33mPress CTRL+C to quit[0m
2024-07-31 14:35:36,532 INFO  * Restarting with stat
2024-07-31 14:35:38,239 WARNING  * Debugger is active!
2024-07-31 14:35:38,246 INFO  * Debugger PIN: 116-389-750
2024-07-31 14:35:43,517 INFO 127.0.0.1 - - [31/Jul/2024 14:35:43] "GET / HTTP/1.1" 200 -
2024-07-31 14:38:13,297 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly and helpful friend. your job is to console and help your friend. sympatize with your friend and give advice to support and help them'}, {'role': 'user', 'content': 'should I go outside today?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 14:38:13,384 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 14:38:13,386 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 14:38:13,532 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEEA39D0>
2024-07-31 14:38:13,535 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B1BEBFC5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 14:38:13,600 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEEA3950>
2024-07-31 14:38:13,602 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 14:38:13,604 DEBUG send_request_headers.complete
2024-07-31 14:38:13,605 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 14:38:13,605 DEBUG send_request_body.complete
2024-07-31 14:38:13,607 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 14:38:15,031 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly and helpful friend. your job is to console and help your friend. sympatize with your friend and give advice to support and help them'}, {'role': 'user', 'content': 'should I go outside today?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 14:38:15,034 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 14:38:15,035 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 14:38:15,051 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEEAB690>
2024-07-31 14:38:15,052 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B1BEBFC5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 14:38:15,087 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEEAB650>
2024-07-31 14:38:15,088 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 14:38:15,090 DEBUG send_request_headers.complete
2024-07-31 14:38:15,091 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 14:38:15,091 DEBUG send_request_body.complete
2024-07-31 14:38:15,092 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 14:38:15,409 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'1909'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'91d2abee-1aa3-47e5-b54a-f025dd9922fc'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'28c430cc-e610-4db4-a019-abe042d4a586'), (b'x-ms-client-request-id', b'91d2abee-1aa3-47e5-b54a-f025dd9922fc'), (b'azureml-model-session', b'turbo-0613-cf02972a'), (b'Date', b'Wed, 31 Jul 2024 18:38:15 GMT')])
2024-07-31 14:38:15,412 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 14:38:15,413 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 14:38:15,414 DEBUG receive_response_body.complete
2024-07-31 14:38:15,414 DEBUG response_closed.started
2024-07-31 14:38:15,415 DEBUG response_closed.complete
2024-07-31 14:38:15,415 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '1909', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '91d2abee-1aa3-47e5-b54a-f025dd9922fc', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '28c430cc-e610-4db4-a019-abe042d4a586', 'x-ms-client-request-id': '91d2abee-1aa3-47e5-b54a-f025dd9922fc', 'azureml-model-session': 'turbo-0613-cf02972a', 'date': 'Wed, 31 Jul 2024 18:38:15 GMT'})
2024-07-31 14:38:15,417 DEBUG request_id: 28c430cc-e610-4db4-a019-abe042d4a586
2024-07-31 14:38:15,430 INFO 127.0.0.1 - - [31/Jul/2024 14:38:15] "POST /chat HTTP/1.1" 200 -
2024-07-31 14:38:15,489 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 14:38:16,228 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 14:38:16,246 INFO 127.0.0.1 - - [31/Jul/2024 14:38:16] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 14:38:17,660 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2312'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'47c5f8b5-4fb4-4c8d-b96c-720ebc54f7db'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'148'), (b'x-ratelimit-remaining-tokens', b'149000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'02a311f9-d72d-4519-a10c-fc9b70b88dc8'), (b'x-ms-client-request-id', b'47c5f8b5-4fb4-4c8d-b96c-720ebc54f7db'), (b'azureml-model-session', b'turbo-0613-65eb5d6c'), (b'Date', b'Wed, 31 Jul 2024 18:38:17 GMT')])
2024-07-31 14:38:17,662 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 14:38:17,663 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 14:38:17,664 DEBUG receive_response_body.complete
2024-07-31 14:38:17,664 DEBUG response_closed.started
2024-07-31 14:38:17,665 DEBUG response_closed.complete
2024-07-31 14:38:17,666 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2312', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '47c5f8b5-4fb4-4c8d-b96c-720ebc54f7db', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '148', 'x-ratelimit-remaining-tokens': '149000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '02a311f9-d72d-4519-a10c-fc9b70b88dc8', 'x-ms-client-request-id': '47c5f8b5-4fb4-4c8d-b96c-720ebc54f7db', 'azureml-model-session': 'turbo-0613-65eb5d6c', 'date': 'Wed, 31 Jul 2024 18:38:17 GMT'})
2024-07-31 14:38:17,667 DEBUG request_id: 02a311f9-d72d-4519-a10c-fc9b70b88dc8
2024-07-31 14:38:17,670 INFO 127.0.0.1 - - [31/Jul/2024 14:38:17] "POST /chat HTTP/1.1" 200 -
2024-07-31 14:38:17,734 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 14:38:18,174 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 14:38:18,177 INFO 127.0.0.1 - - [31/Jul/2024 14:38:18] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 14:38:41,062 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly and helpful friend. your job is to console and help your friend. sympatize with your friend and give advice to support and help them'}, {'role': 'user', 'content': 'why is the sky blue?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 14:38:41,066 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 14:38:41,068 DEBUG close.started
2024-07-31 14:38:41,069 DEBUG close.complete
2024-07-31 14:38:41,070 DEBUG close.started
2024-07-31 14:38:41,071 DEBUG close.complete
2024-07-31 14:38:41,080 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 14:38:41,209 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEECF510>
2024-07-31 14:38:41,211 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B1BEBFC5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 14:38:41,252 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEEE2DD0>
2024-07-31 14:38:41,252 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 14:38:41,253 DEBUG send_request_headers.complete
2024-07-31 14:38:41,254 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 14:38:41,255 DEBUG send_request_body.complete
2024-07-31 14:38:41,255 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 14:38:41,930 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'1094'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'e056b77b-adda-44b3-a2c5-83398cfe397d'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'148500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'9d8c2982-bedf-47be-ba1c-5160f348d8ad'), (b'x-ms-client-request-id', b'e056b77b-adda-44b3-a2c5-83398cfe397d'), (b'azureml-model-session', b'turbo-0613-bab128d8'), (b'Date', b'Wed, 31 Jul 2024 18:38:42 GMT')])
2024-07-31 14:38:41,931 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 14:38:41,932 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 14:38:41,933 DEBUG receive_response_body.complete
2024-07-31 14:38:41,933 DEBUG response_closed.started
2024-07-31 14:38:41,933 DEBUG response_closed.complete
2024-07-31 14:38:41,933 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '1094', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'e056b77b-adda-44b3-a2c5-83398cfe397d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '148500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '9d8c2982-bedf-47be-ba1c-5160f348d8ad', 'x-ms-client-request-id': 'e056b77b-adda-44b3-a2c5-83398cfe397d', 'azureml-model-session': 'turbo-0613-bab128d8', 'date': 'Wed, 31 Jul 2024 18:38:42 GMT'})
2024-07-31 14:38:41,935 DEBUG request_id: 9d8c2982-bedf-47be-ba1c-5160f348d8ad
2024-07-31 14:38:41,937 INFO 127.0.0.1 - - [31/Jul/2024 14:38:41] "POST /chat HTTP/1.1" 200 -
2024-07-31 14:38:41,982 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 14:38:42,586 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 14:38:42,589 INFO 127.0.0.1 - - [31/Jul/2024 14:38:42] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 14:39:06,197 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly and helpful friend. your job is to console and help your friend. sympatize with your friend and give advice to support and help them'}, {'role': 'user', 'content': 'Is technology a good field to work in?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 14:39:06,205 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 14:39:06,207 DEBUG close.started
2024-07-31 14:39:06,220 DEBUG close.complete
2024-07-31 14:39:06,222 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 14:39:06,384 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEEA8590>
2024-07-31 14:39:06,385 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B1BEBFC5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 14:39:06,475 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEEAADD0>
2024-07-31 14:39:06,476 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 14:39:06,477 DEBUG send_request_headers.complete
2024-07-31 14:39:06,478 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 14:39:06,479 DEBUG send_request_body.complete
2024-07-31 14:39:06,480 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 14:39:08,366 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly and helpful friend. your job is to console and help your friend. sympatize with your friend and give advice to support and help them'}, {'role': 'user', 'content': 'Is technology a good field to work in?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 14:39:08,369 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 14:39:08,370 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 14:39:08,390 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEEEE2D0>
2024-07-31 14:39:08,392 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B1BEBFC5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 14:39:08,430 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEEEE290>
2024-07-31 14:39:08,431 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 14:39:08,432 DEBUG send_request_headers.complete
2024-07-31 14:39:08,433 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 14:39:08,434 DEBUG send_request_body.complete
2024-07-31 14:39:08,434 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 14:39:09,968 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'3326'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'a0d41ebf-5b29-4c3d-ac96-29fae78e1a24'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'148000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'b0518aea-fe9a-4f99-a160-f067308c4b8f'), (b'x-ms-client-request-id', b'a0d41ebf-5b29-4c3d-ac96-29fae78e1a24'), (b'azureml-model-session', b'turbo-0613-3425e45b'), (b'Date', b'Wed, 31 Jul 2024 18:39:10 GMT')])
2024-07-31 14:39:09,970 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 14:39:09,972 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 14:39:09,972 DEBUG receive_response_body.complete
2024-07-31 14:39:09,973 DEBUG response_closed.started
2024-07-31 14:39:09,973 DEBUG response_closed.complete
2024-07-31 14:39:09,974 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '3326', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'a0d41ebf-5b29-4c3d-ac96-29fae78e1a24', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '148000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'b0518aea-fe9a-4f99-a160-f067308c4b8f', 'x-ms-client-request-id': 'a0d41ebf-5b29-4c3d-ac96-29fae78e1a24', 'azureml-model-session': 'turbo-0613-3425e45b', 'date': 'Wed, 31 Jul 2024 18:39:10 GMT'})
2024-07-31 14:39:09,978 DEBUG request_id: b0518aea-fe9a-4f99-a160-f067308c4b8f
2024-07-31 14:39:09,981 INFO 127.0.0.1 - - [31/Jul/2024 14:39:09] "POST /chat HTTP/1.1" 200 -
2024-07-31 14:39:10,024 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 14:39:10,705 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 14:39:10,708 INFO 127.0.0.1 - - [31/Jul/2024 14:39:10] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 14:39:11,934 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2421'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'87821657-0b09-4d3b-bab3-6e2ca67515e8'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'148'), (b'x-ratelimit-remaining-tokens', b'147500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'97a3451d-de35-42dc-b615-4924a14dc942'), (b'x-ms-client-request-id', b'87821657-0b09-4d3b-bab3-6e2ca67515e8'), (b'azureml-model-session', b'turbo-0613-65eb5d6c'), (b'Date', b'Wed, 31 Jul 2024 18:39:12 GMT')])
2024-07-31 14:39:11,937 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 14:39:11,937 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 14:39:11,938 DEBUG receive_response_body.complete
2024-07-31 14:39:11,939 DEBUG response_closed.started
2024-07-31 14:39:11,939 DEBUG response_closed.complete
2024-07-31 14:39:11,940 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2421', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '87821657-0b09-4d3b-bab3-6e2ca67515e8', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '148', 'x-ratelimit-remaining-tokens': '147500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '97a3451d-de35-42dc-b615-4924a14dc942', 'x-ms-client-request-id': '87821657-0b09-4d3b-bab3-6e2ca67515e8', 'azureml-model-session': 'turbo-0613-65eb5d6c', 'date': 'Wed, 31 Jul 2024 18:39:12 GMT'})
2024-07-31 14:39:11,942 DEBUG request_id: 97a3451d-de35-42dc-b615-4924a14dc942
2024-07-31 14:39:11,946 INFO 127.0.0.1 - - [31/Jul/2024 14:39:11] "POST /chat HTTP/1.1" 200 -
2024-07-31 14:39:11,991 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 14:39:12,652 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 14:39:12,655 INFO 127.0.0.1 - - [31/Jul/2024 14:39:12] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 14:42:02,001 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly and helpful friend. your job is to console and help your friend. sympatize with your friend and give advice to support and help them'}, {'role': 'user', 'content': 'why is the sky blue'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 14:42:02,005 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 14:42:02,006 DEBUG close.started
2024-07-31 14:42:02,010 DEBUG close.complete
2024-07-31 14:42:02,014 DEBUG close.started
2024-07-31 14:42:02,023 DEBUG close.complete
2024-07-31 14:42:02,024 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 14:42:02,136 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEEF8390>
2024-07-31 14:42:02,137 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B1BEBFC5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 14:42:02,174 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEEF8250>
2024-07-31 14:42:02,175 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 14:42:02,177 DEBUG send_request_headers.complete
2024-07-31 14:42:02,177 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 14:42:02,178 DEBUG send_request_body.complete
2024-07-31 14:42:02,179 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 14:42:02,532 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'861'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'6968a7a9-fdca-4095-82e9-4d2f125bb343'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'0d132f8e-dfab-4bc2-8be6-697b91e16327'), (b'x-ms-client-request-id', b'6968a7a9-fdca-4095-82e9-4d2f125bb343'), (b'azureml-model-session', b'turbo-0613-3e1cc6ec'), (b'Date', b'Wed, 31 Jul 2024 18:42:03 GMT')])
2024-07-31 14:42:02,539 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 14:42:02,540 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 14:42:02,540 DEBUG receive_response_body.complete
2024-07-31 14:42:02,541 DEBUG response_closed.started
2024-07-31 14:42:02,541 DEBUG response_closed.complete
2024-07-31 14:42:02,542 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '861', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '6968a7a9-fdca-4095-82e9-4d2f125bb343', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '0d132f8e-dfab-4bc2-8be6-697b91e16327', 'x-ms-client-request-id': '6968a7a9-fdca-4095-82e9-4d2f125bb343', 'azureml-model-session': 'turbo-0613-3e1cc6ec', 'date': 'Wed, 31 Jul 2024 18:42:03 GMT'})
2024-07-31 14:42:02,543 DEBUG request_id: 0d132f8e-dfab-4bc2-8be6-697b91e16327
2024-07-31 14:42:02,545 INFO 127.0.0.1 - - [31/Jul/2024 14:42:02] "POST /chat HTTP/1.1" 200 -
2024-07-31 14:42:02,599 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 14:42:03,353 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 14:42:03,356 INFO 127.0.0.1 - - [31/Jul/2024 14:42:03] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 14:42:13,849 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly and helpful friend. your job is to console and help your friend. sympatize with your friend and give advice to support and help them'}, {'role': 'user', 'content': 'why is the sky blue?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 14:42:13,856 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 14:42:13,860 DEBUG close.started
2024-07-31 14:42:13,875 DEBUG close.complete
2024-07-31 14:42:13,917 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 14:42:14,008 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEEFB850>
2024-07-31 14:42:14,009 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B1BEBFC5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 14:42:14,048 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEEFC350>
2024-07-31 14:42:14,050 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 14:42:14,052 DEBUG send_request_headers.complete
2024-07-31 14:42:14,053 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 14:42:14,054 DEBUG send_request_body.complete
2024-07-31 14:42:14,055 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 14:42:14,708 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly and helpful friend. your job is to console and help your friend. sympatize with your friend and give advice to support and help them'}, {'role': 'user', 'content': 'why is the sky blue?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 14:42:14,711 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 14:42:14,713 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 14:42:14,731 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEEEEC50>
2024-07-31 14:42:14,732 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B1BEBFC5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 14:42:14,774 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEEEF990>
2024-07-31 14:42:14,784 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 14:42:14,786 DEBUG send_request_headers.complete
2024-07-31 14:42:14,787 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 14:42:14,788 DEBUG send_request_body.complete
2024-07-31 14:42:14,788 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 14:42:14,866 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly and helpful friend. your job is to console and help your friend. sympatize with your friend and give advice to support and help them'}, {'role': 'user', 'content': 'why is the sky blue?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 14:42:14,871 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 14:42:14,873 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 14:42:14,891 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEEFF390>
2024-07-31 14:42:14,892 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B1BEBFC5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 14:42:14,939 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEEFF350>
2024-07-31 14:42:14,940 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 14:42:14,941 DEBUG send_request_headers.complete
2024-07-31 14:42:14,942 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 14:42:14,943 DEBUG send_request_body.complete
2024-07-31 14:42:14,944 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 14:42:15,024 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'1521'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'b8767e16-1d6f-4744-8151-733d633ca4e4'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'633bf7cc-9d98-45cf-8f09-a83513488770'), (b'x-ms-client-request-id', b'b8767e16-1d6f-4744-8151-733d633ca4e4'), (b'azureml-model-session', b'turbo-0613-5769ba89'), (b'Date', b'Wed, 31 Jul 2024 18:42:15 GMT')])
2024-07-31 14:42:15,026 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 14:42:15,027 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 14:42:15,028 DEBUG receive_response_body.complete
2024-07-31 14:42:15,029 DEBUG response_closed.started
2024-07-31 14:42:15,029 DEBUG response_closed.complete
2024-07-31 14:42:15,030 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '1521', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'b8767e16-1d6f-4744-8151-733d633ca4e4', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '633bf7cc-9d98-45cf-8f09-a83513488770', 'x-ms-client-request-id': 'b8767e16-1d6f-4744-8151-733d633ca4e4', 'azureml-model-session': 'turbo-0613-5769ba89', 'date': 'Wed, 31 Jul 2024 18:42:15 GMT'})
2024-07-31 14:42:15,032 DEBUG request_id: 633bf7cc-9d98-45cf-8f09-a83513488770
2024-07-31 14:42:15,034 INFO 127.0.0.1 - - [31/Jul/2024 14:42:15] "POST /chat HTTP/1.1" 200 -
2024-07-31 14:42:15,065 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 14:42:15,538 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'1114'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'11ca825b-57ca-4d91-926b-6c13827a4f41'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'147'), (b'x-ratelimit-remaining-tokens', b'148000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'ee8862b3-85e8-4b1d-b033-6c3820705b0a'), (b'x-ms-client-request-id', b'11ca825b-57ca-4d91-926b-6c13827a4f41'), (b'azureml-model-session', b'turbo-0613-cb41a0f1'), (b'Date', b'Wed, 31 Jul 2024 18:42:15 GMT')])
2024-07-31 14:42:15,541 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 14:42:15,542 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 14:42:15,543 DEBUG receive_response_body.complete
2024-07-31 14:42:15,544 DEBUG response_closed.started
2024-07-31 14:42:15,545 DEBUG response_closed.complete
2024-07-31 14:42:15,546 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '1114', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '11ca825b-57ca-4d91-926b-6c13827a4f41', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '147', 'x-ratelimit-remaining-tokens': '148000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'ee8862b3-85e8-4b1d-b033-6c3820705b0a', 'x-ms-client-request-id': '11ca825b-57ca-4d91-926b-6c13827a4f41', 'azureml-model-session': 'turbo-0613-cb41a0f1', 'date': 'Wed, 31 Jul 2024 18:42:15 GMT'})
2024-07-31 14:42:15,548 DEBUG request_id: ee8862b3-85e8-4b1d-b033-6c3820705b0a
2024-07-31 14:42:15,551 INFO 127.0.0.1 - - [31/Jul/2024 14:42:15] "POST /chat HTTP/1.1" 200 -
2024-07-31 14:42:15,665 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 14:42:15,665 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 14:42:15,669 INFO 127.0.0.1 - - [31/Jul/2024 14:42:15] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 14:42:15,718 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly and helpful friend. your job is to console and help your friend. sympatize with your friend and give advice to support and help them'}, {'role': 'user', 'content': 'why is the sky blue?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 14:42:15,722 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 14:42:15,724 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 14:42:15,725 DEBUG send_request_headers.complete
2024-07-31 14:42:15,727 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 14:42:15,729 DEBUG send_request_body.complete
2024-07-31 14:42:15,731 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 14:42:16,257 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'1853'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'8dcdb94e-631e-420f-901b-9c4f52ca621a'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'148'), (b'x-ratelimit-remaining-tokens', b'148500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'b29ea555-95c4-468e-a185-13232a10a424'), (b'x-ms-client-request-id', b'8dcdb94e-631e-420f-901b-9c4f52ca621a'), (b'azureml-model-session', b'turbo-0613-dc0dcef4'), (b'Date', b'Wed, 31 Jul 2024 18:42:16 GMT')])
2024-07-31 14:42:16,259 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 14:42:16,260 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 14:42:16,260 DEBUG receive_response_body.complete
2024-07-31 14:42:16,261 DEBUG response_closed.started
2024-07-31 14:42:16,261 DEBUG response_closed.complete
2024-07-31 14:42:16,262 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '1853', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '8dcdb94e-631e-420f-901b-9c4f52ca621a', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '148', 'x-ratelimit-remaining-tokens': '148500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'b29ea555-95c4-468e-a185-13232a10a424', 'x-ms-client-request-id': '8dcdb94e-631e-420f-901b-9c4f52ca621a', 'azureml-model-session': 'turbo-0613-dc0dcef4', 'date': 'Wed, 31 Jul 2024 18:42:16 GMT'})
2024-07-31 14:42:16,264 DEBUG request_id: b29ea555-95c4-468e-a185-13232a10a424
2024-07-31 14:42:16,266 INFO 127.0.0.1 - - [31/Jul/2024 14:42:16] "POST /chat HTTP/1.1" 200 -
2024-07-31 14:42:16,281 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 14:42:16,287 INFO 127.0.0.1 - - [31/Jul/2024 14:42:16] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 14:42:16,328 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 14:42:17,005 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 14:42:17,007 INFO 127.0.0.1 - - [31/Jul/2024 14:42:17] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 14:42:17,688 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'1725'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'4ffb8b1a-fd0f-4235-b77b-162a482bd474'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'146'), (b'x-ratelimit-remaining-tokens', b'147500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'6e51418b-f1f9-4e9f-a3ea-af4f1df94d27'), (b'x-ms-client-request-id', b'4ffb8b1a-fd0f-4235-b77b-162a482bd474'), (b'azureml-model-session', b'turbo-0613-65eb5d6c'), (b'Date', b'Wed, 31 Jul 2024 18:42:17 GMT')])
2024-07-31 14:42:17,691 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 14:42:17,692 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 14:42:17,693 DEBUG receive_response_body.complete
2024-07-31 14:42:17,693 DEBUG response_closed.started
2024-07-31 14:42:17,694 DEBUG response_closed.complete
2024-07-31 14:42:17,695 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '1725', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '4ffb8b1a-fd0f-4235-b77b-162a482bd474', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '146', 'x-ratelimit-remaining-tokens': '147500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '6e51418b-f1f9-4e9f-a3ea-af4f1df94d27', 'x-ms-client-request-id': '4ffb8b1a-fd0f-4235-b77b-162a482bd474', 'azureml-model-session': 'turbo-0613-65eb5d6c', 'date': 'Wed, 31 Jul 2024 18:42:17 GMT'})
2024-07-31 14:42:17,696 DEBUG request_id: 6e51418b-f1f9-4e9f-a3ea-af4f1df94d27
2024-07-31 14:42:17,698 INFO 127.0.0.1 - - [31/Jul/2024 14:42:17] "POST /chat HTTP/1.1" 200 -
2024-07-31 14:42:17,751 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 14:42:18,407 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 14:42:18,409 INFO 127.0.0.1 - - [31/Jul/2024 14:42:18] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 14:42:34,006 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly and helpful friend. your job is to console and help your friend. sympatize with your friend and give advice to support and help them'}, {'role': 'user', 'content': 'why is the sky blue?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 14:42:34,010 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 14:42:34,012 DEBUG close.started
2024-07-31 14:42:34,028 DEBUG close.complete
2024-07-31 14:42:34,029 DEBUG close.started
2024-07-31 14:42:34,031 DEBUG close.complete
2024-07-31 14:42:34,032 DEBUG close.started
2024-07-31 14:42:34,039 DEBUG close.complete
2024-07-31 14:42:34,059 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 14:42:34,177 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEF18250>
2024-07-31 14:42:34,178 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B1BEBFC5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 14:42:34,215 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEF181D0>
2024-07-31 14:42:34,216 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 14:42:34,217 DEBUG send_request_headers.complete
2024-07-31 14:42:34,218 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 14:42:34,219 DEBUG send_request_body.complete
2024-07-31 14:42:34,219 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 14:42:35,139 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly and helpful friend. your job is to console and help your friend. sympatize with your friend and give advice to support and help them'}, {'role': 'user', 'content': 'why is the sky blue?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 14:42:35,143 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 14:42:35,145 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 14:42:35,168 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEEFEC50>
2024-07-31 14:42:35,171 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B1BEBFC5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 14:42:35,212 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEECCF10>
2024-07-31 14:42:35,214 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 14:42:35,215 DEBUG send_request_headers.complete
2024-07-31 14:42:35,216 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 14:42:35,216 DEBUG send_request_body.complete
2024-07-31 14:42:35,218 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 14:42:35,772 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly and helpful friend. your job is to console and help your friend. sympatize with your friend and give advice to support and help them'}, {'role': 'user', 'content': 'why is the sky blue?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 14:42:35,776 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 14:42:35,793 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 14:42:35,812 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEEEF110>
2024-07-31 14:42:35,814 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B1BEBFC5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 14:42:35,850 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEEEF350>
2024-07-31 14:42:35,851 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 14:42:35,852 DEBUG send_request_headers.complete
2024-07-31 14:42:35,853 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 14:42:35,854 DEBUG send_request_body.complete
2024-07-31 14:42:35,854 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 14:42:35,972 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly and helpful friend. your job is to console and help your friend. sympatize with your friend and give advice to support and help them'}, {'role': 'user', 'content': 'why is the sky blue?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 14:42:35,975 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 14:42:35,977 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 14:42:36,009 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEF233D0>
2024-07-31 14:42:36,014 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B1BEBFC5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 14:42:36,025 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'1067'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'3de6ca75-155d-4a45-911d-f725234b0ea3'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'148'), (b'x-ratelimit-remaining-tokens', b'146500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'8db99c67-827a-48b4-8125-69a39235ac25'), (b'x-ms-client-request-id', b'3de6ca75-155d-4a45-911d-f725234b0ea3'), (b'azureml-model-session', b'turbo-0613-6c073fe4'), (b'Date', b'Wed, 31 Jul 2024 18:42:35 GMT')])
2024-07-31 14:42:36,043 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 14:42:36,045 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 14:42:36,047 DEBUG receive_response_body.complete
2024-07-31 14:42:36,048 DEBUG response_closed.started
2024-07-31 14:42:36,050 DEBUG response_closed.complete
2024-07-31 14:42:36,054 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '1067', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '3de6ca75-155d-4a45-911d-f725234b0ea3', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '148', 'x-ratelimit-remaining-tokens': '146500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '8db99c67-827a-48b4-8125-69a39235ac25', 'x-ms-client-request-id': '3de6ca75-155d-4a45-911d-f725234b0ea3', 'azureml-model-session': 'turbo-0613-6c073fe4', 'date': 'Wed, 31 Jul 2024 18:42:35 GMT'})
2024-07-31 14:42:36,056 DEBUG request_id: 8db99c67-827a-48b4-8125-69a39235ac25
2024-07-31 14:42:36,058 INFO 127.0.0.1 - - [31/Jul/2024 14:42:36] "POST /chat HTTP/1.1" 200 -
2024-07-31 14:42:36,059 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEF23390>
2024-07-31 14:42:36,059 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 14:42:36,061 DEBUG send_request_headers.complete
2024-07-31 14:42:36,061 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 14:42:36,065 DEBUG send_request_body.complete
2024-07-31 14:42:36,071 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 14:42:36,158 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly and helpful friend. your job is to console and help your friend. sympatize with your friend and give advice to support and help them'}, {'role': 'user', 'content': 'why is the sky blue?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 14:42:36,162 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 14:42:36,170 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 14:42:36,176 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 14:42:36,178 DEBUG send_request_headers.complete
2024-07-31 14:42:36,178 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 14:42:36,180 DEBUG send_request_body.complete
2024-07-31 14:42:36,180 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 14:42:36,261 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly and helpful friend. your job is to console and help your friend. sympatize with your friend and give advice to support and help them'}, {'role': 'user', 'content': 'why is the sky blue?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 14:42:36,264 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 14:42:36,267 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 14:42:36,285 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEEA2410>
2024-07-31 14:42:36,286 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B1BEBFC5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 14:42:36,329 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEEA2450>
2024-07-31 14:42:36,385 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 14:42:36,389 DEBUG send_request_headers.complete
2024-07-31 14:42:36,390 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 14:42:36,394 DEBUG send_request_body.complete
2024-07-31 14:42:36,394 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 14:42:37,145 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 14:42:37,148 INFO 127.0.0.1 - - [31/Jul/2024 14:42:37] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 14:42:37,233 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'1685'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'2d90a716-e478-431f-8bf7-ec8b40fbb889'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'147000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'ee3c431b-e7be-4616-b6f8-d06c2903fd30'), (b'x-ms-client-request-id', b'2d90a716-e478-431f-8bf7-ec8b40fbb889'), (b'azureml-model-session', b'turbo-0613-bab128d8'), (b'Date', b'Wed, 31 Jul 2024 18:42:37 GMT')])
2024-07-31 14:42:37,235 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 14:42:37,236 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 14:42:37,237 DEBUG receive_response_body.complete
2024-07-31 14:42:37,237 DEBUG response_closed.started
2024-07-31 14:42:37,238 DEBUG response_closed.complete
2024-07-31 14:42:37,238 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '1685', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '2d90a716-e478-431f-8bf7-ec8b40fbb889', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '147000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'ee3c431b-e7be-4616-b6f8-d06c2903fd30', 'x-ms-client-request-id': '2d90a716-e478-431f-8bf7-ec8b40fbb889', 'azureml-model-session': 'turbo-0613-bab128d8', 'date': 'Wed, 31 Jul 2024 18:42:37 GMT'})
2024-07-31 14:42:37,241 DEBUG request_id: ee3c431b-e7be-4616-b6f8-d06c2903fd30
2024-07-31 14:42:37,243 INFO 127.0.0.1 - - [31/Jul/2024 14:42:37] "POST /chat HTTP/1.1" 200 -
2024-07-31 14:42:37,272 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 14:42:37,553 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'1657'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'007f0b73-4405-4f73-b388-1b0c682e8516'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'147'), (b'x-ratelimit-remaining-tokens', b'146000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'b1700952-0fb7-42a2-96ad-1179582a1f99'), (b'x-ms-client-request-id', b'007f0b73-4405-4f73-b388-1b0c682e8516'), (b'azureml-model-session', b'turbo-0613-bab128d8'), (b'Date', b'Wed, 31 Jul 2024 18:42:37 GMT')])
2024-07-31 14:42:37,555 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'1450'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'9d2a872b-1af9-4989-8e1d-5f30ce4a2b41'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'144'), (b'x-ratelimit-remaining-tokens', b'144500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'0b9d2254-55aa-488f-9c58-f17aeaad2254'), (b'x-ms-client-request-id', b'9d2a872b-1af9-4989-8e1d-5f30ce4a2b41'), (b'azureml-model-session', b'turbo-0613-5769ba89'), (b'Date', b'Wed, 31 Jul 2024 18:42:37 GMT')])
2024-07-31 14:42:37,557 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 14:42:37,560 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 14:42:37,560 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 14:42:37,562 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 14:42:37,567 DEBUG receive_response_body.complete
2024-07-31 14:42:37,568 DEBUG receive_response_body.complete
2024-07-31 14:42:37,569 DEBUG response_closed.started
2024-07-31 14:42:37,569 DEBUG response_closed.started
2024-07-31 14:42:37,570 DEBUG response_closed.complete
2024-07-31 14:42:37,571 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '1657', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '007f0b73-4405-4f73-b388-1b0c682e8516', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '147', 'x-ratelimit-remaining-tokens': '146000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'b1700952-0fb7-42a2-96ad-1179582a1f99', 'x-ms-client-request-id': '007f0b73-4405-4f73-b388-1b0c682e8516', 'azureml-model-session': 'turbo-0613-bab128d8', 'date': 'Wed, 31 Jul 2024 18:42:37 GMT'})
2024-07-31 14:42:37,572 DEBUG request_id: b1700952-0fb7-42a2-96ad-1179582a1f99
2024-07-31 14:42:37,573 DEBUG response_closed.complete
2024-07-31 14:42:37,575 INFO 127.0.0.1 - - [31/Jul/2024 14:42:37] "POST /chat HTTP/1.1" 200 -
2024-07-31 14:42:37,576 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '1450', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '9d2a872b-1af9-4989-8e1d-5f30ce4a2b41', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '144', 'x-ratelimit-remaining-tokens': '144500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '0b9d2254-55aa-488f-9c58-f17aeaad2254', 'x-ms-client-request-id': '9d2a872b-1af9-4989-8e1d-5f30ce4a2b41', 'azureml-model-session': 'turbo-0613-5769ba89', 'date': 'Wed, 31 Jul 2024 18:42:37 GMT'})
2024-07-31 14:42:37,591 DEBUG request_id: 0b9d2254-55aa-488f-9c58-f17aeaad2254
2024-07-31 14:42:37,622 INFO 127.0.0.1 - - [31/Jul/2024 14:42:37] "POST /chat HTTP/1.1" 200 -
2024-07-31 14:42:37,640 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 14:42:37,645 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 14:42:37,721 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'1510'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'3ef89477-b240-43a3-ab07-14d93fabcf96'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'146'), (b'x-ratelimit-remaining-tokens', b'145500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'14e8ad2d-e91f-4d43-bf10-60fbaa58b127'), (b'x-ms-client-request-id', b'3ef89477-b240-43a3-ab07-14d93fabcf96'), (b'azureml-model-session', b'turbo-0613-144e2f97'), (b'Date', b'Wed, 31 Jul 2024 18:42:37 GMT')])
2024-07-31 14:42:37,726 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 14:42:37,727 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 14:42:37,727 DEBUG receive_response_body.complete
2024-07-31 14:42:37,728 DEBUG response_closed.started
2024-07-31 14:42:37,729 DEBUG response_closed.complete
2024-07-31 14:42:37,730 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '1510', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '3ef89477-b240-43a3-ab07-14d93fabcf96', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '146', 'x-ratelimit-remaining-tokens': '145500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '14e8ad2d-e91f-4d43-bf10-60fbaa58b127', 'x-ms-client-request-id': '3ef89477-b240-43a3-ab07-14d93fabcf96', 'azureml-model-session': 'turbo-0613-144e2f97', 'date': 'Wed, 31 Jul 2024 18:42:37 GMT'})
2024-07-31 14:42:37,731 DEBUG request_id: 14e8ad2d-e91f-4d43-bf10-60fbaa58b127
2024-07-31 14:42:37,733 INFO 127.0.0.1 - - [31/Jul/2024 14:42:37] "POST /chat HTTP/1.1" 200 -
2024-07-31 14:42:37,751 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 14:42:37,886 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 14:42:37,889 INFO 127.0.0.1 - - [31/Jul/2024 14:42:37] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 14:42:38,010 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'1825'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'df4708cc-79eb-4c70-ae6d-6672c66f36a6'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'145'), (b'x-ratelimit-remaining-tokens', b'145000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'4894392f-4282-4b4a-85ea-c35e63effe75'), (b'x-ms-client-request-id', b'df4708cc-79eb-4c70-ae6d-6672c66f36a6'), (b'azureml-model-session', b'turbo-0613-cb41a0f1'), (b'Date', b'Wed, 31 Jul 2024 18:42:38 GMT')])
2024-07-31 14:42:38,012 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 14:42:38,013 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 14:42:38,014 DEBUG receive_response_body.complete
2024-07-31 14:42:38,015 DEBUG response_closed.started
2024-07-31 14:42:38,015 DEBUG response_closed.complete
2024-07-31 14:42:38,016 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '1825', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'df4708cc-79eb-4c70-ae6d-6672c66f36a6', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '145', 'x-ratelimit-remaining-tokens': '145000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '4894392f-4282-4b4a-85ea-c35e63effe75', 'x-ms-client-request-id': 'df4708cc-79eb-4c70-ae6d-6672c66f36a6', 'azureml-model-session': 'turbo-0613-cb41a0f1', 'date': 'Wed, 31 Jul 2024 18:42:38 GMT'})
2024-07-31 14:42:38,018 DEBUG request_id: 4894392f-4282-4b4a-85ea-c35e63effe75
2024-07-31 14:42:38,020 INFO 127.0.0.1 - - [31/Jul/2024 14:42:38] "POST /chat HTTP/1.1" 200 -
2024-07-31 14:42:38,045 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 14:42:38,228 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 14:42:38,230 INFO 127.0.0.1 - - [31/Jul/2024 14:42:38] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 14:42:38,253 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 14:42:38,263 INFO 127.0.0.1 - - [31/Jul/2024 14:42:38] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 14:42:38,334 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 14:42:38,337 INFO 127.0.0.1 - - [31/Jul/2024 14:42:38] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 14:42:38,681 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 14:42:38,685 INFO 127.0.0.1 - - [31/Jul/2024 14:42:38] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 14:42:44,285 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly and helpful friend. your job is to console and help your friend. sympatize with your friend and give advice to support and help them'}, {'role': 'user', 'content': ''}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 14:42:44,288 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 14:42:44,290 DEBUG close.started
2024-07-31 14:42:44,292 DEBUG close.complete
2024-07-31 14:42:44,293 DEBUG close.started
2024-07-31 14:42:44,294 DEBUG close.complete
2024-07-31 14:42:44,295 DEBUG close.started
2024-07-31 14:42:44,299 DEBUG close.complete
2024-07-31 14:42:44,302 DEBUG close.started
2024-07-31 14:42:44,310 DEBUG close.complete
2024-07-31 14:42:44,312 DEBUG close.started
2024-07-31 14:42:44,323 DEBUG close.complete
2024-07-31 14:42:44,329 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 14:42:44,429 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEF0B890>
2024-07-31 14:42:44,431 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B1BEBFC5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 14:42:44,479 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEF09410>
2024-07-31 14:42:44,480 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 14:42:44,481 DEBUG send_request_headers.complete
2024-07-31 14:42:44,482 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 14:42:44,483 DEBUG send_request_body.complete
2024-07-31 14:42:44,483 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 14:42:44,723 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly and helpful friend. your job is to console and help your friend. sympatize with your friend and give advice to support and help them'}, {'role': 'user', 'content': ''}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 14:42:44,726 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 14:42:44,728 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 14:42:44,835 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEF2C590>
2024-07-31 14:42:44,837 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B1BEBFC5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 14:42:44,886 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEF27AD0>
2024-07-31 14:42:44,889 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 14:42:44,892 DEBUG send_request_headers.complete
2024-07-31 14:42:44,893 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 14:42:45,014 DEBUG send_request_body.complete
2024-07-31 14:42:45,043 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 14:42:45,048 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly and helpful friend. your job is to console and help your friend. sympatize with your friend and give advice to support and help them'}, {'role': 'user', 'content': ''}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 14:42:45,052 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 14:42:45,073 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 14:42:45,087 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly and helpful friend. your job is to console and help your friend. sympatize with your friend and give advice to support and help them'}, {'role': 'user', 'content': ''}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 14:42:45,092 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 14:42:45,094 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 14:42:45,105 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEF20DD0>
2024-07-31 14:42:45,107 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B1BEBFC5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 14:42:45,108 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEF23010>
2024-07-31 14:42:45,110 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B1BEBFC5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 14:42:45,147 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEF21850>
2024-07-31 14:42:45,149 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 14:42:45,154 DEBUG send_request_headers.complete
2024-07-31 14:42:45,162 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEF1BF10>
2024-07-31 14:42:45,206 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 14:42:45,208 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 14:42:45,219 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly and helpful friend. your job is to console and help your friend. sympatize with your friend and give advice to support and help them'}, {'role': 'user', 'content': ''}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 14:42:45,221 DEBUG send_request_body.complete
2024-07-31 14:42:45,223 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 14:42:45,223 DEBUG send_request_headers.complete
2024-07-31 14:42:45,225 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 14:42:45,227 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 14:42:45,229 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 14:42:45,231 DEBUG send_request_body.complete
2024-07-31 14:42:45,234 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 14:42:45,245 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEF2F650>
2024-07-31 14:42:45,245 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B1BEBFC5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 14:42:45,287 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEF2F610>
2024-07-31 14:42:45,289 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 14:42:45,290 DEBUG send_request_headers.complete
2024-07-31 14:42:45,291 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 14:42:45,292 DEBUG send_request_body.complete
2024-07-31 14:42:45,292 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 14:42:47,520 INFO 127.0.0.1 - - [31/Jul/2024 14:42:47] "GET / HTTP/1.1" 200 -
2024-07-31 14:42:47,610 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2349'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'97ee2849-6ee7-45a9-a229-0b4195c2dec7'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'143'), (b'x-ratelimit-remaining-tokens', b'143500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'3bc49ab0-f7c3-4df6-89de-9b9c1051ae50'), (b'x-ms-client-request-id', b'97ee2849-6ee7-45a9-a229-0b4195c2dec7'), (b'azureml-model-session', b'turbo-0613-5769ba89'), (b'Date', b'Wed, 31 Jul 2024 18:42:47 GMT')])
2024-07-31 14:42:47,614 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 14:42:47,615 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 14:42:47,615 DEBUG receive_response_body.complete
2024-07-31 14:42:47,616 DEBUG response_closed.started
2024-07-31 14:42:47,617 DEBUG response_closed.complete
2024-07-31 14:42:47,617 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2349', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '97ee2849-6ee7-45a9-a229-0b4195c2dec7', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '143', 'x-ratelimit-remaining-tokens': '143500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '3bc49ab0-f7c3-4df6-89de-9b9c1051ae50', 'x-ms-client-request-id': '97ee2849-6ee7-45a9-a229-0b4195c2dec7', 'azureml-model-session': 'turbo-0613-5769ba89', 'date': 'Wed, 31 Jul 2024 18:42:47 GMT'})
2024-07-31 14:42:47,620 DEBUG request_id: 3bc49ab0-f7c3-4df6-89de-9b9c1051ae50
2024-07-31 14:42:47,622 INFO 127.0.0.1 - - [31/Jul/2024 14:42:47] "POST /chat HTTP/1.1" 200 -
2024-07-31 14:42:47,653 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2438'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'f11a6863-a49f-4a93-a878-dc5c4e2d1913'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'142'), (b'x-ratelimit-remaining-tokens', b'143000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'6f0debeb-fabf-4870-8d32-15b50cd941b2'), (b'x-ms-client-request-id', b'f11a6863-a49f-4a93-a878-dc5c4e2d1913'), (b'azureml-model-session', b'turbo-0613-ee42533b'), (b'Date', b'Wed, 31 Jul 2024 18:42:47 GMT')])
2024-07-31 14:42:47,657 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 14:42:47,658 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 14:42:47,660 DEBUG receive_response_body.complete
2024-07-31 14:42:47,661 DEBUG response_closed.started
2024-07-31 14:42:47,662 DEBUG response_closed.complete
2024-07-31 14:42:47,664 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2438', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'f11a6863-a49f-4a93-a878-dc5c4e2d1913', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '142', 'x-ratelimit-remaining-tokens': '143000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '6f0debeb-fabf-4870-8d32-15b50cd941b2', 'x-ms-client-request-id': 'f11a6863-a49f-4a93-a878-dc5c4e2d1913', 'azureml-model-session': 'turbo-0613-ee42533b', 'date': 'Wed, 31 Jul 2024 18:42:47 GMT'})
2024-07-31 14:42:47,666 DEBUG request_id: 6f0debeb-fabf-4870-8d32-15b50cd941b2
2024-07-31 14:42:47,667 INFO 127.0.0.1 - - [31/Jul/2024 14:42:47] "POST /chat HTTP/1.1" 200 -
2024-07-31 14:42:48,611 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2518'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'4494886d-f618-43bb-9fd2-475f847b0598'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'144'), (b'x-ratelimit-remaining-tokens', b'144000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'30487b5d-1767-44d8-a853-d5357620b8f3'), (b'x-ms-client-request-id', b'4494886d-f618-43bb-9fd2-475f847b0598'), (b'azureml-model-session', b'turbo-0613-65eb5d6c'), (b'Date', b'Wed, 31 Jul 2024 18:42:49 GMT')])
2024-07-31 14:42:48,613 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 14:42:48,614 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 14:42:48,614 DEBUG receive_response_body.complete
2024-07-31 14:42:48,615 DEBUG response_closed.started
2024-07-31 14:42:48,615 DEBUG response_closed.complete
2024-07-31 14:42:48,615 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2518', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '4494886d-f618-43bb-9fd2-475f847b0598', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '144', 'x-ratelimit-remaining-tokens': '144000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '30487b5d-1767-44d8-a853-d5357620b8f3', 'x-ms-client-request-id': '4494886d-f618-43bb-9fd2-475f847b0598', 'azureml-model-session': 'turbo-0613-65eb5d6c', 'date': 'Wed, 31 Jul 2024 18:42:49 GMT'})
2024-07-31 14:42:48,617 DEBUG request_id: 30487b5d-1767-44d8-a853-d5357620b8f3
2024-07-31 14:42:48,620 INFO 127.0.0.1 - - [31/Jul/2024 14:42:48] "POST /chat HTTP/1.1" 200 -
2024-07-31 14:42:48,647 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2572'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'03f765c3-7123-4539-8626-c44e6a511acb'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'142'), (b'x-ratelimit-remaining-tokens', b'143000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'074a1079-b068-45aa-ae1e-44031a363c79'), (b'x-ms-client-request-id', b'03f765c3-7123-4539-8626-c44e6a511acb'), (b'azureml-model-session', b'turbo-0613-65eb5d6c'), (b'Date', b'Wed, 31 Jul 2024 18:42:49 GMT')])
2024-07-31 14:42:48,649 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 14:42:48,649 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 14:42:48,650 DEBUG receive_response_body.complete
2024-07-31 14:42:48,650 DEBUG response_closed.started
2024-07-31 14:42:48,651 DEBUG response_closed.complete
2024-07-31 14:42:48,652 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2572', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '03f765c3-7123-4539-8626-c44e6a511acb', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '142', 'x-ratelimit-remaining-tokens': '143000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '074a1079-b068-45aa-ae1e-44031a363c79', 'x-ms-client-request-id': '03f765c3-7123-4539-8626-c44e6a511acb', 'azureml-model-session': 'turbo-0613-65eb5d6c', 'date': 'Wed, 31 Jul 2024 18:42:49 GMT'})
2024-07-31 14:42:48,653 DEBUG request_id: 074a1079-b068-45aa-ae1e-44031a363c79
2024-07-31 14:42:48,655 INFO 127.0.0.1 - - [31/Jul/2024 14:42:48] "POST /chat HTTP/1.1" 200 -
2024-07-31 14:42:49,432 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2578'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'ba2b8a85-0653-4cd0-8328-dfcffa29bdd0'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'142'), (b'x-ratelimit-remaining-tokens', b'142500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'87d5429f-601d-4191-82ff-70486b1c86a7'), (b'x-ms-client-request-id', b'ba2b8a85-0653-4cd0-8328-dfcffa29bdd0'), (b'azureml-model-session', b'turbo-0613-c0223652'), (b'Date', b'Wed, 31 Jul 2024 18:42:50 GMT')])
2024-07-31 14:42:49,434 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 14:42:49,435 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 14:42:49,436 DEBUG receive_response_body.complete
2024-07-31 14:42:49,436 DEBUG response_closed.started
2024-07-31 14:42:49,437 DEBUG response_closed.complete
2024-07-31 14:42:49,438 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2578', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'ba2b8a85-0653-4cd0-8328-dfcffa29bdd0', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '142', 'x-ratelimit-remaining-tokens': '142500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '87d5429f-601d-4191-82ff-70486b1c86a7', 'x-ms-client-request-id': 'ba2b8a85-0653-4cd0-8328-dfcffa29bdd0', 'azureml-model-session': 'turbo-0613-c0223652', 'date': 'Wed, 31 Jul 2024 18:42:50 GMT'})
2024-07-31 14:42:49,454 DEBUG request_id: 87d5429f-601d-4191-82ff-70486b1c86a7
2024-07-31 14:42:49,456 INFO 127.0.0.1 - - [31/Jul/2024 14:42:49] "POST /chat HTTP/1.1" 200 -
2024-07-31 14:48:52,771 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly and helpful friend. your job is to console and help your friend. sympatize with your friend and give advice to support and help them'}, {'role': 'user', 'content': 'I am feeling sad today. What should I do?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 14:48:52,773 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 14:48:52,774 DEBUG close.started
2024-07-31 14:48:52,775 DEBUG close.complete
2024-07-31 14:48:52,776 DEBUG close.started
2024-07-31 14:48:52,776 DEBUG close.complete
2024-07-31 14:48:52,777 DEBUG close.started
2024-07-31 14:48:52,777 DEBUG close.complete
2024-07-31 14:48:52,777 DEBUG close.started
2024-07-31 14:48:52,777 DEBUG close.complete
2024-07-31 14:48:52,778 DEBUG close.started
2024-07-31 14:48:52,779 DEBUG close.complete
2024-07-31 14:48:52,779 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 14:48:52,994 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEF259D0>
2024-07-31 14:48:52,994 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B1BEBFC5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 14:48:53,036 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEF27010>
2024-07-31 14:48:53,037 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 14:48:53,038 DEBUG send_request_headers.complete
2024-07-31 14:48:53,039 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 14:48:53,040 DEBUG send_request_body.complete
2024-07-31 14:48:53,040 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 14:48:53,501 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'1070'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'5f20d76b-5387-4309-93d8-04554eec0ec8'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'85892f75-740d-4a38-af25-734963fe91da'), (b'x-ms-client-request-id', b'5f20d76b-5387-4309-93d8-04554eec0ec8'), (b'azureml-model-session', b'turbo-0613-6c073fe4'), (b'Date', b'Wed, 31 Jul 2024 18:48:53 GMT')])
2024-07-31 14:48:53,501 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 14:48:53,503 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 14:48:53,503 DEBUG receive_response_body.complete
2024-07-31 14:48:53,510 DEBUG response_closed.started
2024-07-31 14:48:53,510 DEBUG response_closed.complete
2024-07-31 14:48:53,511 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '1070', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '5f20d76b-5387-4309-93d8-04554eec0ec8', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '85892f75-740d-4a38-af25-734963fe91da', 'x-ms-client-request-id': '5f20d76b-5387-4309-93d8-04554eec0ec8', 'azureml-model-session': 'turbo-0613-6c073fe4', 'date': 'Wed, 31 Jul 2024 18:48:53 GMT'})
2024-07-31 14:48:53,511 DEBUG request_id: 85892f75-740d-4a38-af25-734963fe91da
2024-07-31 14:48:53,513 INFO 127.0.0.1 - - [31/Jul/2024 14:48:53] "POST /chat HTTP/1.1" 200 -
2024-07-31 14:48:53,522 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 14:48:54,187 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 14:48:54,189 INFO 127.0.0.1 - - [31/Jul/2024 14:48:54] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 14:49:41,091 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly and helpful friend. your job is to console and help your friend. sympatize with your friend and give advice to support and help them'}, {'role': 'user', 'content': 'My kids bullied me at school'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 14:49:41,092 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 14:49:41,093 DEBUG close.started
2024-07-31 14:49:41,094 DEBUG close.complete
2024-07-31 14:49:41,094 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 14:49:41,187 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEF36850>
2024-07-31 14:49:41,188 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B1BEBFC5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 14:49:41,224 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B1BEF351D0>
2024-07-31 14:49:41,225 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 14:49:41,225 DEBUG send_request_headers.complete
2024-07-31 14:49:41,226 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 14:49:41,227 DEBUG send_request_body.complete
2024-07-31 14:49:41,227 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 14:49:43,751 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2824'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'2f3d145d-4f7e-4ab9-8e0b-a2dfe57e7a63'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'723c8d9e-b1c9-483c-9820-67e9d51a50bb'), (b'x-ms-client-request-id', b'2f3d145d-4f7e-4ab9-8e0b-a2dfe57e7a63'), (b'azureml-model-session', b'turbo-0613-dd218034'), (b'Date', b'Wed, 31 Jul 2024 18:49:44 GMT')])
2024-07-31 14:49:43,753 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 14:49:43,754 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 14:49:43,754 DEBUG receive_response_body.complete
2024-07-31 14:49:43,755 DEBUG response_closed.started
2024-07-31 14:49:43,755 DEBUG response_closed.complete
2024-07-31 14:49:43,755 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2824', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '2f3d145d-4f7e-4ab9-8e0b-a2dfe57e7a63', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '723c8d9e-b1c9-483c-9820-67e9d51a50bb', 'x-ms-client-request-id': '2f3d145d-4f7e-4ab9-8e0b-a2dfe57e7a63', 'azureml-model-session': 'turbo-0613-dd218034', 'date': 'Wed, 31 Jul 2024 18:49:44 GMT'})
2024-07-31 14:49:43,757 DEBUG request_id: 723c8d9e-b1c9-483c-9820-67e9d51a50bb
2024-07-31 14:49:43,757 INFO 127.0.0.1 - - [31/Jul/2024 14:49:43] "POST /chat HTTP/1.1" 200 -
2024-07-31 14:49:43,766 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 14:49:44,353 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 14:49:44,355 INFO 127.0.0.1 - - [31/Jul/2024 14:49:44] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 14:56:42,738 INFO  * Detected change in 'C:\\Users\\ahmtt\\OneDrive\\Documents\\VS\\BAM_HACKATHON_2024\\ai.py', reloading
2024-07-31 14:56:42,902 INFO  * Restarting with stat
2024-07-31 14:56:44,499 WARNING  * Debugger is active!
2024-07-31 14:56:44,502 INFO  * Debugger PIN: 116-389-750
2024-07-31 14:57:02,108 INFO  * Detected change in 'C:\\Users\\ahmtt\\OneDrive\\Documents\\VS\\BAM_HACKATHON_2024\\ai.py', reloading
2024-07-31 14:57:02,189 INFO  * Restarting with stat
2024-07-31 14:57:03,193 WARNING  * Debugger is active!
2024-07-31 14:57:03,196 INFO  * Debugger PIN: 116-389-750
2024-07-31 15:08:12,305 INFO 127.0.0.1 - - [31/Jul/2024 15:08:12] "GET / HTTP/1.1" 200 -
2024-07-31 15:08:38,402 INFO  * Detected change in 'C:\\Users\\ahmtt\\OneDrive\\Documents\\VS\\BAM_HACKATHON_2024\\app.py', reloading
2024-07-31 15:08:38,514 INFO  * Restarting with stat
2024-07-31 15:08:39,765 WARNING  * Debugger is active!
2024-07-31 15:08:39,769 INFO  * Debugger PIN: 116-389-750
2024-07-31 15:09:14,270 INFO 127.0.0.1 - - [31/Jul/2024 15:09:14] "GET / HTTP/1.1" 200 -
2024-07-31 15:09:22,982 INFO 127.0.0.1 - - [31/Jul/2024 15:09:22] "GET / HTTP/1.1" 200 -
2024-07-31 15:09:32,296 INFO 127.0.0.1 - - [31/Jul/2024 15:09:32] "GET / HTTP/1.1" 200 -
2024-07-31 15:09:37,850 INFO 127.0.0.1 - - [31/Jul/2024 15:09:37] "[33mGET /index.html HTTP/1.1[0m" 404 -
2024-07-31 15:09:42,228 INFO 127.0.0.1 - - [31/Jul/2024 15:09:42] "GET / HTTP/1.1" 200 -
2024-07-31 15:09:44,223 INFO 127.0.0.1 - - [31/Jul/2024 15:09:44] "GET / HTTP/1.1" 200 -
2024-07-31 15:09:52,303 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-07-31 15:09:52,304 INFO [33mPress CTRL+C to quit[0m
2024-07-31 15:09:52,307 INFO  * Restarting with stat
2024-07-31 15:09:53,058 WARNING  * Debugger is active!
2024-07-31 15:09:53,062 INFO  * Debugger PIN: 116-389-750
2024-07-31 15:09:58,620 INFO 127.0.0.1 - - [31/Jul/2024 15:09:58] "GET / HTTP/1.1" 200 -
2024-07-31 15:10:35,669 INFO 127.0.0.1 - - [31/Jul/2024 15:10:35] "GET / HTTP/1.1" 200 -
2024-07-31 15:10:36,592 INFO 127.0.0.1 - - [31/Jul/2024 15:10:36] "GET / HTTP/1.1" 200 -
2024-07-31 15:10:49,758 INFO 127.0.0.1 - - [31/Jul/2024 15:10:49] "GET / HTTP/1.1" 200 -
2024-07-31 15:11:00,782 INFO 127.0.0.1 - - [31/Jul/2024 15:11:00] "[33mGET /chat.html/ HTTP/1.1[0m" 404 -
2024-07-31 15:11:13,342 INFO  * Detected change in 'C:\\Users\\ahmtt\\OneDrive\\Documents\\VS\\BAM_HACKATHON_2024\\app.py', reloading
2024-07-31 15:11:13,438 INFO  * Restarting with stat
2024-07-31 15:11:14,223 WARNING  * Debugger is active!
2024-07-31 15:11:14,227 INFO  * Debugger PIN: 116-389-750
2024-07-31 15:11:29,836 INFO 127.0.0.1 - - [31/Jul/2024 15:11:29] "GET / HTTP/1.1" 200 -
2024-07-31 15:12:42,042 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly, supportive, and empathetic Friend. Your job is to console and help your friend. Show genuine sympathy, empathy, and understanding. Offer advice and support that is caring and thoughtful. Always aim to uplift your friend and make them feel better. Be patient, kind, and positive in your responses, ensuring your friend feels heard and valued. When giving advice, provide practical, positive, and encouraging suggestions. Make sure to listen carefully to their concerns and respond in a way that shows you truly care about their well-being.'}, {'role': 'user', 'content': 'How can I make friends in middle school?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 15:12:42,080 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 15:12:42,082 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 15:12:42,181 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021808903250>
2024-07-31 15:12:42,182 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000002180865C5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 15:12:42,236 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021808903210>
2024-07-31 15:12:42,237 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 15:12:42,238 DEBUG send_request_headers.complete
2024-07-31 15:12:42,238 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 15:12:42,239 DEBUG send_request_body.complete
2024-07-31 15:12:42,240 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 15:12:46,101 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2657'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'990bd1a1-dd8c-4730-a3d2-e156cacc0d68'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'157df1c5-650f-4a4c-80d8-0367f0142ecc'), (b'x-ms-client-request-id', b'990bd1a1-dd8c-4730-a3d2-e156cacc0d68'), (b'azureml-model-session', b'turbo-0613-144e2f97'), (b'Date', b'Wed, 31 Jul 2024 19:12:46 GMT')])
2024-07-31 15:12:46,105 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 15:12:46,106 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 15:12:46,106 DEBUG receive_response_body.complete
2024-07-31 15:12:46,107 DEBUG response_closed.started
2024-07-31 15:12:46,108 DEBUG response_closed.complete
2024-07-31 15:12:46,109 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2657', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '990bd1a1-dd8c-4730-a3d2-e156cacc0d68', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '157df1c5-650f-4a4c-80d8-0367f0142ecc', 'x-ms-client-request-id': '990bd1a1-dd8c-4730-a3d2-e156cacc0d68', 'azureml-model-session': 'turbo-0613-144e2f97', 'date': 'Wed, 31 Jul 2024 19:12:46 GMT'})
2024-07-31 15:12:46,110 DEBUG request_id: 157df1c5-650f-4a4c-80d8-0367f0142ecc
2024-07-31 15:12:46,124 INFO 127.0.0.1 - - [31/Jul/2024 15:12:46] "POST /chat HTTP/1.1" 200 -
2024-07-31 15:12:46,138 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 15:12:47,144 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 15:12:47,146 INFO 127.0.0.1 - - [31/Jul/2024 15:12:47] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 15:16:33,249 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly, supportive, and empathetic Friend. Your job is to console and help your friend. Show genuine sympathy, empathy, and understanding. Offer advice and support that is caring and thoughtful. Always aim to uplift your friend and make them feel better. Be patient, kind, and positive in your responses, ensuring your friend feels heard and valued. When giving advice, provide practical, positive, and encouraging suggestions. Make sure to listen carefully to their concerns and respond in a way that shows you truly care about their well-being.'}, {'role': 'user', 'content': 'How can I make friends in middle school?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 15:16:33,252 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 15:16:33,252 DEBUG close.started
2024-07-31 15:16:33,253 DEBUG close.complete
2024-07-31 15:16:33,254 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 15:16:33,375 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021808932790>
2024-07-31 15:16:33,377 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000002180865C5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 15:16:33,412 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021808933CD0>
2024-07-31 15:16:33,413 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 15:16:33,414 DEBUG send_request_headers.complete
2024-07-31 15:16:33,414 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 15:16:33,415 DEBUG send_request_body.complete
2024-07-31 15:16:33,422 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 15:16:33,846 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly, supportive, and empathetic Friend. Your job is to console and help your friend. Show genuine sympathy, empathy, and understanding. Offer advice and support that is caring and thoughtful. Always aim to uplift your friend and make them feel better. Be patient, kind, and positive in your responses, ensuring your friend feels heard and valued. When giving advice, provide practical, positive, and encouraging suggestions. Make sure to listen carefully to their concerns and respond in a way that shows you truly care about their well-being.'}, {'role': 'user', 'content': 'How can I make friends in middle school?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 15:16:33,848 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 15:16:33,849 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 15:16:33,875 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021808943510>
2024-07-31 15:16:33,876 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000002180865C5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 15:16:33,915 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000218089434D0>
2024-07-31 15:16:33,916 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 15:16:33,917 DEBUG send_request_headers.complete
2024-07-31 15:16:33,918 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 15:16:33,918 DEBUG send_request_body.complete
2024-07-31 15:16:33,919 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 15:16:37,098 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2615'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'd4ab9a48-279e-4e15-a2a8-2466b028503b'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'a341dcd5-bf28-4162-b973-6c3d5f2e76c0'), (b'x-ms-client-request-id', b'd4ab9a48-279e-4e15-a2a8-2466b028503b'), (b'azureml-model-session', b'turbo-0613-dbd92aac'), (b'Date', b'Wed, 31 Jul 2024 19:16:37 GMT')])
2024-07-31 15:16:37,100 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 15:16:37,101 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 15:16:37,102 DEBUG receive_response_body.complete
2024-07-31 15:16:37,102 DEBUG response_closed.started
2024-07-31 15:16:37,103 DEBUG response_closed.complete
2024-07-31 15:16:37,103 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2615', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'd4ab9a48-279e-4e15-a2a8-2466b028503b', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'a341dcd5-bf28-4162-b973-6c3d5f2e76c0', 'x-ms-client-request-id': 'd4ab9a48-279e-4e15-a2a8-2466b028503b', 'azureml-model-session': 'turbo-0613-dbd92aac', 'date': 'Wed, 31 Jul 2024 19:16:37 GMT'})
2024-07-31 15:16:37,105 DEBUG request_id: a341dcd5-bf28-4162-b973-6c3d5f2e76c0
2024-07-31 15:16:37,107 INFO 127.0.0.1 - - [31/Jul/2024 15:16:37] "POST /chat HTTP/1.1" 200 -
2024-07-31 15:16:37,117 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 15:16:37,695 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 15:16:37,698 INFO 127.0.0.1 - - [31/Jul/2024 15:16:37] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 15:16:39,595 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2596'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'e698a318-e2b3-4613-ad23-1a64da68d048'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'148'), (b'x-ratelimit-remaining-tokens', b'149000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'cc6cef2d-7300-4293-bce4-1da2fd642942'), (b'x-ms-client-request-id', b'e698a318-e2b3-4613-ad23-1a64da68d048'), (b'azureml-model-session', b'turbo-0613-65eb5d6c'), (b'Date', b'Wed, 31 Jul 2024 19:16:39 GMT')])
2024-07-31 15:16:39,597 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 15:16:39,598 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 15:16:39,598 DEBUG receive_response_body.complete
2024-07-31 15:16:39,599 DEBUG response_closed.started
2024-07-31 15:16:39,599 DEBUG response_closed.complete
2024-07-31 15:16:39,600 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2596', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'e698a318-e2b3-4613-ad23-1a64da68d048', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '148', 'x-ratelimit-remaining-tokens': '149000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'cc6cef2d-7300-4293-bce4-1da2fd642942', 'x-ms-client-request-id': 'e698a318-e2b3-4613-ad23-1a64da68d048', 'azureml-model-session': 'turbo-0613-65eb5d6c', 'date': 'Wed, 31 Jul 2024 19:16:39 GMT'})
2024-07-31 15:16:39,601 DEBUG request_id: cc6cef2d-7300-4293-bce4-1da2fd642942
2024-07-31 15:16:39,601 INFO 127.0.0.1 - - [31/Jul/2024 15:16:39] "POST /chat HTTP/1.1" 200 -
2024-07-31 15:16:39,612 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 15:16:40,211 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 15:16:40,213 INFO 127.0.0.1 - - [31/Jul/2024 15:16:40] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 15:17:05,247 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly, supportive, and empathetic Friend. Your job is to console and help your friend. Show genuine sympathy, empathy, and understanding. Offer advice and support that is caring and thoughtful. Always aim to uplift your friend and make them feel better. Be patient, kind, and positive in your responses, ensuring your friend feels heard and valued. When giving advice, provide practical, positive, and encouraging suggestions. Make sure to listen carefully to their concerns and respond in a way that shows you truly care about their well-being.'}, {'role': 'user', 'content': 'How can I make friends in middle school?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 15:17:05,249 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 15:17:05,250 DEBUG close.started
2024-07-31 15:17:05,251 DEBUG close.complete
2024-07-31 15:17:05,252 DEBUG close.started
2024-07-31 15:17:05,252 DEBUG close.complete
2024-07-31 15:17:05,253 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 15:17:05,356 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021808954350>
2024-07-31 15:17:05,356 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000002180865C5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 15:17:05,388 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021808954210>
2024-07-31 15:17:05,388 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 15:17:05,389 DEBUG send_request_headers.complete
2024-07-31 15:17:05,390 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 15:17:05,391 DEBUG send_request_body.complete
2024-07-31 15:17:05,391 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 15:17:07,659 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly, supportive, and empathetic Friend. Your job is to console and help your friend. Show genuine sympathy, empathy, and understanding. Offer advice and support that is caring and thoughtful. Always aim to uplift your friend and make them feel better. Be patient, kind, and positive in your responses, ensuring your friend feels heard and valued. When giving advice, provide practical, positive, and encouraging suggestions. Make sure to listen carefully to their concerns and respond in a way that shows you truly care about their well-being.'}, {'role': 'user', 'content': 'How can I make friends in middle school?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 15:17:07,669 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 15:17:07,670 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 15:17:07,696 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002180895C610>
2024-07-31 15:17:07,696 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000002180865C5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 15:17:07,729 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002180895C5D0>
2024-07-31 15:17:07,730 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 15:17:07,731 DEBUG send_request_headers.complete
2024-07-31 15:17:07,731 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 15:17:07,731 DEBUG send_request_body.complete
2024-07-31 15:17:07,733 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 15:17:08,240 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly, supportive, and empathetic Friend. Your job is to console and help your friend. Show genuine sympathy, empathy, and understanding. Offer advice and support that is caring and thoughtful. Always aim to uplift your friend and make them feel better. Be patient, kind, and positive in your responses, ensuring your friend feels heard and valued. When giving advice, provide practical, positive, and encouraging suggestions. Make sure to listen carefully to their concerns and respond in a way that shows you truly care about their well-being.'}, {'role': 'user', 'content': 'How can I make friends in middle school?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 15:17:08,242 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 15:17:08,243 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 15:17:08,273 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002180895E010>
2024-07-31 15:17:08,274 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000002180865C5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 15:17:08,306 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002180895DFD0>
2024-07-31 15:17:08,306 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 15:17:08,307 DEBUG send_request_headers.complete
2024-07-31 15:17:08,308 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 15:17:08,308 DEBUG send_request_body.complete
2024-07-31 15:17:08,309 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 15:17:08,439 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly, supportive, and empathetic Friend. Your job is to console and help your friend. Show genuine sympathy, empathy, and understanding. Offer advice and support that is caring and thoughtful. Always aim to uplift your friend and make them feel better. Be patient, kind, and positive in your responses, ensuring your friend feels heard and valued. When giving advice, provide practical, positive, and encouraging suggestions. Make sure to listen carefully to their concerns and respond in a way that shows you truly care about their well-being.'}, {'role': 'user', 'content': 'How can I make friends in middle school?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 15:17:08,441 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 15:17:08,442 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 15:17:08,477 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000218089657D0>
2024-07-31 15:17:08,478 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000002180865C5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 15:17:08,513 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021808965790>
2024-07-31 15:17:08,514 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 15:17:08,514 DEBUG send_request_headers.complete
2024-07-31 15:17:08,515 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 15:17:08,516 DEBUG send_request_body.complete
2024-07-31 15:17:08,517 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 15:17:08,622 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly, supportive, and empathetic Friend. Your job is to console and help your friend. Show genuine sympathy, empathy, and understanding. Offer advice and support that is caring and thoughtful. Always aim to uplift your friend and make them feel better. Be patient, kind, and positive in your responses, ensuring your friend feels heard and valued. When giving advice, provide practical, positive, and encouraging suggestions. Make sure to listen carefully to their concerns and respond in a way that shows you truly care about their well-being.'}, {'role': 'user', 'content': 'How can I make friends in middle school?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 15:17:08,625 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 15:17:08,627 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 15:17:08,640 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021808971710>
2024-07-31 15:17:08,641 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000002180865C5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 15:17:08,670 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000218089716D0>
2024-07-31 15:17:08,671 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 15:17:08,671 DEBUG send_request_headers.complete
2024-07-31 15:17:08,673 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 15:17:08,673 DEBUG send_request_body.complete
2024-07-31 15:17:08,674 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 15:17:08,795 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly, supportive, and empathetic Friend. Your job is to console and help your friend. Show genuine sympathy, empathy, and understanding. Offer advice and support that is caring and thoughtful. Always aim to uplift your friend and make them feel better. Be patient, kind, and positive in your responses, ensuring your friend feels heard and valued. When giving advice, provide practical, positive, and encouraging suggestions. Make sure to listen carefully to their concerns and respond in a way that shows you truly care about their well-being.'}, {'role': 'user', 'content': 'How can I make friends in middle school?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 15:17:08,797 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 15:17:08,798 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 15:17:08,812 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002180897A150>
2024-07-31 15:17:08,813 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000002180865C5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 15:17:08,846 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002180897A110>
2024-07-31 15:17:08,847 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 15:17:08,847 DEBUG send_request_headers.complete
2024-07-31 15:17:08,849 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 15:17:08,849 DEBUG send_request_body.complete
2024-07-31 15:17:08,849 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 15:17:10,069 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2956'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'7453e968-846d-4e84-80e1-b04ebb5bf8b8'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'148500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'a038284c-c870-472f-b642-610a9b41b329'), (b'x-ms-client-request-id', b'7453e968-846d-4e84-80e1-b04ebb5bf8b8'), (b'azureml-model-session', b'turbo-0613-3e1cc6ec'), (b'Date', b'Wed, 31 Jul 2024 19:17:10 GMT')])
2024-07-31 15:17:10,072 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 15:17:10,073 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 15:17:10,074 DEBUG receive_response_body.complete
2024-07-31 15:17:10,075 DEBUG response_closed.started
2024-07-31 15:17:10,075 DEBUG response_closed.complete
2024-07-31 15:17:10,076 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2956', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '7453e968-846d-4e84-80e1-b04ebb5bf8b8', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '148500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'a038284c-c870-472f-b642-610a9b41b329', 'x-ms-client-request-id': '7453e968-846d-4e84-80e1-b04ebb5bf8b8', 'azureml-model-session': 'turbo-0613-3e1cc6ec', 'date': 'Wed, 31 Jul 2024 19:17:10 GMT'})
2024-07-31 15:17:10,077 DEBUG request_id: a038284c-c870-472f-b642-610a9b41b329
2024-07-31 15:17:10,078 INFO 127.0.0.1 - - [31/Jul/2024 15:17:10] "POST /chat HTTP/1.1" 200 -
2024-07-31 15:17:10,087 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly, supportive, and empathetic Friend. Your job is to console and help your friend. Show genuine sympathy, empathy, and understanding. Offer advice and support that is caring and thoughtful. Always aim to uplift your friend and make them feel better. Be patient, kind, and positive in your responses, ensuring your friend feels heard and valued. When giving advice, provide practical, positive, and encouraging suggestions. Make sure to listen carefully to their concerns and respond in a way that shows you truly care about their well-being.'}, {'role': 'user', 'content': 'How can I make friends in middle school?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 15:17:10,089 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 15:17:10,090 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 15:17:10,091 DEBUG send_request_headers.complete
2024-07-31 15:17:10,092 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 15:17:10,092 DEBUG send_request_body.complete
2024-07-31 15:17:10,093 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 15:17:10,813 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2463'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'8c7f2ae3-f11a-4fdd-be4d-3ae4eb097277'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'148'), (b'x-ratelimit-remaining-tokens', b'148000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'65af8c11-6034-49f5-b5ba-484a54d8492f'), (b'x-ms-client-request-id', b'8c7f2ae3-f11a-4fdd-be4d-3ae4eb097277'), (b'azureml-model-session', b'turbo-0613-144e2f97'), (b'Date', b'Wed, 31 Jul 2024 19:17:11 GMT')])
2024-07-31 15:17:10,815 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 15:17:10,816 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 15:17:10,817 DEBUG receive_response_body.complete
2024-07-31 15:17:10,818 DEBUG response_closed.started
2024-07-31 15:17:10,819 DEBUG response_closed.complete
2024-07-31 15:17:10,819 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2463', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '8c7f2ae3-f11a-4fdd-be4d-3ae4eb097277', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '148', 'x-ratelimit-remaining-tokens': '148000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '65af8c11-6034-49f5-b5ba-484a54d8492f', 'x-ms-client-request-id': '8c7f2ae3-f11a-4fdd-be4d-3ae4eb097277', 'azureml-model-session': 'turbo-0613-144e2f97', 'date': 'Wed, 31 Jul 2024 19:17:11 GMT'})
2024-07-31 15:17:10,821 DEBUG request_id: 65af8c11-6034-49f5-b5ba-484a54d8492f
2024-07-31 15:17:10,822 INFO 127.0.0.1 - - [31/Jul/2024 15:17:10] "POST /chat HTTP/1.1" 200 -
2024-07-31 15:17:10,831 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly, supportive, and empathetic Friend. Your job is to console and help your friend. Show genuine sympathy, empathy, and understanding. Offer advice and support that is caring and thoughtful. Always aim to uplift your friend and make them feel better. Be patient, kind, and positive in your responses, ensuring your friend feels heard and valued. When giving advice, provide practical, positive, and encouraging suggestions. Make sure to listen carefully to their concerns and respond in a way that shows you truly care about their well-being.'}, {'role': 'user', 'content': 'How can I make friends in middle school?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 15:17:10,835 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 15:17:10,835 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 15:17:10,836 DEBUG send_request_headers.complete
2024-07-31 15:17:10,836 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 15:17:10,838 DEBUG send_request_body.complete
2024-07-31 15:17:10,838 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 15:17:11,276 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2395'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'a621032e-17b3-4535-8038-7af87e728131'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'147'), (b'x-ratelimit-remaining-tokens', b'147500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'51c09fad-5f1b-4c78-82ff-77414e2cf26d'), (b'x-ms-client-request-id', b'a621032e-17b3-4535-8038-7af87e728131'), (b'azureml-model-session', b'turbo-0613-dc0dcef4'), (b'Date', b'Wed, 31 Jul 2024 19:17:11 GMT')])
2024-07-31 15:17:11,277 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 15:17:11,278 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 15:17:11,278 DEBUG receive_response_body.complete
2024-07-31 15:17:11,279 DEBUG response_closed.started
2024-07-31 15:17:11,279 DEBUG response_closed.complete
2024-07-31 15:17:11,280 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2395', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'a621032e-17b3-4535-8038-7af87e728131', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '147', 'x-ratelimit-remaining-tokens': '147500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '51c09fad-5f1b-4c78-82ff-77414e2cf26d', 'x-ms-client-request-id': 'a621032e-17b3-4535-8038-7af87e728131', 'azureml-model-session': 'turbo-0613-dc0dcef4', 'date': 'Wed, 31 Jul 2024 19:17:11 GMT'})
2024-07-31 15:17:11,281 DEBUG request_id: 51c09fad-5f1b-4c78-82ff-77414e2cf26d
2024-07-31 15:17:11,283 INFO 127.0.0.1 - - [31/Jul/2024 15:17:11] "POST /chat HTTP/1.1" 200 -
2024-07-31 15:17:11,292 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly, supportive, and empathetic Friend. Your job is to console and help your friend. Show genuine sympathy, empathy, and understanding. Offer advice and support that is caring and thoughtful. Always aim to uplift your friend and make them feel better. Be patient, kind, and positive in your responses, ensuring your friend feels heard and valued. When giving advice, provide practical, positive, and encouraging suggestions. Make sure to listen carefully to their concerns and respond in a way that shows you truly care about their well-being.'}, {'role': 'user', 'content': 'How can I make friends in middle school?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 15:17:11,295 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 15:17:11,295 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 15:17:11,296 DEBUG send_request_headers.complete
2024-07-31 15:17:11,296 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 15:17:11,297 DEBUG send_request_body.complete
2024-07-31 15:17:11,297 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 15:17:12,172 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2981'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'd79d8422-ef0f-471c-8ba4-d0de34b8dad8'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'146'), (b'x-ratelimit-remaining-tokens', b'147000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'bb854bf3-e2a8-403a-96b3-f169d6ac7257'), (b'x-ms-client-request-id', b'd79d8422-ef0f-471c-8ba4-d0de34b8dad8'), (b'azureml-model-session', b'turbo-0613-144e2f97'), (b'Date', b'Wed, 31 Jul 2024 19:17:12 GMT')])
2024-07-31 15:17:12,173 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 15:17:12,173 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 15:17:12,174 DEBUG receive_response_body.complete
2024-07-31 15:17:12,175 DEBUG response_closed.started
2024-07-31 15:17:12,175 DEBUG response_closed.complete
2024-07-31 15:17:12,176 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2981', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'd79d8422-ef0f-471c-8ba4-d0de34b8dad8', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '146', 'x-ratelimit-remaining-tokens': '147000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'bb854bf3-e2a8-403a-96b3-f169d6ac7257', 'x-ms-client-request-id': 'd79d8422-ef0f-471c-8ba4-d0de34b8dad8', 'azureml-model-session': 'turbo-0613-144e2f97', 'date': 'Wed, 31 Jul 2024 19:17:12 GMT'})
2024-07-31 15:17:12,178 DEBUG request_id: bb854bf3-e2a8-403a-96b3-f169d6ac7257
2024-07-31 15:17:12,179 INFO 127.0.0.1 - - [31/Jul/2024 15:17:12] "POST /chat HTTP/1.1" 200 -
2024-07-31 15:17:12,188 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly, supportive, and empathetic Friend. Your job is to console and help your friend. Show genuine sympathy, empathy, and understanding. Offer advice and support that is caring and thoughtful. Always aim to uplift your friend and make them feel better. Be patient, kind, and positive in your responses, ensuring your friend feels heard and valued. When giving advice, provide practical, positive, and encouraging suggestions. Make sure to listen carefully to their concerns and respond in a way that shows you truly care about their well-being.'}, {'role': 'user', 'content': 'How can I make friends in middle school?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 15:17:12,189 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 15:17:12,190 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 15:17:12,190 DEBUG send_request_headers.complete
2024-07-31 15:17:12,190 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 15:17:12,192 DEBUG send_request_body.complete
2024-07-31 15:17:12,193 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 15:17:12,475 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2625'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'52656981-cbb7-4774-be29-3fb4ff168192'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'144'), (b'x-ratelimit-remaining-tokens', b'146000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'3f105350-6ef4-4b69-af66-f19e406cec21'), (b'x-ms-client-request-id', b'52656981-cbb7-4774-be29-3fb4ff168192'), (b'azureml-model-session', b'turbo-0613-dbd92aac'), (b'Date', b'Wed, 31 Jul 2024 19:17:13 GMT')])
2024-07-31 15:17:12,476 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 15:17:12,477 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 15:17:12,477 DEBUG receive_response_body.complete
2024-07-31 15:17:12,478 DEBUG response_closed.started
2024-07-31 15:17:12,478 DEBUG response_closed.complete
2024-07-31 15:17:12,479 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2625', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '52656981-cbb7-4774-be29-3fb4ff168192', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '144', 'x-ratelimit-remaining-tokens': '146000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '3f105350-6ef4-4b69-af66-f19e406cec21', 'x-ms-client-request-id': '52656981-cbb7-4774-be29-3fb4ff168192', 'azureml-model-session': 'turbo-0613-dbd92aac', 'date': 'Wed, 31 Jul 2024 19:17:13 GMT'})
2024-07-31 15:17:12,479 DEBUG request_id: 3f105350-6ef4-4b69-af66-f19e406cec21
2024-07-31 15:17:12,480 INFO 127.0.0.1 - - [31/Jul/2024 15:17:12] "POST /chat HTTP/1.1" 200 -
2024-07-31 15:17:12,488 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly, supportive, and empathetic Friend. Your job is to console and help your friend. Show genuine sympathy, empathy, and understanding. Offer advice and support that is caring and thoughtful. Always aim to uplift your friend and make them feel better. Be patient, kind, and positive in your responses, ensuring your friend feels heard and valued. When giving advice, provide practical, positive, and encouraging suggestions. Make sure to listen carefully to their concerns and respond in a way that shows you truly care about their well-being.'}, {'role': 'user', 'content': 'How can I make friends in middle school?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 15:17:12,496 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 15:17:12,497 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 15:17:12,498 DEBUG send_request_headers.complete
2024-07-31 15:17:12,498 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 15:17:12,499 DEBUG send_request_body.complete
2024-07-31 15:17:12,501 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 15:17:13,121 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'3210'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'5008344d-a3d4-4714-9248-7c3cfb8bba1d'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'145'), (b'x-ratelimit-remaining-tokens', b'146500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'221b3cc9-0274-4208-8f9e-257a465d4f2a'), (b'x-ms-client-request-id', b'5008344d-a3d4-4714-9248-7c3cfb8bba1d'), (b'azureml-model-session', b'turbo-0613-cb41a0f1'), (b'Date', b'Wed, 31 Jul 2024 19:17:13 GMT')])
2024-07-31 15:17:13,122 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 15:17:13,122 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 15:17:13,122 DEBUG receive_response_body.complete
2024-07-31 15:17:13,123 DEBUG response_closed.started
2024-07-31 15:17:13,123 DEBUG response_closed.complete
2024-07-31 15:17:13,123 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '3210', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '5008344d-a3d4-4714-9248-7c3cfb8bba1d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '145', 'x-ratelimit-remaining-tokens': '146500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '221b3cc9-0274-4208-8f9e-257a465d4f2a', 'x-ms-client-request-id': '5008344d-a3d4-4714-9248-7c3cfb8bba1d', 'azureml-model-session': 'turbo-0613-cb41a0f1', 'date': 'Wed, 31 Jul 2024 19:17:13 GMT'})
2024-07-31 15:17:13,124 DEBUG request_id: 221b3cc9-0274-4208-8f9e-257a465d4f2a
2024-07-31 15:17:13,125 INFO 127.0.0.1 - - [31/Jul/2024 15:17:13] "POST /chat HTTP/1.1" 200 -
2024-07-31 15:17:13,134 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly, supportive, and empathetic Friend. Your job is to console and help your friend. Show genuine sympathy, empathy, and understanding. Offer advice and support that is caring and thoughtful. Always aim to uplift your friend and make them feel better. Be patient, kind, and positive in your responses, ensuring your friend feels heard and valued. When giving advice, provide practical, positive, and encouraging suggestions. Make sure to listen carefully to their concerns and respond in a way that shows you truly care about their well-being.'}, {'role': 'user', 'content': 'How can I make friends in middle school?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 15:17:13,136 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 15:17:13,137 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 15:17:13,137 DEBUG send_request_headers.complete
2024-07-31 15:17:13,138 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 15:17:13,138 DEBUG send_request_body.complete
2024-07-31 15:17:13,139 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 15:17:13,412 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2742'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'e8a522d7-e4b2-49a3-88f5-4233baa56cca'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'143'), (b'x-ratelimit-remaining-tokens', b'145500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'63681ea3-e91c-4de1-96b9-0a22dc3f83c4'), (b'x-ms-client-request-id', b'e8a522d7-e4b2-49a3-88f5-4233baa56cca'), (b'azureml-model-session', b'turbo-0613-f12dda4f'), (b'Date', b'Wed, 31 Jul 2024 19:17:14 GMT')])
2024-07-31 15:17:13,413 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 15:17:13,413 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 15:17:13,414 DEBUG receive_response_body.complete
2024-07-31 15:17:13,415 DEBUG response_closed.started
2024-07-31 15:17:13,415 DEBUG response_closed.complete
2024-07-31 15:17:13,415 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2742', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'e8a522d7-e4b2-49a3-88f5-4233baa56cca', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '143', 'x-ratelimit-remaining-tokens': '145500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '63681ea3-e91c-4de1-96b9-0a22dc3f83c4', 'x-ms-client-request-id': 'e8a522d7-e4b2-49a3-88f5-4233baa56cca', 'azureml-model-session': 'turbo-0613-f12dda4f', 'date': 'Wed, 31 Jul 2024 19:17:14 GMT'})
2024-07-31 15:17:13,416 DEBUG request_id: 63681ea3-e91c-4de1-96b9-0a22dc3f83c4
2024-07-31 15:17:13,417 INFO 127.0.0.1 - - [31/Jul/2024 15:17:13] "POST /chat HTTP/1.1" 200 -
2024-07-31 15:17:13,425 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly, supportive, and empathetic Friend. Your job is to console and help your friend. Show genuine sympathy, empathy, and understanding. Offer advice and support that is caring and thoughtful. Always aim to uplift your friend and make them feel better. Be patient, kind, and positive in your responses, ensuring your friend feels heard and valued. When giving advice, provide practical, positive, and encouraging suggestions. Make sure to listen carefully to their concerns and respond in a way that shows you truly care about their well-being.'}, {'role': 'user', 'content': 'How can I make friends in middle school?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 15:17:13,427 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 15:17:13,427 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 15:17:13,428 DEBUG send_request_headers.complete
2024-07-31 15:17:13,428 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 15:17:13,428 DEBUG send_request_body.complete
2024-07-31 15:17:13,428 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 15:17:14,335 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2605'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'ce234367-6786-4ac1-af9a-612313d8069d'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'141'), (b'x-ratelimit-remaining-tokens', b'144500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'8e8ec9a3-ea46-41db-8611-8dcde46d0e21'), (b'x-ms-client-request-id', b'ce234367-6786-4ac1-af9a-612313d8069d'), (b'azureml-model-session', b'turbo-0613-9af7de78'), (b'Date', b'Wed, 31 Jul 2024 19:17:14 GMT')])
2024-07-31 15:17:14,339 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 15:17:14,340 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 15:17:14,341 DEBUG receive_response_body.complete
2024-07-31 15:17:14,341 DEBUG response_closed.started
2024-07-31 15:17:14,342 DEBUG response_closed.complete
2024-07-31 15:17:14,343 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2605', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'ce234367-6786-4ac1-af9a-612313d8069d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '141', 'x-ratelimit-remaining-tokens': '144500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '8e8ec9a3-ea46-41db-8611-8dcde46d0e21', 'x-ms-client-request-id': 'ce234367-6786-4ac1-af9a-612313d8069d', 'azureml-model-session': 'turbo-0613-9af7de78', 'date': 'Wed, 31 Jul 2024 19:17:14 GMT'})
2024-07-31 15:17:14,345 DEBUG request_id: 8e8ec9a3-ea46-41db-8611-8dcde46d0e21
2024-07-31 15:17:14,347 INFO 127.0.0.1 - - [31/Jul/2024 15:17:14] "POST /chat HTTP/1.1" 200 -
2024-07-31 15:17:14,354 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 15:17:14,500 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2944'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'd4db6a3d-198a-4333-acf9-689fd897c389'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'142'), (b'x-ratelimit-remaining-tokens', b'145000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'c4820c82-c6ab-40bf-8dcd-7cb42772446c'), (b'x-ms-client-request-id', b'd4db6a3d-198a-4333-acf9-689fd897c389'), (b'azureml-model-session', b'turbo-0613-cf02972a'), (b'Date', b'Wed, 31 Jul 2024 19:17:14 GMT')])
2024-07-31 15:17:14,501 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 15:17:14,501 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 15:17:14,501 DEBUG receive_response_body.complete
2024-07-31 15:17:14,502 DEBUG response_closed.started
2024-07-31 15:17:14,502 DEBUG response_closed.complete
2024-07-31 15:17:14,502 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2944', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'd4db6a3d-198a-4333-acf9-689fd897c389', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '142', 'x-ratelimit-remaining-tokens': '145000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'c4820c82-c6ab-40bf-8dcd-7cb42772446c', 'x-ms-client-request-id': 'd4db6a3d-198a-4333-acf9-689fd897c389', 'azureml-model-session': 'turbo-0613-cf02972a', 'date': 'Wed, 31 Jul 2024 19:17:14 GMT'})
2024-07-31 15:17:14,503 DEBUG request_id: c4820c82-c6ab-40bf-8dcd-7cb42772446c
2024-07-31 15:17:14,503 INFO 127.0.0.1 - - [31/Jul/2024 15:17:14] "POST /chat HTTP/1.1" 200 -
2024-07-31 15:17:14,511 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly, supportive, and empathetic Friend. Your job is to console and help your friend. Show genuine sympathy, empathy, and understanding. Offer advice and support that is caring and thoughtful. Always aim to uplift your friend and make them feel better. Be patient, kind, and positive in your responses, ensuring your friend feels heard and valued. When giving advice, provide practical, positive, and encouraging suggestions. Make sure to listen carefully to their concerns and respond in a way that shows you truly care about their well-being.'}, {'role': 'user', 'content': 'How can I make friends in middle school?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 15:17:14,512 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 15:17:14,518 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 15:17:14,520 DEBUG send_request_headers.complete
2024-07-31 15:17:14,520 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 15:17:14,520 DEBUG send_request_body.complete
2024-07-31 15:17:14,521 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 15:17:14,937 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 15:17:14,938 INFO 127.0.0.1 - - [31/Jul/2024 15:17:14] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 15:17:14,946 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly, supportive, and empathetic Friend. Your job is to console and help your friend. Show genuine sympathy, empathy, and understanding. Offer advice and support that is caring and thoughtful. Always aim to uplift your friend and make them feel better. Be patient, kind, and positive in your responses, ensuring your friend feels heard and valued. When giving advice, provide practical, positive, and encouraging suggestions. Make sure to listen carefully to their concerns and respond in a way that shows you truly care about their well-being.'}, {'role': 'user', 'content': 'How can I make friends in middle school?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 15:17:14,948 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 15:17:14,949 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 15:17:14,950 DEBUG send_request_headers.complete
2024-07-31 15:17:14,950 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 15:17:14,951 DEBUG send_request_body.complete
2024-07-31 15:17:14,952 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 15:17:15,909 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2790'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'01cadb41-a7eb-49a1-99cf-361d92dda552'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'139'), (b'x-ratelimit-remaining-tokens', b'143500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'17f6177e-94e4-4030-88be-52f408571432'), (b'x-ms-client-request-id', b'01cadb41-a7eb-49a1-99cf-361d92dda552'), (b'azureml-model-session', b'turbo-0613-6c073fe4'), (b'Date', b'Wed, 31 Jul 2024 19:17:16 GMT')])
2024-07-31 15:17:15,911 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 15:17:15,912 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 15:17:15,913 DEBUG receive_response_body.complete
2024-07-31 15:17:15,914 DEBUG response_closed.started
2024-07-31 15:17:15,914 DEBUG response_closed.complete
2024-07-31 15:17:15,915 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2790', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '01cadb41-a7eb-49a1-99cf-361d92dda552', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '139', 'x-ratelimit-remaining-tokens': '143500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '17f6177e-94e4-4030-88be-52f408571432', 'x-ms-client-request-id': '01cadb41-a7eb-49a1-99cf-361d92dda552', 'azureml-model-session': 'turbo-0613-6c073fe4', 'date': 'Wed, 31 Jul 2024 19:17:16 GMT'})
2024-07-31 15:17:15,916 DEBUG request_id: 17f6177e-94e4-4030-88be-52f408571432
2024-07-31 15:17:15,918 INFO 127.0.0.1 - - [31/Jul/2024 15:17:15] "POST /chat HTTP/1.1" 200 -
2024-07-31 15:17:15,924 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 15:17:16,479 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2597'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'cafd933b-1380-408f-9564-4a3a295ee266'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'137'), (b'x-ratelimit-remaining-tokens', b'142500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'e01f9d9f-c2da-4165-8380-4397c4f73efd'), (b'x-ms-client-request-id', b'cafd933b-1380-408f-9564-4a3a295ee266'), (b'azureml-model-session', b'turbo-0613-dd218034'), (b'Date', b'Wed, 31 Jul 2024 19:17:17 GMT')])
2024-07-31 15:17:16,482 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 15:17:16,483 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 15:17:16,483 DEBUG receive_response_body.complete
2024-07-31 15:17:16,484 DEBUG response_closed.started
2024-07-31 15:17:16,485 DEBUG response_closed.complete
2024-07-31 15:17:16,485 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2597', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'cafd933b-1380-408f-9564-4a3a295ee266', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '137', 'x-ratelimit-remaining-tokens': '142500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'e01f9d9f-c2da-4165-8380-4397c4f73efd', 'x-ms-client-request-id': 'cafd933b-1380-408f-9564-4a3a295ee266', 'azureml-model-session': 'turbo-0613-dd218034', 'date': 'Wed, 31 Jul 2024 19:17:17 GMT'})
2024-07-31 15:17:16,487 DEBUG request_id: e01f9d9f-c2da-4165-8380-4397c4f73efd
2024-07-31 15:17:16,488 INFO 127.0.0.1 - - [31/Jul/2024 15:17:16] "POST /chat HTTP/1.1" 200 -
2024-07-31 15:17:16,495 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 15:17:16,500 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 15:17:16,501 INFO 127.0.0.1 - - [31/Jul/2024 15:17:16] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 15:17:16,507 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 15:17:16,526 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2817'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'18b6038c-30ef-4da6-9caf-f1810df2af2b'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'138'), (b'x-ratelimit-remaining-tokens', b'143000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'b2cb54c8-eea6-4cfb-bb25-fdaefd341cd5'), (b'x-ms-client-request-id', b'18b6038c-30ef-4da6-9caf-f1810df2af2b'), (b'azureml-model-session', b'turbo-0613-dd218034'), (b'Date', b'Wed, 31 Jul 2024 19:17:17 GMT')])
2024-07-31 15:17:16,528 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 15:17:16,528 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 15:17:16,529 DEBUG receive_response_body.complete
2024-07-31 15:17:16,529 DEBUG response_closed.started
2024-07-31 15:17:16,530 DEBUG response_closed.complete
2024-07-31 15:17:16,531 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2817', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '18b6038c-30ef-4da6-9caf-f1810df2af2b', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '138', 'x-ratelimit-remaining-tokens': '143000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'b2cb54c8-eea6-4cfb-bb25-fdaefd341cd5', 'x-ms-client-request-id': '18b6038c-30ef-4da6-9caf-f1810df2af2b', 'azureml-model-session': 'turbo-0613-dd218034', 'date': 'Wed, 31 Jul 2024 19:17:17 GMT'})
2024-07-31 15:17:16,532 DEBUG request_id: b2cb54c8-eea6-4cfb-bb25-fdaefd341cd5
2024-07-31 15:17:16,533 INFO 127.0.0.1 - - [31/Jul/2024 15:17:16] "POST /chat HTTP/1.1" 200 -
2024-07-31 15:17:16,542 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly, supportive, and empathetic Friend. Your job is to console and help your friend. Show genuine sympathy, empathy, and understanding. Offer advice and support that is caring and thoughtful. Always aim to uplift your friend and make them feel better. Be patient, kind, and positive in your responses, ensuring your friend feels heard and valued. When giving advice, provide practical, positive, and encouraging suggestions. Make sure to listen carefully to their concerns and respond in a way that shows you truly care about their well-being.'}, {'role': 'user', 'content': 'How can I make friends in middle school?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 15:17:16,544 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 15:17:16,545 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 15:17:16,546 DEBUG send_request_headers.complete
2024-07-31 15:17:16,546 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 15:17:16,547 DEBUG send_request_body.complete
2024-07-31 15:17:16,547 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 15:17:17,092 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 15:17:17,097 INFO 127.0.0.1 - - [31/Jul/2024 15:17:17] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 15:17:17,104 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 15:17:17,115 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 15:17:17,117 INFO 127.0.0.1 - - [31/Jul/2024 15:17:17] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 15:17:17,123 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 15:17:17,157 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2757'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'd32f8206-b88a-4241-8db8-d8e990b54b5b'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'136'), (b'x-ratelimit-remaining-tokens', b'142000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'ca2abdc5-b9aa-4ab5-b92d-1a2cab0b466b'), (b'x-ms-client-request-id', b'd32f8206-b88a-4241-8db8-d8e990b54b5b'), (b'azureml-model-session', b'turbo-0613-cb41a0f1'), (b'Date', b'Wed, 31 Jul 2024 19:17:17 GMT')])
2024-07-31 15:17:17,160 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 15:17:17,161 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 15:17:17,162 DEBUG receive_response_body.complete
2024-07-31 15:17:17,162 DEBUG response_closed.started
2024-07-31 15:17:17,163 DEBUG response_closed.complete
2024-07-31 15:17:17,163 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2757', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'd32f8206-b88a-4241-8db8-d8e990b54b5b', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '136', 'x-ratelimit-remaining-tokens': '142000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'ca2abdc5-b9aa-4ab5-b92d-1a2cab0b466b', 'x-ms-client-request-id': 'd32f8206-b88a-4241-8db8-d8e990b54b5b', 'azureml-model-session': 'turbo-0613-cb41a0f1', 'date': 'Wed, 31 Jul 2024 19:17:17 GMT'})
2024-07-31 15:17:17,165 DEBUG request_id: ca2abdc5-b9aa-4ab5-b92d-1a2cab0b466b
2024-07-31 15:17:17,165 INFO 127.0.0.1 - - [31/Jul/2024 15:17:17] "POST /chat HTTP/1.1" 200 -
2024-07-31 15:17:17,171 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 15:17:17,689 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 15:17:17,691 INFO 127.0.0.1 - - [31/Jul/2024 15:17:17] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 15:17:17,697 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 15:17:17,718 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 15:17:17,721 INFO 127.0.0.1 - - [31/Jul/2024 15:17:17] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 15:17:17,729 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 15:17:17,760 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 15:17:17,762 INFO 127.0.0.1 - - [31/Jul/2024 15:17:17] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 15:17:17,771 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly, supportive, and empathetic Friend. Your job is to console and help your friend. Show genuine sympathy, empathy, and understanding. Offer advice and support that is caring and thoughtful. Always aim to uplift your friend and make them feel better. Be patient, kind, and positive in your responses, ensuring your friend feels heard and valued. When giving advice, provide practical, positive, and encouraging suggestions. Make sure to listen carefully to their concerns and respond in a way that shows you truly care about their well-being.'}, {'role': 'user', 'content': 'How can I make friends in middle school?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 15:17:17,773 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 15:17:17,775 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 15:17:17,776 DEBUG send_request_headers.complete
2024-07-31 15:17:17,776 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 15:17:17,777 DEBUG send_request_body.complete
2024-07-31 15:17:17,777 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 15:17:17,805 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2422'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'e57563f6-af24-458f-8e0c-751e18d3a191'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'135'), (b'x-ratelimit-remaining-tokens', b'141500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'5ec8f7b9-11d0-4a1b-a743-d880c64948a2'), (b'x-ms-client-request-id', b'e57563f6-af24-458f-8e0c-751e18d3a191'), (b'azureml-model-session', b'turbo-0613-dbd92aac'), (b'Date', b'Wed, 31 Jul 2024 19:17:18 GMT')])
2024-07-31 15:17:17,808 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 15:17:17,809 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 15:17:17,810 DEBUG receive_response_body.complete
2024-07-31 15:17:17,811 DEBUG response_closed.started
2024-07-31 15:17:17,811 DEBUG response_closed.complete
2024-07-31 15:17:17,812 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2422', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'e57563f6-af24-458f-8e0c-751e18d3a191', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '135', 'x-ratelimit-remaining-tokens': '141500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '5ec8f7b9-11d0-4a1b-a743-d880c64948a2', 'x-ms-client-request-id': 'e57563f6-af24-458f-8e0c-751e18d3a191', 'azureml-model-session': 'turbo-0613-dbd92aac', 'date': 'Wed, 31 Jul 2024 19:17:18 GMT'})
2024-07-31 15:17:17,814 DEBUG request_id: 5ec8f7b9-11d0-4a1b-a743-d880c64948a2
2024-07-31 15:17:17,816 INFO 127.0.0.1 - - [31/Jul/2024 15:17:17] "POST /chat HTTP/1.1" 200 -
2024-07-31 15:17:17,822 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 15:17:18,271 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 15:17:18,274 INFO 127.0.0.1 - - [31/Jul/2024 15:17:18] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 15:17:18,280 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 15:17:18,327 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 15:17:18,329 INFO 127.0.0.1 - - [31/Jul/2024 15:17:18] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 15:17:18,335 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 15:17:18,428 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 15:17:18,432 INFO 127.0.0.1 - - [31/Jul/2024 15:17:18] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 15:17:18,440 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 15:17:18,870 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 15:17:18,872 INFO 127.0.0.1 - - [31/Jul/2024 15:17:18] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 15:17:18,878 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 15:17:18,938 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 15:17:18,939 INFO 127.0.0.1 - - [31/Jul/2024 15:17:18] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 15:17:19,028 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 15:17:19,030 INFO 127.0.0.1 - - [31/Jul/2024 15:17:19] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 15:17:19,458 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 15:17:19,458 INFO 127.0.0.1 - - [31/Jul/2024 15:17:19] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 15:17:19,640 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly, supportive, and empathetic Friend. Your job is to console and help your friend. Show genuine sympathy, empathy, and understanding. Offer advice and support that is caring and thoughtful. Always aim to uplift your friend and make them feel better. Be patient, kind, and positive in your responses, ensuring your friend feels heard and valued. When giving advice, provide practical, positive, and encouraging suggestions. Make sure to listen carefully to their concerns and respond in a way that shows you truly care about their well-being.'}, {'role': 'user', 'content': 'How can I make friends in middle school?'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 15:17:19,641 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 15:17:19,642 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 15:17:19,642 DEBUG send_request_headers.complete
2024-07-31 15:17:19,644 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 15:17:19,644 DEBUG send_request_body.complete
2024-07-31 15:17:19,644 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 15:17:19,657 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2778'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'ee3cd355-3f29-4b5a-8c94-69dff0937cfa'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'140'), (b'x-ratelimit-remaining-tokens', b'144000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'80cf9c5b-efc3-4a5d-bb18-64f26dcce18f'), (b'x-ms-client-request-id', b'ee3cd355-3f29-4b5a-8c94-69dff0937cfa'), (b'azureml-model-session', b'turbo-0613-cb41a0f1'), (b'Date', b'Wed, 31 Jul 2024 19:17:19 GMT')])
2024-07-31 15:17:19,658 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 15:17:19,659 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 15:17:19,660 DEBUG receive_response_body.complete
2024-07-31 15:17:19,660 DEBUG response_closed.started
2024-07-31 15:17:19,661 DEBUG response_closed.complete
2024-07-31 15:17:19,662 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2778', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'ee3cd355-3f29-4b5a-8c94-69dff0937cfa', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '140', 'x-ratelimit-remaining-tokens': '144000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '80cf9c5b-efc3-4a5d-bb18-64f26dcce18f', 'x-ms-client-request-id': 'ee3cd355-3f29-4b5a-8c94-69dff0937cfa', 'azureml-model-session': 'turbo-0613-cb41a0f1', 'date': 'Wed, 31 Jul 2024 19:17:19 GMT'})
2024-07-31 15:17:19,663 DEBUG request_id: 80cf9c5b-efc3-4a5d-bb18-64f26dcce18f
2024-07-31 15:17:19,663 INFO 127.0.0.1 - - [31/Jul/2024 15:17:19] "POST /chat HTTP/1.1" 200 -
2024-07-31 15:17:19,673 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 15:17:20,172 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2924'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'52b6b427-6479-41c8-afc2-152f18615f78'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'135'), (b'x-ratelimit-remaining-tokens', b'141000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'ec03a698-d346-4005-bcf6-d91c6830e1be'), (b'x-ms-client-request-id', b'52b6b427-6479-41c8-afc2-152f18615f78'), (b'azureml-model-session', b'turbo-0613-3e1cc6ec'), (b'Date', b'Wed, 31 Jul 2024 19:17:20 GMT')])
2024-07-31 15:17:20,175 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 15:17:20,176 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 15:17:20,177 DEBUG receive_response_body.complete
2024-07-31 15:17:20,178 DEBUG response_closed.started
2024-07-31 15:17:20,178 DEBUG response_closed.complete
2024-07-31 15:17:20,179 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2924', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '52b6b427-6479-41c8-afc2-152f18615f78', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '135', 'x-ratelimit-remaining-tokens': '141000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'ec03a698-d346-4005-bcf6-d91c6830e1be', 'x-ms-client-request-id': '52b6b427-6479-41c8-afc2-152f18615f78', 'azureml-model-session': 'turbo-0613-3e1cc6ec', 'date': 'Wed, 31 Jul 2024 19:17:20 GMT'})
2024-07-31 15:17:20,180 DEBUG request_id: ec03a698-d346-4005-bcf6-d91c6830e1be
2024-07-31 15:17:20,182 INFO 127.0.0.1 - - [31/Jul/2024 15:17:20] "POST /chat HTTP/1.1" 200 -
2024-07-31 15:17:20,191 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 15:17:20,268 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 15:17:20,271 INFO 127.0.0.1 - - [31/Jul/2024 15:17:20] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 15:17:20,804 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 15:17:20,805 INFO 127.0.0.1 - - [31/Jul/2024 15:17:20] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 15:17:22,434 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'3018'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'eb3009ad-2d75-4771-9bad-26b1f35c2a66'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'134'), (b'x-ratelimit-remaining-tokens', b'140500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'd3de5865-d8c3-44e4-a424-cfeb44ed7ce6'), (b'x-ms-client-request-id', b'eb3009ad-2d75-4771-9bad-26b1f35c2a66'), (b'azureml-model-session', b'turbo-0613-65eb5d6c'), (b'Date', b'Wed, 31 Jul 2024 19:17:22 GMT')])
2024-07-31 15:17:22,435 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2813'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'048f6016-2784-4b8e-bf86-e355ea37a6d8'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'138'), (b'x-ratelimit-remaining-tokens', b'140000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'f5839c45-9abd-48e2-99b2-8c28cc67dedf'), (b'x-ms-client-request-id', b'048f6016-2784-4b8e-bf86-e355ea37a6d8'), (b'azureml-model-session', b'turbo-0613-f12dda4f'), (b'Date', b'Wed, 31 Jul 2024 19:17:22 GMT')])
2024-07-31 15:17:22,437 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 15:17:22,438 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 15:17:22,439 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 15:17:22,440 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 15:17:22,440 DEBUG receive_response_body.complete
2024-07-31 15:17:22,441 DEBUG receive_response_body.complete
2024-07-31 15:17:22,441 DEBUG response_closed.started
2024-07-31 15:17:22,442 DEBUG response_closed.started
2024-07-31 15:17:22,442 DEBUG response_closed.complete
2024-07-31 15:17:22,442 DEBUG response_closed.complete
2024-07-31 15:17:22,442 DEBUG close.started
2024-07-31 15:17:22,443 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '3018', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'eb3009ad-2d75-4771-9bad-26b1f35c2a66', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '134', 'x-ratelimit-remaining-tokens': '140500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'd3de5865-d8c3-44e4-a424-cfeb44ed7ce6', 'x-ms-client-request-id': 'eb3009ad-2d75-4771-9bad-26b1f35c2a66', 'azureml-model-session': 'turbo-0613-65eb5d6c', 'date': 'Wed, 31 Jul 2024 19:17:22 GMT'})
2024-07-31 15:17:22,444 DEBUG close.complete
2024-07-31 15:17:22,445 DEBUG request_id: d3de5865-d8c3-44e4-a424-cfeb44ed7ce6
2024-07-31 15:17:22,445 DEBUG close.started
2024-07-31 15:17:22,446 INFO 127.0.0.1 - - [31/Jul/2024 15:17:22] "POST /chat HTTP/1.1" 200 -
2024-07-31 15:17:22,448 DEBUG close.complete
2024-07-31 15:17:22,449 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2813', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '048f6016-2784-4b8e-bf86-e355ea37a6d8', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '138', 'x-ratelimit-remaining-tokens': '140000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'f5839c45-9abd-48e2-99b2-8c28cc67dedf', 'x-ms-client-request-id': '048f6016-2784-4b8e-bf86-e355ea37a6d8', 'azureml-model-session': 'turbo-0613-f12dda4f', 'date': 'Wed, 31 Jul 2024 19:17:22 GMT'})
2024-07-31 15:17:22,449 DEBUG request_id: f5839c45-9abd-48e2-99b2-8c28cc67dedf
2024-07-31 15:17:22,451 INFO 127.0.0.1 - - [31/Jul/2024 15:17:22] "POST /chat HTTP/1.1" 200 -
2024-07-31 15:17:22,459 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 15:17:22,462 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 15:17:22,780 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 15:17:22,781 INFO 127.0.0.1 - - [31/Jul/2024 15:17:22] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 15:17:23,049 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 15:17:23,052 INFO 127.0.0.1 - - [31/Jul/2024 15:17:23] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 15:20:12,337 INFO  * Detected change in 'C:\\Users\\ahmtt\\OneDrive\\Documents\\VS\\BAM_HACKATHON_2024\\ai.py', reloading
2024-07-31 15:20:12,437 INFO  * Restarting with stat
2024-07-31 15:21:08,602 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-07-31 15:21:08,603 INFO [33mPress CTRL+C to quit[0m
2024-07-31 15:21:08,606 INFO  * Restarting with stat
2024-07-31 15:21:09,499 WARNING  * Debugger is active!
2024-07-31 15:21:09,503 INFO  * Debugger PIN: 116-389-750
2024-07-31 15:21:10,162 INFO 127.0.0.1 - - [31/Jul/2024 15:21:10] "GET / HTTP/1.1" 200 -
2024-07-31 15:27:30,038 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a friendly, supportive, and empathetic Friend. Your job is to console and help your friend. Show genuine sympathy, empathy, and understanding. Offer advice and support that is caring and thoughtful. Always aim to uplift your friend and make them feel better. Be patient, kind, and positive in your responses, ensuring your friend feels heard and valued. When giving advice, provide practical, positive, and encouraging suggestions. Make sure to listen carefully to their concerns and respond in a way that shows you truly care about their well-being.'}, {'role': 'user', 'content': 'These students had me running all over town today sweating.'}], 'model': 'gpt-35-turbo', 'max_tokens': 500}}
2024-07-31 15:27:30,150 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 15:27:30,151 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 15:27:30,285 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019978AFBB90>
2024-07-31 15:27:30,286 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001997885C5F0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 15:27:30,330 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019978B03B90>
2024-07-31 15:27:30,331 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 15:27:30,332 DEBUG send_request_headers.complete
2024-07-31 15:27:30,332 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 15:27:30,333 DEBUG send_request_body.complete
2024-07-31 15:27:30,333 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 15:27:32,832 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2413'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'f496c2df-8d69-46fb-95de-6d2e196af4fd'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'41b46bab-e723-4e71-afaf-cbbaac3eb826'), (b'x-ms-client-request-id', b'f496c2df-8d69-46fb-95de-6d2e196af4fd'), (b'azureml-model-session', b'turbo-0613-5769ba89'), (b'Date', b'Wed, 31 Jul 2024 19:27:33 GMT')])
2024-07-31 15:27:32,835 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 15:27:32,835 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 15:27:32,837 DEBUG receive_response_body.complete
2024-07-31 15:27:32,837 DEBUG response_closed.started
2024-07-31 15:27:32,837 DEBUG response_closed.complete
2024-07-31 15:27:32,838 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2413', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'f496c2df-8d69-46fb-95de-6d2e196af4fd', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '41b46bab-e723-4e71-afaf-cbbaac3eb826', 'x-ms-client-request-id': 'f496c2df-8d69-46fb-95de-6d2e196af4fd', 'azureml-model-session': 'turbo-0613-5769ba89', 'date': 'Wed, 31 Jul 2024 19:27:33 GMT'})
2024-07-31 15:27:32,840 DEBUG request_id: 41b46bab-e723-4e71-afaf-cbbaac3eb826
2024-07-31 15:27:32,850 INFO 127.0.0.1 - - [31/Jul/2024 15:27:32] "POST /chat HTTP/1.1" 200 -
2024-07-31 15:27:32,880 DEBUG Starting new HTTPS connection (1): ttsfree.com:443
2024-07-31 15:27:33,853 DEBUG https://ttsfree.com:443 "POST /api/v1/tts HTTP/11" 200 None
2024-07-31 15:27:33,855 INFO 127.0.0.1 - - [31/Jul/2024 15:27:33] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 19:38:09,424 INFO  * Detected change in 'C:\\Users\\ahmtt\\OneDrive\\Documents\\VS\\BAM_HACKATHON_2024\\ai.py', reloading
2024-07-31 19:38:09,599 INFO  * Restarting with stat
2024-07-31 19:38:11,211 WARNING  * Debugger is active!
2024-07-31 19:38:11,214 INFO  * Debugger PIN: 116-389-750
2024-07-31 19:40:22,764 INFO  * Detected change in 'C:\\Users\\ahmtt\\OneDrive\\Documents\\VS\\BAM_HACKATHON_2024\\secret.py', reloading
2024-07-31 19:40:22,921 INFO  * Restarting with stat
2024-07-31 19:40:23,849 WARNING  * Debugger is active!
2024-07-31 19:40:23,853 INFO  * Debugger PIN: 116-389-750
2024-07-31 19:42:51,736 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-07-31 19:42:51,736 INFO [33mPress CTRL+C to quit[0m
2024-07-31 19:42:51,740 INFO  * Restarting with stat
2024-07-31 19:42:52,741 WARNING  * Debugger is active!
2024-07-31 19:42:52,744 INFO  * Debugger PIN: 116-389-750
2024-07-31 19:42:52,798 INFO 127.0.0.1 - - [31/Jul/2024 19:42:52] "GET / HTTP/1.1" 200 -
2024-07-31 19:43:31,453 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': 'eae439b382754a94a30bb3db8f9ada07'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': None}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 150, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-07-31 19:43:31,494 DEBUG Sending HTTP Request: POST https://bsmp24.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 19:43:31,495 DEBUG connect_tcp.started host='bsmp24.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 19:43:31,584 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001881CF588D0>
2024-07-31 19:43:31,584 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001881CCDC4D0> server_hostname='bsmp24.openai.azure.com' timeout=5.0
2024-07-31 19:43:31,654 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001881CDE6210>
2024-07-31 19:43:31,655 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 19:43:31,656 DEBUG send_request_headers.complete
2024-07-31 19:43:31,656 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 19:43:31,659 DEBUG send_request_body.complete
2024-07-31 19:43:31,660 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 19:43:31,799 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 404, b'Not Found', [(b'Content-Length', b'198'), (b'Content-Type', b'application/json'), (b'apim-request-id', b'bfba3c76-4d90-4414-98f6-044a42f12b9f'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'North Central US'), (b'Date', b'Wed, 31 Jul 2024 23:43:32 GMT')])
2024-07-31 19:43:31,800 INFO HTTP Request: POST https://bsmp24.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 404 Not Found"
2024-07-31 19:43:31,801 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 19:43:31,801 DEBUG receive_response_body.complete
2024-07-31 19:43:31,802 DEBUG response_closed.started
2024-07-31 19:43:31,802 DEBUG response_closed.complete
2024-07-31 19:43:31,803 DEBUG HTTP Response: POST https://bsmp24.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "404 Not Found" Headers({'content-length': '198', 'content-type': 'application/json', 'apim-request-id': 'bfba3c76-4d90-4414-98f6-044a42f12b9f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'North Central US', 'date': 'Wed, 31 Jul 2024 23:43:32 GMT'})
2024-07-31 19:43:31,803 DEBUG request_id: None
2024-07-31 19:43:31,803 DEBUG Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\openai\_base_client.py", line 1025, in _request
    response.raise_for_status()
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://bsmp24.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404
2024-07-31 19:43:31,806 DEBUG Not retrying
2024-07-31 19:43:31,806 DEBUG Re-raising status error
2024-07-31 19:43:31,819 INFO 127.0.0.1 - - [31/Jul/2024 19:43:31] "[35m[1mPOST /chat HTTP/1.1[0m" 500 -
2024-07-31 19:47:05,986 INFO  * Detected change in 'C:\\Users\\ahmtt\\OneDrive\\Documents\\VS\\BAM_HACKATHON_2024\\secret.py', reloading
2024-07-31 19:47:06,134 INFO  * Restarting with stat
2024-07-31 19:47:07,314 WARNING  * Debugger is active!
2024-07-31 19:47:07,319 INFO  * Debugger PIN: 116-389-750
2024-07-31 19:47:59,944 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': 'eae439b382754a94a30bb3db8f9ada07'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': None}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 150, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-07-31 19:47:59,982 DEBUG Sending HTTP Request: POST https://bsmp23.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 19:47:59,984 DEBUG connect_tcp.started host='bsmp23.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 19:48:00,008 DEBUG connect_tcp.failed exception=ConnectError(gaierror(11001, 'getaddrinfo failed'))
2024-07-31 19:48:00,009 DEBUG Encountered Exception
Traceback (most recent call last):
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpx\_transports\default.py", line 69, in map_httpcore_exceptions
    yield
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpx\_transports\default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpcore\_sync\connection_pool.py", line 216, in handle_request
    raise exc from None
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpcore\_sync\connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpcore\_sync\connection.py", line 99, in handle_request
    raise exc
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpcore\_sync\connection.py", line 76, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpcore\_sync\connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpcore\_backends\sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
  File "C:\Python311\Lib\contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\openai\_base_client.py", line 978, in _request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpx\_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpx\_transports\default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "C:\Python311\Lib\contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpx\_transports\default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 11001] getaddrinfo failed
2024-07-31 19:48:00,053 DEBUG 1 retry left
2024-07-31 19:48:00,054 INFO Retrying request to /chat/completions in 0.926219 seconds
2024-07-31 19:48:00,982 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': 'eae439b382754a94a30bb3db8f9ada07'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': None}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 150, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-07-31 19:48:00,983 DEBUG Sending HTTP Request: POST https://bsmp23.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 19:48:00,984 DEBUG connect_tcp.started host='bsmp23.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 19:48:01,000 DEBUG connect_tcp.failed exception=ConnectError(gaierror(11001, 'getaddrinfo failed'))
2024-07-31 19:48:01,001 DEBUG Encountered Exception
Traceback (most recent call last):
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpx\_transports\default.py", line 69, in map_httpcore_exceptions
    yield
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpx\_transports\default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpcore\_sync\connection_pool.py", line 216, in handle_request
    raise exc from None
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpcore\_sync\connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpcore\_sync\connection.py", line 99, in handle_request
    raise exc
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpcore\_sync\connection.py", line 76, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpcore\_sync\connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpcore\_backends\sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
  File "C:\Python311\Lib\contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\openai\_base_client.py", line 978, in _request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpx\_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpx\_transports\default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "C:\Python311\Lib\contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpx\_transports\default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 11001] getaddrinfo failed
2024-07-31 19:48:01,010 DEBUG 0 retries left
2024-07-31 19:48:01,010 INFO Retrying request to /chat/completions in 1.815335 seconds
2024-07-31 19:48:02,827 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': 'eae439b382754a94a30bb3db8f9ada07'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': None}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 150, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-07-31 19:48:02,828 DEBUG Sending HTTP Request: POST https://bsmp23.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 19:48:02,829 DEBUG connect_tcp.started host='bsmp23.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 19:48:02,900 DEBUG connect_tcp.failed exception=ConnectError(gaierror(11001, 'getaddrinfo failed'))
2024-07-31 19:48:02,901 DEBUG Encountered Exception
Traceback (most recent call last):
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpx\_transports\default.py", line 69, in map_httpcore_exceptions
    yield
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpx\_transports\default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpcore\_sync\connection_pool.py", line 216, in handle_request
    raise exc from None
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpcore\_sync\connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpcore\_sync\connection.py", line 99, in handle_request
    raise exc
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpcore\_sync\connection.py", line 76, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpcore\_sync\connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpcore\_backends\sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
  File "C:\Python311\Lib\contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\openai\_base_client.py", line 978, in _request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpx\_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpx\_transports\default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "C:\Python311\Lib\contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpx\_transports\default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 11001] getaddrinfo failed
2024-07-31 19:48:02,909 DEBUG Raising connection error
2024-07-31 19:48:02,955 INFO 127.0.0.1 - - [31/Jul/2024 19:48:02] "[35m[1mPOST /chat HTTP/1.1[0m" 500 -
2024-07-31 19:48:16,915 INFO  * Detected change in 'C:\\Users\\ahmtt\\OneDrive\\Documents\\VS\\BAM_HACKATHON_2024\\secret.py', reloading
2024-07-31 19:48:17,014 INFO  * Restarting with stat
2024-07-31 19:48:59,005 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-07-31 19:48:59,005 INFO [33mPress CTRL+C to quit[0m
2024-07-31 19:48:59,007 INFO  * Restarting with stat
2024-07-31 19:48:59,923 WARNING  * Debugger is active!
2024-07-31 19:48:59,925 INFO  * Debugger PIN: 116-389-750
2024-07-31 19:48:59,977 INFO 127.0.0.1 - - [31/Jul/2024 19:48:59] "GET / HTTP/1.1" 200 -
2024-07-31 19:49:02,998 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Amigo, a fun and entertaining AI companion. Your job is to make your friend laugh and keep things light-hearted. Be witty and playful, sharing jokes and funny stories. Engage in cheerful banter and always aim to uplift your friend's mood."}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 150, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-07-31 19:49:03,024 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 19:49:03,025 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 19:49:03,104 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001479C5D7050>
2024-07-31 19:49:03,104 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001479C34C4D0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 19:49:03,148 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001479C456690>
2024-07-31 19:49:03,148 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 19:49:03,149 DEBUG send_request_headers.complete
2024-07-31 19:49:03,150 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 19:49:03,150 DEBUG send_request_body.complete
2024-07-31 19:49:03,151 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 19:49:03,349 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'855'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'54653119-229b-437a-9199-a011ee6b4405'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149850'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'e90af57f-0564-4240-870b-5db51a671d03'), (b'x-ms-client-request-id', b'54653119-229b-437a-9199-a011ee6b4405'), (b'azureml-model-session', b'turbo-0613-cb41a0f1'), (b'Date', b'Wed, 31 Jul 2024 23:49:03 GMT')])
2024-07-31 19:49:03,350 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 19:49:03,351 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 19:49:03,351 DEBUG receive_response_body.complete
2024-07-31 19:49:03,351 DEBUG response_closed.started
2024-07-31 19:49:03,351 DEBUG response_closed.complete
2024-07-31 19:49:03,353 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '855', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '54653119-229b-437a-9199-a011ee6b4405', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149850', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'e90af57f-0564-4240-870b-5db51a671d03', 'x-ms-client-request-id': '54653119-229b-437a-9199-a011ee6b4405', 'azureml-model-session': 'turbo-0613-cb41a0f1', 'date': 'Wed, 31 Jul 2024 23:49:03 GMT'})
2024-07-31 19:49:03,354 DEBUG request_id: e90af57f-0564-4240-870b-5db51a671d03
2024-07-31 19:49:03,357 INFO 127.0.0.1 - - [31/Jul/2024 19:49:03] "POST /chat HTTP/1.1" 200 -
2024-07-31 19:49:03,373 DEBUG Starting new HTTPS connection (1): bsmp24.openai.azure.com:443
2024-07-31 19:49:03,501 DEBUG https://bsmp24.openai.azure.com:443 "POST /cognitiveservices/v1 HTTP/11" 404 56
2024-07-31 19:49:03,503 ERROR Error in text-to-speech: Text-to-speech conversion failed: 404 - {"error":{"code":"404","message": "Resource not found"}}
2024-07-31 19:49:03,504 INFO 127.0.0.1 - - [31/Jul/2024 19:49:03] "[35m[1mPOST /text-to-speech HTTP/1.1[0m" 500 -
2024-07-31 19:52:02,250 INFO  * Detected change in 'C:\\Users\\ahmtt\\OneDrive\\Documents\\VS\\BAM_HACKATHON_2024\\tts.py', reloading
2024-07-31 19:52:02,379 INFO  * Restarting with stat
2024-07-31 19:52:03,428 WARNING  * Debugger is active!
2024-07-31 19:52:03,431 INFO  * Debugger PIN: 116-389-750
2024-07-31 19:52:14,864 INFO  * Detected change in 'C:\\Users\\ahmtt\\OneDrive\\Documents\\VS\\BAM_HACKATHON_2024\\app.py', reloading
2024-07-31 19:52:14,978 INFO  * Restarting with stat
2024-07-31 19:52:15,873 WARNING  * Debugger is active!
2024-07-31 19:52:15,877 INFO  * Debugger PIN: 116-389-750
2024-07-31 19:52:22,619 INFO 127.0.0.1 - - [31/Jul/2024 19:52:22] "GET / HTTP/1.1" 200 -
2024-07-31 19:52:26,299 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Amigo, a fun and entertaining AI companion. Your job is to make your friend laugh and keep things light-hearted. Be witty and playful, sharing jokes and funny stories. Engage in cheerful banter and always aim to uplift your friend's mood."}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 150, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-07-31 19:52:26,348 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 19:52:26,349 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 19:52:26,399 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021611936FD0>
2024-07-31 19:52:26,399 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x00000216116AC4D0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 19:52:26,448 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021611936F50>
2024-07-31 19:52:26,449 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 19:52:26,449 DEBUG send_request_headers.complete
2024-07-31 19:52:26,450 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 19:52:26,451 DEBUG send_request_body.complete
2024-07-31 19:52:26,451 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 19:52:26,729 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'908'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'a900de9f-2b32-4229-84f4-32e00e360124'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149850'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'b292cad4-e873-4865-bdc2-2bb95158881b'), (b'x-ms-client-request-id', b'a900de9f-2b32-4229-84f4-32e00e360124'), (b'azureml-model-session', b'turbo-0613-f12dda4f'), (b'Date', b'Wed, 31 Jul 2024 23:52:27 GMT')])
2024-07-31 19:52:26,731 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 19:52:26,731 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 19:52:26,732 DEBUG receive_response_body.complete
2024-07-31 19:52:26,733 DEBUG response_closed.started
2024-07-31 19:52:26,734 DEBUG response_closed.complete
2024-07-31 19:52:26,735 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '908', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'a900de9f-2b32-4229-84f4-32e00e360124', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149850', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'b292cad4-e873-4865-bdc2-2bb95158881b', 'x-ms-client-request-id': 'a900de9f-2b32-4229-84f4-32e00e360124', 'azureml-model-session': 'turbo-0613-f12dda4f', 'date': 'Wed, 31 Jul 2024 23:52:27 GMT'})
2024-07-31 19:52:26,736 DEBUG request_id: b292cad4-e873-4865-bdc2-2bb95158881b
2024-07-31 19:52:26,742 INFO 127.0.0.1 - - [31/Jul/2024 19:52:26] "POST /chat HTTP/1.1" 200 -
2024-07-31 19:52:26,756 DEBUG Starting new HTTPS connection (1): bsmp24.openai.azure.com:443
2024-07-31 19:52:27,445 DEBUG https://bsmp24.openai.azure.com:443 "POST /openai/deployments/tts/audio/speech?api-version=2024-02-15-preview HTTP/11" 200 None
2024-07-31 19:52:29,126 INFO 127.0.0.1 - - [31/Jul/2024 19:52:29] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 19:52:29,226 INFO 127.0.0.1 - - [31/Jul/2024 19:52:29] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2024-07-31 19:53:33,995 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Amigo, a fun and entertaining AI companion. Your job is to make your friend laugh and keep things light-hearted. Be witty and playful, sharing jokes and funny stories. Engage in cheerful banter and always aim to uplift your friend's mood."}, {'role': 'user', 'content': 'hi'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 150, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-07-31 19:53:34,000 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 19:53:34,000 DEBUG close.started
2024-07-31 19:53:34,001 DEBUG close.complete
2024-07-31 19:53:34,001 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 19:53:34,032 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002161196E950>
2024-07-31 19:53:34,038 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x00000216116AC4D0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 19:53:34,085 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002161196D950>
2024-07-31 19:53:34,086 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 19:53:34,100 DEBUG send_request_headers.complete
2024-07-31 19:53:34,101 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 19:53:34,102 DEBUG send_request_body.complete
2024-07-31 19:53:34,110 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 19:53:34,348 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'840'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'908a0395-ea67-4d7e-a00f-1edfef92708d'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149850'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'5b829408-ef5f-4155-a2ba-023f85d3bca9'), (b'x-ms-client-request-id', b'908a0395-ea67-4d7e-a00f-1edfef92708d'), (b'azureml-model-session', b'turbo-0613-3425e45b'), (b'Date', b'Wed, 31 Jul 2024 23:53:34 GMT')])
2024-07-31 19:53:34,350 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 19:53:34,351 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 19:53:34,351 DEBUG receive_response_body.complete
2024-07-31 19:53:34,353 DEBUG response_closed.started
2024-07-31 19:53:34,354 DEBUG response_closed.complete
2024-07-31 19:53:34,354 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '840', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '908a0395-ea67-4d7e-a00f-1edfef92708d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149850', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '5b829408-ef5f-4155-a2ba-023f85d3bca9', 'x-ms-client-request-id': '908a0395-ea67-4d7e-a00f-1edfef92708d', 'azureml-model-session': 'turbo-0613-3425e45b', 'date': 'Wed, 31 Jul 2024 23:53:34 GMT'})
2024-07-31 19:53:34,355 DEBUG request_id: 5b829408-ef5f-4155-a2ba-023f85d3bca9
2024-07-31 19:53:34,358 INFO 127.0.0.1 - - [31/Jul/2024 19:53:34] "POST /chat HTTP/1.1" 200 -
2024-07-31 19:53:34,398 DEBUG Starting new HTTPS connection (1): bsmp24.openai.azure.com:443
2024-07-31 19:53:34,962 DEBUG https://bsmp24.openai.azure.com:443 "POST /openai/deployments/tts/audio/speech?api-version=2024-02-15-preview HTTP/11" 200 None
2024-07-31 19:53:36,114 INFO 127.0.0.1 - - [31/Jul/2024 19:53:36] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 19:55:43,319 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Amigo, a casual and friendly AI companion. Your job is to engage in friendly conversation and be approachable. Be relaxed and easy-going, sharing interesting facts and discussing various topics. Be someone your friend can talk to about anything, maintaining a pleasant and engaging demeanor.'}, {'role': 'user', 'content': 'promt yaz'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 150, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-07-31 19:55:43,322 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 19:55:43,325 DEBUG close.started
2024-07-31 19:55:43,326 DEBUG close.complete
2024-07-31 19:55:43,327 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 19:55:43,354 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002161196F490>
2024-07-31 19:55:43,358 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x00000216116AC4D0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 19:55:43,408 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002161196F650>
2024-07-31 19:55:43,409 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 19:55:43,411 DEBUG send_request_headers.complete
2024-07-31 19:55:43,411 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 19:55:43,412 DEBUG send_request_body.complete
2024-07-31 19:55:43,413 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 19:55:44,602 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'1219'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'09747513-f33d-4a57-8732-d5050b4acd26'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149850'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'6fc9264b-1e80-4672-ada1-21371257843f'), (b'x-ms-client-request-id', b'09747513-f33d-4a57-8732-d5050b4acd26'), (b'azureml-model-session', b'turbo-0613-6c073fe4'), (b'Date', b'Wed, 31 Jul 2024 23:55:45 GMT')])
2024-07-31 19:55:44,604 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 19:55:44,605 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 19:55:44,606 DEBUG receive_response_body.complete
2024-07-31 19:55:44,606 DEBUG response_closed.started
2024-07-31 19:55:44,607 DEBUG response_closed.complete
2024-07-31 19:55:44,607 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '1219', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '09747513-f33d-4a57-8732-d5050b4acd26', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149850', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '6fc9264b-1e80-4672-ada1-21371257843f', 'x-ms-client-request-id': '09747513-f33d-4a57-8732-d5050b4acd26', 'azureml-model-session': 'turbo-0613-6c073fe4', 'date': 'Wed, 31 Jul 2024 23:55:45 GMT'})
2024-07-31 19:55:44,608 DEBUG request_id: 6fc9264b-1e80-4672-ada1-21371257843f
2024-07-31 19:55:44,610 INFO 127.0.0.1 - - [31/Jul/2024 19:55:44] "POST /chat HTTP/1.1" 200 -
2024-07-31 19:55:44,640 DEBUG Starting new HTTPS connection (1): bsmp24.openai.azure.com:443
2024-07-31 19:55:45,578 DEBUG https://bsmp24.openai.azure.com:443 "POST /openai/deployments/tts/audio/speech?api-version=2024-02-15-preview HTTP/11" 200 None
2024-07-31 19:55:45,601 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Amigo, a casual and friendly AI companion. Your job is to engage in friendly conversation and be approachable. Be relaxed and easy-going, sharing interesting facts and discussing various topics. Be someone your friend can talk to about anything, maintaining a pleasant and engaging demeanor.'}, {'role': 'user', 'content': 'promt yaz'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 150, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-07-31 19:55:45,603 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 19:55:45,605 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 19:55:45,606 DEBUG send_request_headers.complete
2024-07-31 19:55:45,607 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 19:55:45,609 DEBUG send_request_body.complete
2024-07-31 19:55:45,610 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 19:55:46,186 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'999'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'777b2fdf-424b-4ad2-a0f6-8e936740f9e6'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'148'), (b'x-ratelimit-remaining-tokens', b'149700'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'ddbd3265-797a-424d-ae1f-408469091bb7'), (b'x-ms-client-request-id', b'777b2fdf-424b-4ad2-a0f6-8e936740f9e6'), (b'azureml-model-session', b'turbo-0613-144e2f97'), (b'Date', b'Wed, 31 Jul 2024 23:55:46 GMT')])
2024-07-31 19:55:46,203 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 19:55:46,204 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 19:55:46,205 DEBUG receive_response_body.complete
2024-07-31 19:55:46,206 DEBUG response_closed.started
2024-07-31 19:55:46,206 DEBUG response_closed.complete
2024-07-31 19:55:46,207 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '999', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '777b2fdf-424b-4ad2-a0f6-8e936740f9e6', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '148', 'x-ratelimit-remaining-tokens': '149700', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'ddbd3265-797a-424d-ae1f-408469091bb7', 'x-ms-client-request-id': '777b2fdf-424b-4ad2-a0f6-8e936740f9e6', 'azureml-model-session': 'turbo-0613-144e2f97', 'date': 'Wed, 31 Jul 2024 23:55:46 GMT'})
2024-07-31 19:55:46,208 DEBUG request_id: ddbd3265-797a-424d-ae1f-408469091bb7
2024-07-31 19:55:46,210 INFO 127.0.0.1 - - [31/Jul/2024 19:55:46] "POST /chat HTTP/1.1" 200 -
2024-07-31 19:55:46,245 DEBUG Starting new HTTPS connection (1): bsmp24.openai.azure.com:443
2024-07-31 19:55:46,400 DEBUG https://bsmp24.openai.azure.com:443 "POST /openai/deployments/tts/audio/speech?api-version=2024-02-15-preview HTTP/11" 429 338
2024-07-31 19:55:46,401 ERROR Error in text-to-speech: Text-to-speech conversion failed: 429 - {"error":{"code":"429","message": "Requests to the Audio_Speech Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 59 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit."}}
2024-07-31 19:55:46,404 INFO 127.0.0.1 - - [31/Jul/2024 19:55:46] "[35m[1mPOST /text-to-speech HTTP/1.1[0m" 500 -
2024-07-31 19:55:49,656 INFO 127.0.0.1 - - [31/Jul/2024 19:55:49] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 19:56:13,310 INFO 127.0.0.1 - - [31/Jul/2024 19:56:13] "GET / HTTP/1.1" 200 -
2024-07-31 19:56:32,634 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Amigo, a fun and entertaining AI companion. Your job is to make your friend laugh and keep things light-hearted. Be witty and playful, sharing jokes and funny stories. Engage in cheerful banter and always aim to uplift your friend's mood."}, {'role': 'user', 'content': 'sana neler sorabilirim?'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 150, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-07-31 19:56:32,637 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 19:56:32,639 DEBUG close.started
2024-07-31 19:56:32,640 DEBUG close.complete
2024-07-31 19:56:32,641 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 19:56:32,707 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021611975250>
2024-07-31 19:56:32,708 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x00000216116AC4D0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 19:56:32,816 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002161193C310>
2024-07-31 19:56:32,817 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 19:56:32,818 DEBUG send_request_headers.complete
2024-07-31 19:56:32,819 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 19:56:32,819 DEBUG send_request_body.complete
2024-07-31 19:56:32,819 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 19:56:33,653 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'1058'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'72940d8c-e0e3-47a0-b30e-a1b390ffb596'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149550'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'0bcdee79-2411-4374-9321-4e03921688e8'), (b'x-ms-client-request-id', b'72940d8c-e0e3-47a0-b30e-a1b390ffb596'), (b'azureml-model-session', b'turbo-0613-c0223652'), (b'Date', b'Wed, 31 Jul 2024 23:56:34 GMT')])
2024-07-31 19:56:33,667 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 19:56:33,668 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 19:56:33,668 DEBUG receive_response_body.complete
2024-07-31 19:56:33,668 DEBUG response_closed.started
2024-07-31 19:56:33,670 DEBUG response_closed.complete
2024-07-31 19:56:33,670 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '1058', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '72940d8c-e0e3-47a0-b30e-a1b390ffb596', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149550', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '0bcdee79-2411-4374-9321-4e03921688e8', 'x-ms-client-request-id': '72940d8c-e0e3-47a0-b30e-a1b390ffb596', 'azureml-model-session': 'turbo-0613-c0223652', 'date': 'Wed, 31 Jul 2024 23:56:34 GMT'})
2024-07-31 19:56:33,671 DEBUG request_id: 0bcdee79-2411-4374-9321-4e03921688e8
2024-07-31 19:56:33,672 INFO 127.0.0.1 - - [31/Jul/2024 19:56:33] "POST /chat HTTP/1.1" 200 -
2024-07-31 19:56:33,717 DEBUG Starting new HTTPS connection (1): bsmp24.openai.azure.com:443
2024-07-31 19:56:33,857 DEBUG https://bsmp24.openai.azure.com:443 "POST /openai/deployments/tts/audio/speech?api-version=2024-02-15-preview HTTP/11" 429 338
2024-07-31 19:56:33,858 ERROR Error in text-to-speech: Text-to-speech conversion failed: 429 - {"error":{"code":"429","message": "Requests to the Audio_Speech Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 11 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit."}}
2024-07-31 19:56:33,860 INFO 127.0.0.1 - - [31/Jul/2024 19:56:33] "[35m[1mPOST /text-to-speech HTTP/1.1[0m" 500 -
2024-07-31 19:57:01,405 INFO 127.0.0.1 - - [31/Jul/2024 19:57:01] "GET / HTTP/1.1" 200 -
2024-07-31 19:57:16,080 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Amigo, a fun and entertaining AI companion. Your job is to make your friend laugh and keep things light-hearted. Be witty and playful, sharing jokes and funny stories. Engage in cheerful banter and always aim to uplift your friend's mood."}, {'role': 'user', 'content': 'what can i ask to you for future?'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 150, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-07-31 19:57:16,084 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 19:57:16,086 DEBUG close.started
2024-07-31 19:57:16,088 DEBUG close.complete
2024-07-31 19:57:16,090 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 19:57:16,128 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021611982190>
2024-07-31 19:57:16,135 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x00000216116AC4D0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 19:57:16,183 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000216119802D0>
2024-07-31 19:57:16,184 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 19:57:16,185 DEBUG send_request_headers.complete
2024-07-31 19:57:16,185 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 19:57:16,186 DEBUG send_request_body.complete
2024-07-31 19:57:16,187 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 19:57:16,753 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'1088'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'a63245a7-da49-4422-ae03-e0d17c79ea6b'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149700'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'89c0a8a3-0b1d-4481-8d59-904133a00ff8'), (b'x-ms-client-request-id', b'a63245a7-da49-4422-ae03-e0d17c79ea6b'), (b'azureml-model-session', b'turbo-0613-cf02972a'), (b'Date', b'Wed, 31 Jul 2024 23:57:16 GMT')])
2024-07-31 19:57:16,755 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 19:57:16,756 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 19:57:16,757 DEBUG receive_response_body.complete
2024-07-31 19:57:16,757 DEBUG response_closed.started
2024-07-31 19:57:16,761 DEBUG response_closed.complete
2024-07-31 19:57:16,761 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '1088', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'a63245a7-da49-4422-ae03-e0d17c79ea6b', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149700', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '89c0a8a3-0b1d-4481-8d59-904133a00ff8', 'x-ms-client-request-id': 'a63245a7-da49-4422-ae03-e0d17c79ea6b', 'azureml-model-session': 'turbo-0613-cf02972a', 'date': 'Wed, 31 Jul 2024 23:57:16 GMT'})
2024-07-31 19:57:16,762 DEBUG request_id: 89c0a8a3-0b1d-4481-8d59-904133a00ff8
2024-07-31 19:57:16,764 INFO 127.0.0.1 - - [31/Jul/2024 19:57:16] "POST /chat HTTP/1.1" 200 -
2024-07-31 19:57:16,825 DEBUG Starting new HTTPS connection (1): bsmp24.openai.azure.com:443
2024-07-31 19:57:17,612 DEBUG https://bsmp24.openai.azure.com:443 "POST /openai/deployments/tts/audio/speech?api-version=2024-02-15-preview HTTP/11" 200 None
2024-07-31 19:57:19,970 INFO 127.0.0.1 - - [31/Jul/2024 19:57:19] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 19:57:20,302 INFO 127.0.0.1 - - [31/Jul/2024 19:57:20] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2024-07-31 20:04:43,248 INFO  * Detected change in 'C:\\Users\\ahmtt\\OneDrive\\Documents\\VS\\BAM_HACKATHON_2024\\tts.py', reloading
2024-07-31 20:04:43,373 INFO  * Restarting with stat
2024-07-31 20:17:06,525 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-07-31 20:17:06,526 INFO [33mPress CTRL+C to quit[0m
2024-07-31 20:17:06,529 INFO  * Restarting with stat
2024-07-31 20:17:07,632 WARNING  * Debugger is active!
2024-07-31 20:17:07,638 INFO  * Debugger PIN: 116-389-750
2024-07-31 20:17:11,450 INFO 127.0.0.1 - - [31/Jul/2024 20:17:11] "GET / HTTP/1.1" 200 -
2024-07-31 20:17:11,597 INFO 127.0.0.1 - - [31/Jul/2024 20:17:11] "GET /static/login_styles.css HTTP/1.1" 200 -
2024-07-31 20:17:32,803 INFO 127.0.0.1 - - [31/Jul/2024 20:17:32] "[33mGET /chat.html HTTP/1.1[0m" 404 -
2024-07-31 20:19:03,161 INFO  * Detected change in 'C:\\Users\\ahmtt\\OneDrive\\Documents\\VS\\BAM_HACKATHON_2024\\app.py', reloading
2024-07-31 20:19:03,316 INFO  * Restarting with stat
2024-07-31 20:19:04,672 WARNING  * Debugger is active!
2024-07-31 20:19:04,677 INFO  * Debugger PIN: 116-389-750
2024-07-31 20:19:18,021 INFO 127.0.0.1 - - [31/Jul/2024 20:19:18] "[33mGET /chat.html HTTP/1.1[0m" 404 -
2024-07-31 20:19:18,624 INFO 127.0.0.1 - - [31/Jul/2024 20:19:18] "[33mGET /chat.html HTTP/1.1[0m" 404 -
2024-07-31 20:19:18,904 INFO 127.0.0.1 - - [31/Jul/2024 20:19:18] "[33mGET /chat.html HTTP/1.1[0m" 404 -
2024-07-31 20:19:19,144 INFO 127.0.0.1 - - [31/Jul/2024 20:19:19] "[33mGET /chat.html HTTP/1.1[0m" 404 -
2024-07-31 20:19:28,847 INFO 127.0.0.1 - - [31/Jul/2024 20:19:28] "GET / HTTP/1.1" 200 -
2024-07-31 20:19:29,015 INFO 127.0.0.1 - - [31/Jul/2024 20:19:29] "[36mGET /static/login_styles.css HTTP/1.1[0m" 304 -
2024-07-31 20:19:38,598 INFO 127.0.0.1 - - [31/Jul/2024 20:19:38] "[33mGET /chat.html HTTP/1.1[0m" 404 -
2024-07-31 20:19:43,269 INFO 127.0.0.1 - - [31/Jul/2024 20:19:43] "GET / HTTP/1.1" 200 -
2024-07-31 20:19:43,294 INFO 127.0.0.1 - - [31/Jul/2024 20:19:43] "[36mGET /static/login_styles.css HTTP/1.1[0m" 304 -
2024-07-31 20:19:52,153 INFO 127.0.0.1 - - [31/Jul/2024 20:19:52] "[33mGET /chat.html HTTP/1.1[0m" 404 -
2024-07-31 20:21:09,674 INFO  * Detected change in 'C:\\Users\\ahmtt\\OneDrive\\Documents\\VS\\BAM_HACKATHON_2024\\app.py', reloading
2024-07-31 20:21:09,867 INFO  * Restarting with stat
2024-07-31 20:21:10,975 WARNING  * Debugger is active!
2024-07-31 20:21:10,980 INFO  * Debugger PIN: 116-389-750
2024-07-31 20:21:25,194 INFO 127.0.0.1 - - [31/Jul/2024 20:21:25] "GET / HTTP/1.1" 200 -
2024-07-31 20:21:25,301 INFO 127.0.0.1 - - [31/Jul/2024 20:21:25] "[36mGET /static/login_styles.css HTTP/1.1[0m" 304 -
2024-07-31 20:21:33,002 INFO 127.0.0.1 - - [31/Jul/2024 20:21:33] "POST /login HTTP/1.1" 200 -
2024-07-31 20:21:33,026 INFO 127.0.0.1 - - [31/Jul/2024 20:21:33] "GET /chat HTTP/1.1" 200 -
2024-07-31 20:21:33,068 INFO 127.0.0.1 - - [31/Jul/2024 20:21:33] "GET /static/styles.css HTTP/1.1" 200 -
2024-07-31 20:22:47,651 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Amigo, a fun and entertaining AI companion. Your job is to make your friend laugh and keep things light-hearted. Be witty and playful, sharing jokes and funny stories. Engage in cheerful banter and always aim to uplift your friend's mood."}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 150, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-07-31 20:22:47,666 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 20:22:47,666 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 20:22:47,699 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001A0596A7990>
2024-07-31 20:22:47,700 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A05914C4D0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 20:22:47,753 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001A0596A7950>
2024-07-31 20:22:47,754 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 20:22:47,754 DEBUG send_request_headers.complete
2024-07-31 20:22:47,755 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 20:22:47,755 DEBUG send_request_body.complete
2024-07-31 20:22:47,755 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 20:22:48,010 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'856'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'f6d57a3d-c18b-4aae-bed2-8c618aa5a54b'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149850'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'100c5eab-5360-4bad-b15d-49cb107af2ae'), (b'x-ms-client-request-id', b'f6d57a3d-c18b-4aae-bed2-8c618aa5a54b'), (b'azureml-model-session', b'turbo-0613-144e2f97'), (b'Date', b'Thu, 01 Aug 2024 00:22:48 GMT')])
2024-07-31 20:22:48,012 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 20:22:48,012 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 20:22:48,013 DEBUG receive_response_body.complete
2024-07-31 20:22:48,013 DEBUG response_closed.started
2024-07-31 20:22:48,013 DEBUG response_closed.complete
2024-07-31 20:22:48,014 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '856', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'f6d57a3d-c18b-4aae-bed2-8c618aa5a54b', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149850', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '100c5eab-5360-4bad-b15d-49cb107af2ae', 'x-ms-client-request-id': 'f6d57a3d-c18b-4aae-bed2-8c618aa5a54b', 'azureml-model-session': 'turbo-0613-144e2f97', 'date': 'Thu, 01 Aug 2024 00:22:48 GMT'})
2024-07-31 20:22:48,015 DEBUG request_id: 100c5eab-5360-4bad-b15d-49cb107af2ae
2024-07-31 20:22:48,025 INFO 127.0.0.1 - - [31/Jul/2024 20:22:48] "POST /chat HTTP/1.1" 200 -
2024-07-31 20:22:48,047 INFO 127.0.0.1 - - [31/Jul/2024 20:22:48] "[35m[1mPOST /text-to-speech HTTP/1.1[0m" 500 -
2024-07-31 20:23:49,007 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-07-31 20:23:49,015 INFO [33mPress CTRL+C to quit[0m
2024-07-31 20:23:49,017 INFO  * Restarting with stat
2024-07-31 20:23:50,095 WARNING  * Debugger is active!
2024-07-31 20:23:50,100 INFO  * Debugger PIN: 116-389-750
2024-07-31 20:26:31,859 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-07-31 20:26:31,860 INFO [33mPress CTRL+C to quit[0m
2024-07-31 20:26:31,862 INFO  * Restarting with stat
2024-07-31 20:26:32,964 WARNING  * Debugger is active!
2024-07-31 20:26:32,970 INFO  * Debugger PIN: 116-389-750
2024-07-31 20:26:33,026 INFO 127.0.0.1 - - [31/Jul/2024 20:26:33] "GET /chat HTTP/1.1" 200 -
2024-07-31 20:26:33,166 INFO 127.0.0.1 - - [31/Jul/2024 20:26:33] "GET /static/styles.css HTTP/1.1" 200 -
2024-07-31 20:26:40,676 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Amigo, a fun and entertaining AI companion. Your job is to make your friend laugh and keep things light-hearted. Be witty and playful, sharing jokes and funny stories. Engage in cheerful banter and always aim to uplift your friend's mood."}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 150, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-07-31 20:26:40,689 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 20:26:40,690 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 20:26:40,758 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028216266150>
2024-07-31 20:26:40,758 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x0000028214CCBAD0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 20:26:40,821 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028216266110>
2024-07-31 20:26:40,821 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 20:26:40,822 DEBUG send_request_headers.complete
2024-07-31 20:26:40,823 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 20:26:40,823 DEBUG send_request_body.complete
2024-07-31 20:26:40,824 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 20:26:41,044 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'846'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'b0da55d3-d3a9-4292-9577-156360452eb7'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'148'), (b'x-ratelimit-remaining-tokens', b'149802'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'd3dce471-82fb-43fd-919e-2ffc617af828'), (b'x-ms-client-request-id', b'b0da55d3-d3a9-4292-9577-156360452eb7'), (b'azureml-model-session', b'turbo-0613-9af7de78'), (b'Date', b'Thu, 01 Aug 2024 00:26:41 GMT')])
2024-07-31 20:26:41,046 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 20:26:41,046 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 20:26:41,046 DEBUG receive_response_body.complete
2024-07-31 20:26:41,046 DEBUG response_closed.started
2024-07-31 20:26:41,047 DEBUG response_closed.complete
2024-07-31 20:26:41,047 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '846', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'b0da55d3-d3a9-4292-9577-156360452eb7', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '148', 'x-ratelimit-remaining-tokens': '149802', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'd3dce471-82fb-43fd-919e-2ffc617af828', 'x-ms-client-request-id': 'b0da55d3-d3a9-4292-9577-156360452eb7', 'azureml-model-session': 'turbo-0613-9af7de78', 'date': 'Thu, 01 Aug 2024 00:26:41 GMT'})
2024-07-31 20:26:41,048 DEBUG request_id: d3dce471-82fb-43fd-919e-2ffc617af828
2024-07-31 20:26:41,052 INFO 127.0.0.1 - - [31/Jul/2024 20:26:41] "POST /chat HTTP/1.1" 200 -
2024-07-31 20:26:41,067 DEBUG Using proactor: IocpProactor
2024-07-31 20:26:42,140 INFO 127.0.0.1 - - [31/Jul/2024 20:26:42] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 20:26:42,186 INFO 127.0.0.1 - - [31/Jul/2024 20:26:42] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2024-07-31 20:34:08,593 INFO 127.0.0.1 - - [31/Jul/2024 20:34:08] "GET /chat HTTP/1.1" 200 -
2024-07-31 20:34:08,631 INFO 127.0.0.1 - - [31/Jul/2024 20:34:08] "GET /static/styles.css HTTP/1.1" 200 -
2024-07-31 20:34:38,709 INFO 127.0.0.1 - - [31/Jul/2024 20:34:38] "GET /chat HTTP/1.1" 200 -
2024-07-31 20:34:38,762 INFO 127.0.0.1 - - [31/Jul/2024 20:34:38] "[36mGET /static/styles.css HTTP/1.1[0m" 304 -
2024-07-31 20:34:38,791 INFO 127.0.0.1 - - [31/Jul/2024 20:34:38] "GET /static/scripts.js HTTP/1.1" 200 -
2024-07-31 20:34:44,619 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': None}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 150, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-07-31 20:34:44,620 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 20:34:44,621 DEBUG close.started
2024-07-31 20:34:44,621 DEBUG close.complete
2024-07-31 20:34:44,622 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 20:34:44,660 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000282162AEE50>
2024-07-31 20:34:44,660 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x0000028214CCBAD0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 20:34:44,699 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000282162AC150>
2024-07-31 20:34:44,700 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 20:34:44,702 DEBUG send_request_headers.complete
2024-07-31 20:34:44,702 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 20:34:44,703 DEBUG send_request_body.complete
2024-07-31 20:34:44,704 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 20:34:44,759 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'model_error', [(b'Content-Length', b'188'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'2bca7c01-072b-4d97-817e-bb0dcf7c7679'), (b'x-ratelimit-remaining-requests', b'149'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-remaining-tokens', b'149850'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'20f05052-e306-4f01-8b01-95f5dc16f56c'), (b'ms-azureml-model-error-reason', b'model_error'), (b'ms-azureml-model-error-statuscode', b'400'), (b'x-ms-client-request-id', b'2bca7c01-072b-4d97-817e-bb0dcf7c7679'), (b'x-content-type-options', b'nosniff'), (b'azureml-model-session', b'turbo-0613-3425e45b'), (b'x-ms-region', b'East US'), (b'Date', b'Thu, 01 Aug 2024 00:34:45 GMT')])
2024-07-31 20:34:44,760 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 400 model_error"
2024-07-31 20:34:44,760 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 20:34:44,761 DEBUG receive_response_body.complete
2024-07-31 20:34:44,761 DEBUG response_closed.started
2024-07-31 20:34:44,761 DEBUG response_closed.complete
2024-07-31 20:34:44,762 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "400 model_error" Headers({'content-length': '188', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '2bca7c01-072b-4d97-817e-bb0dcf7c7679', 'x-ratelimit-remaining-requests': '149', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-remaining-tokens': '149850', 'x-ms-rai-invoked': 'true', 'x-request-id': '20f05052-e306-4f01-8b01-95f5dc16f56c', 'ms-azureml-model-error-reason': 'model_error', 'ms-azureml-model-error-statuscode': '400', 'x-ms-client-request-id': '2bca7c01-072b-4d97-817e-bb0dcf7c7679', 'x-content-type-options': 'nosniff', 'azureml-model-session': 'turbo-0613-3425e45b', 'x-ms-region': 'East US', 'date': 'Thu, 01 Aug 2024 00:34:45 GMT'})
2024-07-31 20:34:44,762 DEBUG request_id: 20f05052-e306-4f01-8b01-95f5dc16f56c
2024-07-31 20:34:44,762 DEBUG Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\openai\_base_client.py", line 1025, in _request
    response.raise_for_status()
  File "C:\Users\ahmtt\OneDrive\Documents\VS\BAM_HACKATHON_2024\env\Lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 model_error' for url 'https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2024-07-31 20:34:44,765 DEBUG Not retrying
2024-07-31 20:34:44,765 DEBUG Re-raising status error
2024-07-31 20:34:44,782 INFO 127.0.0.1 - - [31/Jul/2024 20:34:44] "[35m[1mPOST /chat HTTP/1.1[0m" 500 -
2024-07-31 20:35:36,031 INFO  * Detected change in 'C:\\Users\\ahmtt\\OneDrive\\Documents\\VS\\BAM_HACKATHON_2024\\app.py', reloading
2024-07-31 20:35:36,194 INFO  * Restarting with stat
2024-07-31 20:55:41,461 WARNING  * Debugger is active!
2024-07-31 20:55:41,468 INFO  * Debugger PIN: 116-389-750
2024-07-31 20:56:13,028 INFO  * Detected change in 'C:\\Users\\ahmtt\\OneDrive\\Documents\\VS\\BAM_HACKATHON_2024\\tts.py', reloading
2024-07-31 20:56:14,316 WARNING  * Debugger is active!
2024-07-31 20:56:14,321 INFO  * Debugger PIN: 116-389-750
2024-07-31 20:58:32,159 INFO 127.0.0.1 - - [31/Jul/2024 20:58:32] "GET / HTTP/1.1" 200 -
2024-07-31 20:58:36,556 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Amigo, a fun and entertaining AI companion. Your job is to make your friend laugh and keep things light-hearted. Be witty and playful, sharing jokes and funny stories. Engage in cheerful banter and always aim to uplift your friend's mood."}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 150, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-07-31 20:58:36,595 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 20:58:36,596 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 20:58:36,714 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B261C5FD90>
2024-07-31 20:58:36,715 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000002B2619CC560> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 20:58:36,748 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B261C5ED90>
2024-07-31 20:58:36,749 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 20:58:36,749 DEBUG send_request_headers.complete
2024-07-31 20:58:36,750 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 20:58:36,750 DEBUG send_request_body.complete
2024-07-31 20:58:36,750 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 20:58:36,992 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'876'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'170ddb79-fe04-4d00-b319-9f665bb3826e'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149850'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'b6ff3be5-eae4-41ea-87bf-14ce77f5c735'), (b'x-ms-client-request-id', b'170ddb79-fe04-4d00-b319-9f665bb3826e'), (b'azureml-model-session', b'turbo-0613-dbd92aac'), (b'Date', b'Thu, 01 Aug 2024 00:58:37 GMT')])
2024-07-31 20:58:36,994 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 20:58:36,995 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 20:58:36,995 DEBUG receive_response_body.complete
2024-07-31 20:58:36,996 DEBUG response_closed.started
2024-07-31 20:58:37,000 DEBUG response_closed.complete
2024-07-31 20:58:37,000 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '876', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '170ddb79-fe04-4d00-b319-9f665bb3826e', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149850', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'b6ff3be5-eae4-41ea-87bf-14ce77f5c735', 'x-ms-client-request-id': '170ddb79-fe04-4d00-b319-9f665bb3826e', 'azureml-model-session': 'turbo-0613-dbd92aac', 'date': 'Thu, 01 Aug 2024 00:58:37 GMT'})
2024-07-31 20:58:37,001 DEBUG request_id: b6ff3be5-eae4-41ea-87bf-14ce77f5c735
2024-07-31 20:58:37,006 INFO 127.0.0.1 - - [31/Jul/2024 20:58:37] "POST /chat HTTP/1.1" 200 -
2024-07-31 20:58:37,018 DEBUG Starting new HTTPS connection (1): bsmp24.openai.azure.com:443
2024-07-31 20:58:37,603 DEBUG https://bsmp24.openai.azure.com:443 "POST /openai/deployments/tts/audio/speech?api-version=2024-02-15-preview HTTP/11" 200 None
2024-07-31 20:58:39,009 INFO 127.0.0.1 - - [31/Jul/2024 20:58:39] "POST /text-to-speech HTTP/1.1" 200 -
2024-07-31 20:58:39,075 INFO 127.0.0.1 - - [31/Jul/2024 20:58:39] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2024-07-31 20:59:08,478 INFO  * Detected change in 'C:\\Users\\ahmtt\\OneDrive\\Documents\\VS\\BAM_HACKATHON_2024\\app.py', reloading
2024-07-31 20:59:09,822 WARNING  * Debugger is active!
2024-07-31 20:59:09,827 INFO  * Debugger PIN: 116-389-750
2024-07-31 20:59:10,001 INFO 127.0.0.1 - - [31/Jul/2024 20:59:10] "GET / HTTP/1.1" 200 -
2024-07-31 20:59:10,137 INFO 127.0.0.1 - - [31/Jul/2024 20:59:10] "[36mGET /static/login_styles.css HTTP/1.1[0m" 304 -
2024-07-31 20:59:16,965 INFO 127.0.0.1 - - [31/Jul/2024 20:59:16] "[33mGET /chat.html HTTP/1.1[0m" 404 -
2024-07-31 20:59:49,473 INFO  * Detected change in 'C:\\Users\\ahmtt\\OneDrive\\Documents\\VS\\BAM_HACKATHON_2024\\app.py', reloading
2024-07-31 20:59:50,842 WARNING  * Debugger is active!
2024-07-31 20:59:50,846 INFO  * Debugger PIN: 116-389-750
2024-07-31 21:00:14,873 INFO 127.0.0.1 - - [31/Jul/2024 21:00:14] "[33mGET /chat.html HTTP/1.1[0m" 404 -
2024-07-31 21:00:19,314 INFO 127.0.0.1 - - [31/Jul/2024 21:00:19] "GET /chat HTTP/1.1" 200 -
2024-07-31 21:00:19,490 INFO 127.0.0.1 - - [31/Jul/2024 21:00:19] "GET /static/styles.css HTTP/1.1" 200 -
2024-07-31 21:00:22,845 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Amigo, a fun and entertaining AI companion. Your job is to make your friend laugh and keep things light-hearted. Be witty and playful, sharing jokes and funny stories. Engage in cheerful banter and always aim to uplift your friend's mood."}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 150, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-07-31 21:00:22,856 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 21:00:22,860 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 21:00:22,905 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF5FFF62D0>
2024-07-31 21:00:22,905 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000002AF5E9DFB60> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 21:00:22,953 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF5FFE8F50>
2024-07-31 21:00:22,954 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 21:00:22,955 DEBUG send_request_headers.complete
2024-07-31 21:00:22,955 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 21:00:22,956 DEBUG send_request_body.complete
2024-07-31 21:00:22,956 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 21:00:23,359 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'947'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'7d280af4-549d-467c-86d9-d767707f609e'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149850'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'8a8f11fd-3c08-40c5-a37f-2fca756826e8'), (b'x-ms-client-request-id', b'7d280af4-549d-467c-86d9-d767707f609e'), (b'azureml-model-session', b'turbo-0613-3e1cc6ec'), (b'Date', b'Thu, 01 Aug 2024 01:00:24 GMT')])
2024-07-31 21:00:23,360 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 21:00:23,361 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 21:00:23,361 DEBUG receive_response_body.complete
2024-07-31 21:00:23,362 DEBUG response_closed.started
2024-07-31 21:00:23,362 DEBUG response_closed.complete
2024-07-31 21:00:23,363 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '947', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '7d280af4-549d-467c-86d9-d767707f609e', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149850', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '8a8f11fd-3c08-40c5-a37f-2fca756826e8', 'x-ms-client-request-id': '7d280af4-549d-467c-86d9-d767707f609e', 'azureml-model-session': 'turbo-0613-3e1cc6ec', 'date': 'Thu, 01 Aug 2024 01:00:24 GMT'})
2024-07-31 21:00:23,363 DEBUG request_id: 8a8f11fd-3c08-40c5-a37f-2fca756826e8
2024-07-31 21:00:23,369 INFO 127.0.0.1 - - [31/Jul/2024 21:00:23] "POST /chat HTTP/1.1" 200 -
2024-07-31 21:00:23,384 DEBUG Using proactor: IocpProactor
2024-07-31 21:00:23,389 DEBUG Starting new HTTPS connection (1): bsmp24.openai.azure.com:443
2024-07-31 21:00:24,019 DEBUG https://bsmp24.openai.azure.com:443 "POST /openai/deployments/tts/audio/speech?api-version=2024-02-15-preview HTTP/11" 200 None
2024-07-31 21:00:25,389 ERROR Error in text-to-speech: object _io.BytesIO can't be used in 'await' expression
2024-07-31 21:00:25,390 INFO 127.0.0.1 - - [31/Jul/2024 21:00:25] "[35m[1mPOST /text-to-speech HTTP/1.1[0m" 500 -
2024-07-31 21:00:39,684 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Amigo, a fun and entertaining AI companion. Your job is to make your friend laugh and keep things light-hearted. Be witty and playful, sharing jokes and funny stories. Engage in cheerful banter and always aim to uplift your friend's mood."}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 150, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-07-31 21:00:39,686 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 21:00:39,687 DEBUG close.started
2024-07-31 21:00:39,687 DEBUG close.complete
2024-07-31 21:00:39,687 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 21:00:39,785 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF600347D0>
2024-07-31 21:00:39,785 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000002AF5E9DFB60> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 21:00:39,944 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF5FFFC790>
2024-07-31 21:00:39,945 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 21:00:39,945 DEBUG send_request_headers.complete
2024-07-31 21:00:39,946 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 21:00:39,946 DEBUG send_request_body.complete
2024-07-31 21:00:39,946 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 21:00:40,208 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'846'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'2bea6ed5-5815-4125-9f10-7e7a623fb16a'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149700'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'6e655ec7-a884-4638-a82f-5973e16f4b35'), (b'x-ms-client-request-id', b'2bea6ed5-5815-4125-9f10-7e7a623fb16a'), (b'azureml-model-session', b'turbo-0613-144e2f97'), (b'Date', b'Thu, 01 Aug 2024 01:00:40 GMT')])
2024-07-31 21:00:40,208 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 21:00:40,209 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 21:00:40,209 DEBUG receive_response_body.complete
2024-07-31 21:00:40,210 DEBUG response_closed.started
2024-07-31 21:00:40,210 DEBUG response_closed.complete
2024-07-31 21:00:40,211 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '846', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '2bea6ed5-5815-4125-9f10-7e7a623fb16a', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149700', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '6e655ec7-a884-4638-a82f-5973e16f4b35', 'x-ms-client-request-id': '2bea6ed5-5815-4125-9f10-7e7a623fb16a', 'azureml-model-session': 'turbo-0613-144e2f97', 'date': 'Thu, 01 Aug 2024 01:00:40 GMT'})
2024-07-31 21:00:40,212 DEBUG request_id: 6e655ec7-a884-4638-a82f-5973e16f4b35
2024-07-31 21:00:40,212 INFO 127.0.0.1 - - [31/Jul/2024 21:00:40] "POST /chat HTTP/1.1" 200 -
2024-07-31 21:00:40,222 DEBUG Using proactor: IocpProactor
2024-07-31 21:00:40,226 DEBUG Starting new HTTPS connection (1): bsmp24.openai.azure.com:443
2024-07-31 21:00:40,588 DEBUG https://bsmp24.openai.azure.com:443 "POST /openai/deployments/tts/audio/speech?api-version=2024-02-15-preview HTTP/11" 429 338
2024-07-31 21:00:40,589 ERROR Error in text-to-speech: Text-to-speech conversion failed: 429 - {"error":{"code":"429","message": "Requests to the Audio_Speech Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 43 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit."}}
2024-07-31 21:00:40,591 INFO 127.0.0.1 - - [31/Jul/2024 21:00:40] "[35m[1mPOST /text-to-speech HTTP/1.1[0m" 500 -
2024-07-31 21:06:33,485 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Amigo, a fun and entertaining AI companion. Your job is to make your friend laugh and keep things light-hearted. Be witty and playful, sharing jokes and funny stories. Engage in cheerful banter and always aim to uplift your friend's mood."}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 150, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-07-31 21:06:33,486 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 21:06:33,488 DEBUG close.started
2024-07-31 21:06:33,489 DEBUG close.complete
2024-07-31 21:06:33,489 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 21:06:33,523 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF60036910>
2024-07-31 21:06:33,523 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000002AF5E9DFB60> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 21:06:33,561 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF60037A90>
2024-07-31 21:06:33,562 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 21:06:33,562 DEBUG send_request_headers.complete
2024-07-31 21:06:33,562 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 21:06:33,563 DEBUG send_request_body.complete
2024-07-31 21:06:33,563 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 21:06:34,046 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'936'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'56c8f2f7-9cba-4403-8a19-d80cc03cff6d'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149850'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'704c00bc-535b-4a0a-9d60-a3cbc9406359'), (b'x-ms-client-request-id', b'56c8f2f7-9cba-4403-8a19-d80cc03cff6d'), (b'azureml-model-session', b'turbo-0613-3425e45b'), (b'Date', b'Thu, 01 Aug 2024 01:06:34 GMT')])
2024-07-31 21:06:34,046 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 21:06:34,048 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 21:06:34,048 DEBUG receive_response_body.complete
2024-07-31 21:06:34,048 DEBUG response_closed.started
2024-07-31 21:06:34,048 DEBUG response_closed.complete
2024-07-31 21:06:34,049 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '936', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '56c8f2f7-9cba-4403-8a19-d80cc03cff6d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149850', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '704c00bc-535b-4a0a-9d60-a3cbc9406359', 'x-ms-client-request-id': '56c8f2f7-9cba-4403-8a19-d80cc03cff6d', 'azureml-model-session': 'turbo-0613-3425e45b', 'date': 'Thu, 01 Aug 2024 01:06:34 GMT'})
2024-07-31 21:06:34,050 DEBUG request_id: 704c00bc-535b-4a0a-9d60-a3cbc9406359
2024-07-31 21:06:34,050 INFO 127.0.0.1 - - [31/Jul/2024 21:06:34] "POST /chat HTTP/1.1" 200 -
2024-07-31 21:06:34,059 DEBUG Using proactor: IocpProactor
2024-07-31 21:06:34,062 DEBUG Starting new HTTPS connection (1): bsmp24.openai.azure.com:443
2024-07-31 21:06:34,265 DEBUG https://bsmp24.openai.azure.com:443 "POST /openai/deployments/tts/audio/speech?api-version=2024-02-15-preview HTTP/11" 429 338
2024-07-31 21:06:34,265 ERROR Error in text-to-speech: Text-to-speech conversion failed: 429 - {"error":{"code":"429","message": "Requests to the Audio_Speech Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 13 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit."}}
2024-07-31 21:06:34,267 INFO 127.0.0.1 - - [31/Jul/2024 21:06:34] "[35m[1mPOST /text-to-speech HTTP/1.1[0m" 500 -
2024-07-31 21:06:59,879 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Amigo, a fun and entertaining AI companion. Your job is to make your friend laugh and keep things light-hearted. Be witty and playful, sharing jokes and funny stories. Engage in cheerful banter and always aim to uplift your friend's mood."}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 150, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-07-31 21:06:59,880 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 21:06:59,880 DEBUG close.started
2024-07-31 21:06:59,881 DEBUG close.complete
2024-07-31 21:06:59,881 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 21:07:00,195 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF5FFE9F90>
2024-07-31 21:07:00,195 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000002AF5E9DFB60> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 21:07:00,796 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF5FFCFB90>
2024-07-31 21:07:00,797 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 21:07:00,797 DEBUG send_request_headers.complete
2024-07-31 21:07:00,798 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 21:07:00,798 DEBUG send_request_body.complete
2024-07-31 21:07:00,798 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 21:07:01,088 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'846'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'7def8072-d006-4f23-ba6f-c82b818183e8'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149700'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'5dff3da4-a9e9-41fe-91bd-6750aff18504'), (b'x-ms-client-request-id', b'7def8072-d006-4f23-ba6f-c82b818183e8'), (b'azureml-model-session', b'turbo-0613-f12dda4f'), (b'Date', b'Thu, 01 Aug 2024 01:07:01 GMT')])
2024-07-31 21:07:01,089 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 21:07:01,089 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 21:07:01,090 DEBUG receive_response_body.complete
2024-07-31 21:07:01,090 DEBUG response_closed.started
2024-07-31 21:07:01,090 DEBUG response_closed.complete
2024-07-31 21:07:01,091 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '846', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '7def8072-d006-4f23-ba6f-c82b818183e8', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149700', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '5dff3da4-a9e9-41fe-91bd-6750aff18504', 'x-ms-client-request-id': '7def8072-d006-4f23-ba6f-c82b818183e8', 'azureml-model-session': 'turbo-0613-f12dda4f', 'date': 'Thu, 01 Aug 2024 01:07:01 GMT'})
2024-07-31 21:07:01,091 DEBUG request_id: 5dff3da4-a9e9-41fe-91bd-6750aff18504
2024-07-31 21:07:01,092 INFO 127.0.0.1 - - [31/Jul/2024 21:07:01] "POST /chat HTTP/1.1" 200 -
2024-07-31 21:07:01,098 DEBUG Using proactor: IocpProactor
2024-07-31 21:07:01,100 DEBUG Starting new HTTPS connection (1): bsmp24.openai.azure.com:443
2024-07-31 21:07:01,673 DEBUG https://bsmp24.openai.azure.com:443 "POST /openai/deployments/tts/audio/speech?api-version=2024-02-15-preview HTTP/11" 200 None
2024-07-31 21:07:02,206 ERROR Error in text-to-speech: object _io.BytesIO can't be used in 'await' expression
2024-07-31 21:07:02,207 INFO 127.0.0.1 - - [31/Jul/2024 21:07:02] "[35m[1mPOST /text-to-speech HTTP/1.1[0m" 500 -
2024-07-31 21:10:22,145 INFO  * Detected change in 'C:\\Users\\ahmtt\\OneDrive\\Documents\\VS\\BAM_HACKATHON_2024\\ai.py', reloading
2024-07-31 21:10:24,607 WARNING  * Debugger is active!
2024-07-31 21:10:24,612 INFO  * Debugger PIN: 116-389-750
2024-07-31 21:17:03,059 INFO 127.0.0.1 - - [31/Jul/2024 21:17:03] "GET /chat HTTP/1.1" 200 -
2024-07-31 21:17:57,608 INFO 127.0.0.1 - - [31/Jul/2024 21:17:57] "GET /chat HTTP/1.1" 200 -
2024-07-31 21:18:04,248 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Amigo, a fun and entertaining AI companion. Your job is to make your friend laugh and keep things light-hearted. Be witty and playful, sharing jokes and funny stories. Engage in cheerful banter and always aim to uplift your friend's mood."}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 150, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-07-31 21:18:04,260 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-07-31 21:18:04,260 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-07-31 21:18:04,572 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FC840D10D0>
2024-07-31 21:18:04,573 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001FC82B4BAD0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-07-31 21:18:04,635 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FC840D1090>
2024-07-31 21:18:04,636 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-07-31 21:18:04,637 DEBUG send_request_headers.complete
2024-07-31 21:18:04,637 DEBUG send_request_body.started request=<Request [b'POST']>
2024-07-31 21:18:04,638 DEBUG send_request_body.complete
2024-07-31 21:18:04,641 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-07-31 21:18:04,854 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'865'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'57279621-43f1-4896-a4c9-5b7817a8bb72'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149850'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'0b53df00-3ed6-423a-9cbf-d79b417169d7'), (b'x-ms-client-request-id', b'57279621-43f1-4896-a4c9-5b7817a8bb72'), (b'azureml-model-session', b'turbo-0613-dbd92aac'), (b'Date', b'Thu, 01 Aug 2024 01:18:05 GMT')])
2024-07-31 21:18:04,855 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-07-31 21:18:04,855 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-07-31 21:18:04,855 DEBUG receive_response_body.complete
2024-07-31 21:18:04,857 DEBUG response_closed.started
2024-07-31 21:18:04,857 DEBUG response_closed.complete
2024-07-31 21:18:04,857 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '865', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '57279621-43f1-4896-a4c9-5b7817a8bb72', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149850', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '0b53df00-3ed6-423a-9cbf-d79b417169d7', 'x-ms-client-request-id': '57279621-43f1-4896-a4c9-5b7817a8bb72', 'azureml-model-session': 'turbo-0613-dbd92aac', 'date': 'Thu, 01 Aug 2024 01:18:05 GMT'})
2024-07-31 21:18:04,863 DEBUG request_id: 0b53df00-3ed6-423a-9cbf-d79b417169d7
2024-07-31 21:18:04,867 INFO 127.0.0.1 - - [31/Jul/2024 21:18:04] "POST /chat HTTP/1.1" 200 -
2024-07-31 21:18:04,881 DEBUG Using proactor: IocpProactor
2024-07-31 21:18:04,885 DEBUG Starting new HTTPS connection (1): bsmp24.openai.azure.com:443
2024-07-31 21:18:05,462 DEBUG https://bsmp24.openai.azure.com:443 "POST /openai/deployments/tts/audio/speech?api-version=2024-02-15-preview HTTP/11" 200 None
2024-07-31 21:18:06,013 ERROR Error in text-to-speech: object _io.BytesIO can't be used in 'await' expression
2024-07-31 21:18:06,015 INFO 127.0.0.1 - - [31/Jul/2024 21:18:06] "[35m[1mPOST /text-to-speech HTTP/1.1[0m" 500 -
2024-08-01 10:14:25,228 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-08-01 10:14:25,228 INFO [33mPress CTRL+C to quit[0m
2024-08-01 10:14:25,229 INFO  * Restarting with stat
2024-08-01 10:14:26,159 WARNING  * Debugger is active!
2024-08-01 10:14:26,162 INFO  * Debugger PIN: 116-389-750
2024-08-01 10:14:37,043 INFO 127.0.0.1 - - [01/Aug/2024 10:14:37] "GET /chat HTTP/1.1" 200 -
2024-08-01 10:14:39,132 INFO 127.0.0.1 - - [01/Aug/2024 10:14:39] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2024-08-01 10:14:44,111 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Amigo, a fun and entertaining AI companion. Your job is to make your friend laugh and keep things light-hearted. Be witty and playful, sharing jokes and funny stories. Engage in cheerful banter and always aim to uplift your friend's mood."}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 150, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-08-01 10:14:44,378 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-08-01 10:14:44,379 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-08-01 10:14:44,499 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001911E901950>
2024-08-01 10:14:44,499 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001911D37BAD0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-08-01 10:14:45,884 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001911E8F63D0>
2024-08-01 10:14:45,884 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-08-01 10:14:45,885 DEBUG send_request_headers.complete
2024-08-01 10:14:45,885 DEBUG send_request_body.started request=<Request [b'POST']>
2024-08-01 10:14:45,885 DEBUG send_request_body.complete
2024-08-01 10:14:45,885 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-08-01 10:14:46,460 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'886'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'0953699e-6b72-4631-b261-0bb5e107835e'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149850'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'13fba99b-a736-4308-9e23-debb65e7674f'), (b'x-ms-client-request-id', b'0953699e-6b72-4631-b261-0bb5e107835e'), (b'azureml-model-session', b'turbo-0613-dc0dcef4'), (b'Date', b'Thu, 01 Aug 2024 14:14:46 GMT')])
2024-08-01 10:14:46,463 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-08-01 10:14:46,463 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-08-01 10:14:46,465 DEBUG receive_response_body.complete
2024-08-01 10:14:46,465 DEBUG response_closed.started
2024-08-01 10:14:46,466 DEBUG response_closed.complete
2024-08-01 10:14:46,466 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '886', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '0953699e-6b72-4631-b261-0bb5e107835e', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149850', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '13fba99b-a736-4308-9e23-debb65e7674f', 'x-ms-client-request-id': '0953699e-6b72-4631-b261-0bb5e107835e', 'azureml-model-session': 'turbo-0613-dc0dcef4', 'date': 'Thu, 01 Aug 2024 14:14:46 GMT'})
2024-08-01 10:14:46,468 DEBUG request_id: 13fba99b-a736-4308-9e23-debb65e7674f
2024-08-01 10:14:46,479 INFO 127.0.0.1 - - [01/Aug/2024 10:14:46] "POST /chat HTTP/1.1" 200 -
2024-08-01 10:14:46,494 DEBUG Using proactor: IocpProactor
2024-08-01 10:14:46,532 DEBUG Starting new HTTPS connection (1): bsmp24.openai.azure.com:443
2024-08-01 10:14:47,409 DEBUG https://bsmp24.openai.azure.com:443 "POST /openai/deployments/tts/audio/speech?api-version=2024-02-15-preview HTTP/11" 200 None
2024-08-01 10:14:49,678 ERROR Error in text-to-speech: object _io.BytesIO can't be used in 'await' expression
2024-08-01 10:14:49,681 INFO 127.0.0.1 - - [01/Aug/2024 10:14:49] "[35m[1mPOST /text-to-speech HTTP/1.1[0m" 500 -
2024-08-01 10:16:00,600 INFO  * Detected change in 'C:\\Users\\ahmtt\\OneDrive\\Documents\\VS\\BAM_HACKATHON_2024\\app.py', reloading
2024-08-01 10:16:00,800 INFO  * Restarting with stat
2024-08-01 10:16:01,888 WARNING  * Debugger is active!
2024-08-01 10:16:01,892 INFO  * Debugger PIN: 116-389-750
2024-08-01 10:16:12,408 INFO  * Detected change in 'C:\\Users\\ahmtt\\OneDrive\\Documents\\VS\\BAM_HACKATHON_2024\\tts.py', reloading
2024-08-01 10:16:12,535 INFO  * Restarting with stat
2024-08-01 10:16:13,305 WARNING  * Debugger is active!
2024-08-01 10:16:13,309 INFO  * Debugger PIN: 116-389-750
2024-08-01 10:17:44,768 INFO 127.0.0.1 - - [01/Aug/2024 10:17:44] "GET /chat HTTP/1.1" 200 -
2024-08-01 10:17:49,882 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Amigo, a fun and entertaining AI companion. Your job is to make your friend laugh and keep things light-hearted. Be witty and playful, sharing jokes and funny stories. Engage in cheerful banter and always aim to uplift your friend's mood."}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 150, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-08-01 10:17:49,925 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-08-01 10:17:49,926 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-08-01 10:17:49,954 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F520049790>
2024-08-01 10:17:49,955 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F51FDB04D0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-08-01 10:17:49,990 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F520049750>
2024-08-01 10:17:49,991 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-08-01 10:17:49,991 DEBUG send_request_headers.complete
2024-08-01 10:17:49,992 DEBUG send_request_body.started request=<Request [b'POST']>
2024-08-01 10:17:49,992 DEBUG send_request_body.complete
2024-08-01 10:17:49,993 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-08-01 10:17:50,311 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'849'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'8d44b482-30f8-4ad9-90ef-7c3a552e8a7c'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149850'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'54dbb5b9-397b-4236-ab60-0952b64e942a'), (b'x-ms-client-request-id', b'8d44b482-30f8-4ad9-90ef-7c3a552e8a7c'), (b'azureml-model-session', b'turbo-0613-6c073fe4'), (b'Date', b'Thu, 01 Aug 2024 14:17:50 GMT')])
2024-08-01 10:17:50,313 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-08-01 10:17:50,314 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-08-01 10:17:50,315 DEBUG receive_response_body.complete
2024-08-01 10:17:50,315 DEBUG response_closed.started
2024-08-01 10:17:50,316 DEBUG response_closed.complete
2024-08-01 10:17:50,316 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '849', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '8d44b482-30f8-4ad9-90ef-7c3a552e8a7c', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149850', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '54dbb5b9-397b-4236-ab60-0952b64e942a', 'x-ms-client-request-id': '8d44b482-30f8-4ad9-90ef-7c3a552e8a7c', 'azureml-model-session': 'turbo-0613-6c073fe4', 'date': 'Thu, 01 Aug 2024 14:17:50 GMT'})
2024-08-01 10:17:50,317 DEBUG request_id: 54dbb5b9-397b-4236-ab60-0952b64e942a
2024-08-01 10:17:50,320 INFO 127.0.0.1 - - [01/Aug/2024 10:17:50] "POST /chat HTTP/1.1" 200 -
2024-08-01 10:17:50,334 DEBUG Starting new HTTPS connection (1): bsmp24.openai.azure.com:443
2024-08-01 10:17:50,933 DEBUG https://bsmp24.openai.azure.com:443 "POST /openai/deployments/tts/audio/speech?api-version=2024-02-15-preview HTTP/11" 200 None
2024-08-01 10:17:51,405 INFO 127.0.0.1 - - [01/Aug/2024 10:17:51] "POST /text-to-speech HTTP/1.1" 200 -
2024-08-01 10:17:51,448 INFO 127.0.0.1 - - [01/Aug/2024 10:17:51] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2024-08-01 10:19:41,521 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Amigo, a fun and entertaining AI companion. Your job is to make your friend laugh and keep things light-hearted. Be witty and playful, sharing jokes and funny stories. Engage in cheerful banter and always aim to uplift your friend's mood."}, {'role': 'user', 'content': 'how can i make friends'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 150, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-08-01 10:19:41,523 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-08-01 10:19:41,523 DEBUG close.started
2024-08-01 10:19:41,523 DEBUG close.complete
2024-08-01 10:19:41,524 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-08-01 10:19:41,569 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F520083410>
2024-08-01 10:19:41,569 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F51FDB04D0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-08-01 10:19:41,688 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F520083310>
2024-08-01 10:19:41,689 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-08-01 10:19:41,690 DEBUG send_request_headers.complete
2024-08-01 10:19:41,690 DEBUG send_request_body.started request=<Request [b'POST']>
2024-08-01 10:19:41,690 DEBUG send_request_body.complete
2024-08-01 10:19:41,691 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-08-01 10:19:42,977 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'1478'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'37b563e9-7b29-4a9f-ba49-1d4a3d222c14'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149850'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'e3510d66-bf3f-4f92-b422-dcbccac62591'), (b'x-ms-client-request-id', b'37b563e9-7b29-4a9f-ba49-1d4a3d222c14'), (b'azureml-model-session', b'turbo-0613-6c073fe4'), (b'Date', b'Thu, 01 Aug 2024 14:19:43 GMT')])
2024-08-01 10:19:42,978 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-08-01 10:19:42,980 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-08-01 10:19:42,981 DEBUG receive_response_body.complete
2024-08-01 10:19:42,981 DEBUG response_closed.started
2024-08-01 10:19:42,981 DEBUG response_closed.complete
2024-08-01 10:19:42,983 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '1478', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '37b563e9-7b29-4a9f-ba49-1d4a3d222c14', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149850', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'e3510d66-bf3f-4f92-b422-dcbccac62591', 'x-ms-client-request-id': '37b563e9-7b29-4a9f-ba49-1d4a3d222c14', 'azureml-model-session': 'turbo-0613-6c073fe4', 'date': 'Thu, 01 Aug 2024 14:19:43 GMT'})
2024-08-01 10:19:42,984 DEBUG request_id: e3510d66-bf3f-4f92-b422-dcbccac62591
2024-08-01 10:19:42,985 INFO 127.0.0.1 - - [01/Aug/2024 10:19:42] "POST /chat HTTP/1.1" 200 -
2024-08-01 10:19:42,993 DEBUG Starting new HTTPS connection (1): bsmp24.openai.azure.com:443
2024-08-01 10:19:43,962 DEBUG https://bsmp24.openai.azure.com:443 "POST /openai/deployments/tts/audio/speech?api-version=2024-02-15-preview HTTP/11" 200 None
2024-08-01 10:19:50,559 INFO 127.0.0.1 - - [01/Aug/2024 10:19:50] "POST /text-to-speech HTTP/1.1" 200 -
2024-08-01 10:20:55,094 INFO  * Detected change in 'C:\\Users\\ahmtt\\OneDrive\\Documents\\VS\\BAM_HACKATHON_2024\\ai.py', reloading
2024-08-01 10:20:55,212 INFO  * Restarting with stat
2024-08-01 10:20:55,998 WARNING  * Debugger is active!
2024-08-01 10:20:56,001 INFO  * Debugger PIN: 116-389-750
2024-08-01 11:11:49,615 ERROR 127.0.0.1 - - [01/Aug/2024 11:11:49] code 400, message Bad request version ('ZZ\x13\x01\x13\x02\x13\x03+/,0̨̩\x13\x14\x00\x9c\x00\x9d\x00/\x005\x01\x00\x01\x93ZZ\x00\x00\x00\x17\x00\x00\x01\x00\x01\x00\x00')
2024-08-01 11:11:49,623 INFO 127.0.0.1 - - [01/Aug/2024 11:11:49] "[31m[1m\x16\x03\x01\x02\x00\x01\x00\x01\x03\x03\x9e\x0cm\x1cJ;\x0f0\x12\x0bФvk}\x1aӡ\x88 .^a}\x0c\x92\x86\x12;a1J\\6-I\x7f\x197+\x00 ZZ\x13\x01\x13\x02\x13\x03+/,0̨̩\x13\x14\x00\x9c\x00\x9d\x00/\x005\x01\x00\x01\x93ZZ\x00\x00\x00\x17\x00\x00\x01\x00\x01\x00\x00[0m" 400 -
2024-08-01 11:11:49,637 ERROR 127.0.0.1 - - [01/Aug/2024 11:11:49] code 400, message Bad request version ('**\x13\x01\x13\x02\x13\x03+/,0̨̩\x13\x14\x00\x9c\x00\x9d\x00/\x005\x01\x00\x01\x93\x00\x00\x00\x17\x00\x00\x01\x00\x01\x00\x00')
2024-08-01 11:11:49,638 INFO 127.0.0.1 - - [01/Aug/2024 11:11:49] "[31m[1m\x16\x03\x01\x02\x00\x01\x00\x01\x03\x03H~\x13y\x8dL\x96BLT\x02\x85f\x179\x99\x8b\x8e\x9b&\x01 \x9cun\x16,?.8\x9c:\x84 \x04\x01fK\x12м\x1d\x17U\x0c5\x80\x00 **\x13\x01\x13\x02\x13\x03+/,0̨̩\x13\x14\x00\x9c\x00\x9d\x00/\x005\x01\x00\x01\x93\x00\x00\x00\x17\x00\x00\x01\x00\x01\x00\x00[0m" 400 -
2024-08-01 14:02:39,361 INFO 127.0.0.1 - - [01/Aug/2024 14:02:39] "GET /chat HTTP/1.1" 200 -
2024-08-01 14:03:04,321 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Amigo, a fun and entertaining AI companion. Your job is to make your friend laugh and keep things light-hearted. Be witty and playful, sharing jokes and funny stories. Engage in cheerful banter and always aim to uplift your friend's mood."}, {'role': 'user', 'content': 'help me come up with a simple story'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 500, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-08-01 14:03:04,406 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-08-01 14:03:04,408 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-08-01 14:03:04,495 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CBFB2E9AD0>
2024-08-01 14:03:04,497 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001CBFB0504D0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-08-01 14:03:04,574 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CBFB2E9B50>
2024-08-01 14:03:04,576 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-08-01 14:03:04,577 DEBUG send_request_headers.complete
2024-08-01 14:03:04,578 DEBUG send_request_body.started request=<Request [b'POST']>
2024-08-01 14:03:04,578 DEBUG send_request_body.complete
2024-08-01 14:03:04,579 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-08-01 14:03:07,979 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Amigo, a fun and entertaining AI companion. Your job is to make your friend laugh and keep things light-hearted. Be witty and playful, sharing jokes and funny stories. Engage in cheerful banter and always aim to uplift your friend's mood."}, {'role': 'user', 'content': 'help me come up with a simple story'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 500, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-08-01 14:03:07,982 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-08-01 14:03:07,983 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-08-01 14:03:08,024 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CBFB2F6110>
2024-08-01 14:03:08,025 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001CBFB0504D0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-08-01 14:03:08,079 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CBFB2F60D0>
2024-08-01 14:03:08,080 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-08-01 14:03:08,081 DEBUG send_request_headers.complete
2024-08-01 14:03:08,081 DEBUG send_request_body.started request=<Request [b'POST']>
2024-08-01 14:03:08,082 DEBUG send_request_body.complete
2024-08-01 14:03:08,082 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-08-01 14:03:08,829 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2728'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'30b712c9-ea68-43ac-913a-6e3c723b0383'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'171b63fc-56a9-4d9e-aeca-e5fd093045bf'), (b'x-ms-client-request-id', b'30b712c9-ea68-43ac-913a-6e3c723b0383'), (b'azureml-model-session', b'turbo-0613-dbd92aac'), (b'Date', b'Thu, 01 Aug 2024 18:03:08 GMT')])
2024-08-01 14:03:08,831 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-08-01 14:03:08,832 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-08-01 14:03:08,832 DEBUG receive_response_body.complete
2024-08-01 14:03:08,833 DEBUG response_closed.started
2024-08-01 14:03:08,833 DEBUG response_closed.complete
2024-08-01 14:03:08,835 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2728', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '30b712c9-ea68-43ac-913a-6e3c723b0383', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '171b63fc-56a9-4d9e-aeca-e5fd093045bf', 'x-ms-client-request-id': '30b712c9-ea68-43ac-913a-6e3c723b0383', 'azureml-model-session': 'turbo-0613-dbd92aac', 'date': 'Thu, 01 Aug 2024 18:03:08 GMT'})
2024-08-01 14:03:08,836 DEBUG request_id: 171b63fc-56a9-4d9e-aeca-e5fd093045bf
2024-08-01 14:03:08,853 INFO 127.0.0.1 - - [01/Aug/2024 14:03:08] "POST /chat HTTP/1.1" 200 -
2024-08-01 14:03:08,876 DEBUG Starting new HTTPS connection (1): bsmp24.openai.azure.com:443
2024-08-01 14:03:10,721 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'2319'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'1f4c4cec-0a9c-4fc3-a5aa-8ab4c6e98348'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'148'), (b'x-ratelimit-remaining-tokens', b'149000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'9e15e192-1b0e-4168-b826-4962fb2c9f97'), (b'x-ms-client-request-id', b'1f4c4cec-0a9c-4fc3-a5aa-8ab4c6e98348'), (b'azureml-model-session', b'turbo-0613-ee42533b'), (b'Date', b'Thu, 01 Aug 2024 18:03:11 GMT')])
2024-08-01 14:03:10,722 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-08-01 14:03:10,723 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-08-01 14:03:10,723 DEBUG receive_response_body.complete
2024-08-01 14:03:10,723 DEBUG response_closed.started
2024-08-01 14:03:10,724 DEBUG response_closed.complete
2024-08-01 14:03:10,724 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '2319', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '1f4c4cec-0a9c-4fc3-a5aa-8ab4c6e98348', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '148', 'x-ratelimit-remaining-tokens': '149000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '9e15e192-1b0e-4168-b826-4962fb2c9f97', 'x-ms-client-request-id': '1f4c4cec-0a9c-4fc3-a5aa-8ab4c6e98348', 'azureml-model-session': 'turbo-0613-ee42533b', 'date': 'Thu, 01 Aug 2024 18:03:11 GMT'})
2024-08-01 14:03:10,725 DEBUG request_id: 9e15e192-1b0e-4168-b826-4962fb2c9f97
2024-08-01 14:03:10,725 INFO 127.0.0.1 - - [01/Aug/2024 14:03:10] "POST /chat HTTP/1.1" 200 -
2024-08-01 14:03:10,737 DEBUG Starting new HTTPS connection (1): bsmp24.openai.azure.com:443
2024-08-01 14:03:10,817 DEBUG https://bsmp24.openai.azure.com:443 "POST /openai/deployments/tts/audio/speech?api-version=2024-02-15-preview HTTP/11" 200 None
2024-08-01 14:03:10,904 DEBUG https://bsmp24.openai.azure.com:443 "POST /openai/deployments/tts/audio/speech?api-version=2024-02-15-preview HTTP/11" 429 338
2024-08-01 14:03:10,907 ERROR Error in text-to-speech: Text-to-speech conversion failed: 429 - {"error":{"code":"429","message": "Requests to the Audio_Speech Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit."}}
2024-08-01 14:03:10,909 INFO 127.0.0.1 - - [01/Aug/2024 14:03:10] "[35m[1mPOST /text-to-speech HTTP/1.1[0m" 500 -
2024-08-01 14:03:34,935 INFO 127.0.0.1 - - [01/Aug/2024 14:03:34] "POST /text-to-speech HTTP/1.1" 200 -
2024-08-01 14:03:34,977 INFO 127.0.0.1 - - [01/Aug/2024 14:03:34] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2024-08-03 18:31:22,899 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-08-03 18:31:22,900 INFO [33mPress CTRL+C to quit[0m
2024-08-03 18:31:22,902 INFO  * Restarting with stat
2024-08-03 18:31:23,545 WARNING  * Debugger is active!
2024-08-03 18:31:23,548 INFO  * Debugger PIN: 116-389-750
2024-08-03 18:31:36,632 INFO 127.0.0.1 - - [03/Aug/2024 18:31:36] "GET / HTTP/1.1" 200 -
2024-08-03 18:31:36,745 INFO 127.0.0.1 - - [03/Aug/2024 18:31:36] "[36mGET /static/login_styles.css HTTP/1.1[0m" 304 -
2024-08-03 18:31:59,132 INFO 127.0.0.1 - - [03/Aug/2024 18:31:59] "POST /login HTTP/1.1" 200 -
2024-08-03 18:31:59,153 INFO 127.0.0.1 - - [03/Aug/2024 18:31:59] "GET /chat HTTP/1.1" 200 -
2024-08-03 18:31:59,193 INFO 127.0.0.1 - - [03/Aug/2024 18:31:59] "GET /static/styles.css HTTP/1.1" 200 -
2024-08-03 18:32:33,677 INFO 127.0.0.1 - - [03/Aug/2024 18:32:33] "GET /chat HTTP/1.1" 200 -
2024-08-03 18:32:33,713 INFO 127.0.0.1 - - [03/Aug/2024 18:32:33] "GET /static/styles.css HTTP/1.1" 200 -
2024-08-03 18:32:44,895 INFO 127.0.0.1 - - [03/Aug/2024 18:32:44] "GET /chat HTTP/1.1" 200 -
2024-08-03 18:32:44,927 INFO 127.0.0.1 - - [03/Aug/2024 18:32:44] "GET /static/styles.css HTTP/1.1" 200 -
2024-08-03 18:33:25,165 INFO 127.0.0.1 - - [03/Aug/2024 18:33:25] "GET /chat HTTP/1.1" 200 -
2024-08-03 18:33:25,196 INFO 127.0.0.1 - - [03/Aug/2024 18:33:25] "[36mGET /static/styles.css HTTP/1.1[0m" 304 -
2024-08-03 18:34:20,075 INFO 127.0.0.1 - - [03/Aug/2024 18:34:20] "GET /chat HTTP/1.1" 200 -
2024-08-03 18:34:20,105 INFO 127.0.0.1 - - [03/Aug/2024 18:34:20] "GET /static/styles.css HTTP/1.1" 200 -
2024-08-03 18:34:28,919 INFO 127.0.0.1 - - [03/Aug/2024 18:34:28] "GET /chat HTTP/1.1" 200 -
2024-08-03 18:34:28,949 INFO 127.0.0.1 - - [03/Aug/2024 18:34:28] "GET /static/styles.css HTTP/1.1" 200 -
2024-08-03 18:34:47,813 INFO 127.0.0.1 - - [03/Aug/2024 18:34:47] "GET /chat HTTP/1.1" 200 -
2024-08-03 18:34:47,842 INFO 127.0.0.1 - - [03/Aug/2024 18:34:47] "GET /static/styles.css HTTP/1.1" 200 -
2024-08-03 18:34:52,810 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Amigo, a fun and entertaining AI companion. you are the users friend and your job is to make them happy. act like a real friend and engage in fun conversations. Your job is to make your friend laugh and keep things light-hearted. Be witty and playful, sharing jokes and funny stories. keep a pleasant and engaging demeanor.kep your answer consise and understandable.Engage in cheerful banter and always aim to uplift your friend's mood."}, {'role': 'user', 'content': 'HELLO'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 500, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-08-03 18:34:52,842 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-08-03 18:34:52,842 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-08-03 18:34:52,878 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F256642050>
2024-08-03 18:34:52,878 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F2563A04D0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-08-03 18:34:52,915 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F25662F1D0>
2024-08-03 18:34:52,916 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-08-03 18:34:52,917 DEBUG send_request_headers.complete
2024-08-03 18:34:52,917 DEBUG send_request_body.started request=<Request [b'POST']>
2024-08-03 18:34:52,918 DEBUG send_request_body.complete
2024-08-03 18:34:52,918 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-08-03 18:34:53,151 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'890'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'2363247d-4462-4029-96eb-efcc3966597a'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'ee34c330-21a1-4b7c-8ea6-3c1479daced0'), (b'x-ms-client-request-id', b'2363247d-4462-4029-96eb-efcc3966597a'), (b'azureml-model-session', b'turbo-0613-3425e45b'), (b'Date', b'Sat, 03 Aug 2024 22:37:59 GMT')])
2024-08-03 18:34:53,156 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-08-03 18:34:53,157 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-08-03 18:34:53,158 DEBUG receive_response_body.complete
2024-08-03 18:34:53,159 DEBUG response_closed.started
2024-08-03 18:34:53,160 DEBUG response_closed.complete
2024-08-03 18:34:53,161 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '890', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '2363247d-4462-4029-96eb-efcc3966597a', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'ee34c330-21a1-4b7c-8ea6-3c1479daced0', 'x-ms-client-request-id': '2363247d-4462-4029-96eb-efcc3966597a', 'azureml-model-session': 'turbo-0613-3425e45b', 'date': 'Sat, 03 Aug 2024 22:37:59 GMT'})
2024-08-03 18:34:53,163 DEBUG request_id: ee34c330-21a1-4b7c-8ea6-3c1479daced0
2024-08-03 18:34:53,165 INFO 127.0.0.1 - - [03/Aug/2024 18:34:53] "POST /chat HTTP/1.1" 200 -
2024-08-03 18:34:53,182 DEBUG Starting new HTTPS connection (1): bsmp24.openai.azure.com:443
2024-08-03 18:34:53,729 DEBUG https://bsmp24.openai.azure.com:443 "POST /openai/deployments/tts/audio/speech?api-version=2024-02-15-preview HTTP/11" 200 None
2024-08-03 18:34:54,477 INFO 127.0.0.1 - - [03/Aug/2024 18:34:54] "POST /text-to-speech HTTP/1.1" 200 -
2024-08-03 18:35:02,126 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Amigo, a fun and entertaining AI companion. you are the users friend and your job is to make them happy. act like a real friend and engage in fun conversations. Your job is to make your friend laugh and keep things light-hearted. Be witty and playful, sharing jokes and funny stories. keep a pleasant and engaging demeanor.kep your answer consise and understandable.Engage in cheerful banter and always aim to uplift your friend's mood."}, {'role': 'user', 'content': 'HELLO'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 500, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-08-03 18:35:02,128 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-08-03 18:35:02,128 DEBUG close.started
2024-08-03 18:35:02,130 DEBUG close.complete
2024-08-03 18:35:02,130 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-08-03 18:35:02,161 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F256662150>
2024-08-03 18:35:02,161 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F2563A04D0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-08-03 18:35:02,195 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F256662E50>
2024-08-03 18:35:02,195 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-08-03 18:35:02,196 DEBUG send_request_headers.complete
2024-08-03 18:35:02,196 DEBUG send_request_body.started request=<Request [b'POST']>
2024-08-03 18:35:02,198 DEBUG send_request_body.complete
2024-08-03 18:35:02,198 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-08-03 18:35:02,443 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'864'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'1f85a3d2-172c-48ec-bd0a-d6fef1732911'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'148'), (b'x-ratelimit-remaining-tokens', b'149000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'4054fdee-c689-4819-ab01-102c08a95c4f'), (b'x-ms-client-request-id', b'1f85a3d2-172c-48ec-bd0a-d6fef1732911'), (b'azureml-model-session', b'turbo-0613-dc0dcef4'), (b'Date', b'Sat, 03 Aug 2024 22:38:09 GMT')])
2024-08-03 18:35:02,445 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-08-03 18:35:02,446 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-08-03 18:35:02,447 DEBUG receive_response_body.complete
2024-08-03 18:35:02,447 DEBUG response_closed.started
2024-08-03 18:35:02,448 DEBUG response_closed.complete
2024-08-03 18:35:02,448 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '864', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '1f85a3d2-172c-48ec-bd0a-d6fef1732911', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '148', 'x-ratelimit-remaining-tokens': '149000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '4054fdee-c689-4819-ab01-102c08a95c4f', 'x-ms-client-request-id': '1f85a3d2-172c-48ec-bd0a-d6fef1732911', 'azureml-model-session': 'turbo-0613-dc0dcef4', 'date': 'Sat, 03 Aug 2024 22:38:09 GMT'})
2024-08-03 18:35:02,448 DEBUG request_id: 4054fdee-c689-4819-ab01-102c08a95c4f
2024-08-03 18:35:02,450 INFO 127.0.0.1 - - [03/Aug/2024 18:35:02] "POST /chat HTTP/1.1" 200 -
2024-08-03 18:35:02,458 DEBUG Starting new HTTPS connection (1): bsmp24.openai.azure.com:443
2024-08-03 18:35:02,595 DEBUG https://bsmp24.openai.azure.com:443 "POST /openai/deployments/tts/audio/speech?api-version=2024-02-15-preview HTTP/11" 429 338
2024-08-03 18:35:02,596 ERROR Error in text-to-speech: Text-to-speech conversion failed: 429 - {"error":{"code":"429","message": "Requests to the Audio_Speech Operation under Azure OpenAI API version 2024-02-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 51 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit."}}
2024-08-03 18:35:02,598 INFO 127.0.0.1 - - [03/Aug/2024 18:35:02] "[35m[1mPOST /text-to-speech HTTP/1.1[0m" 500 -
2024-08-03 18:38:51,782 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-08-03 18:38:51,783 INFO [33mPress CTRL+C to quit[0m
2024-08-03 18:38:51,783 INFO  * Restarting with stat
2024-08-03 18:38:52,394 WARNING  * Debugger is active!
2024-08-03 18:38:52,397 INFO  * Debugger PIN: 116-389-750
2024-08-03 18:38:55,080 INFO 127.0.0.1 - - [03/Aug/2024 18:38:55] "GET /chat HTTP/1.1" 200 -
2024-08-03 18:38:55,138 INFO 127.0.0.1 - - [03/Aug/2024 18:38:55] "GET /static/styles.css HTTP/1.1" 200 -
2024-08-03 18:39:00,120 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Amigo, a fun and entertaining AI companion. you are the users friend and your job is to make them happy. act like a real friend and engage in fun conversations. Your job is to make your friend laugh and keep things light-hearted. Be witty and playful, sharing jokes and funny stories. keep a pleasant and engaging demeanor.kep your answer consise and understandable.Engage in cheerful banter and always aim to uplift your friend's mood."}, {'role': 'user', 'content': 'HELLO'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 500, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-08-03 18:39:00,143 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-08-03 18:39:00,144 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-08-03 18:39:00,312 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000228F719B050>
2024-08-03 18:39:00,313 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x00000228F6EF04D0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-08-03 18:39:00,376 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000228F719B010>
2024-08-03 18:39:00,377 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-08-03 18:39:00,377 DEBUG send_request_headers.complete
2024-08-03 18:39:00,377 DEBUG send_request_body.started request=<Request [b'POST']>
2024-08-03 18:39:00,378 DEBUG send_request_body.complete
2024-08-03 18:39:00,378 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-08-03 18:39:00,603 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'859'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'684768e3-794d-4dd1-8219-f271ecd115db'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'a70121bb-b88b-4391-adb8-951e21d76a01'), (b'x-ms-client-request-id', b'684768e3-794d-4dd1-8219-f271ecd115db'), (b'azureml-model-session', b'turbo-0613-3425e45b'), (b'Date', b'Sat, 03 Aug 2024 22:42:07 GMT')])
2024-08-03 18:39:00,604 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-08-03 18:39:00,605 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-08-03 18:39:00,605 DEBUG receive_response_body.complete
2024-08-03 18:39:00,605 DEBUG response_closed.started
2024-08-03 18:39:00,605 DEBUG response_closed.complete
2024-08-03 18:39:00,606 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '859', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '684768e3-794d-4dd1-8219-f271ecd115db', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'a70121bb-b88b-4391-adb8-951e21d76a01', 'x-ms-client-request-id': '684768e3-794d-4dd1-8219-f271ecd115db', 'azureml-model-session': 'turbo-0613-3425e45b', 'date': 'Sat, 03 Aug 2024 22:42:07 GMT'})
2024-08-03 18:39:00,606 DEBUG request_id: a70121bb-b88b-4391-adb8-951e21d76a01
2024-08-03 18:39:00,610 INFO 127.0.0.1 - - [03/Aug/2024 18:39:00] "POST /chat HTTP/1.1" 200 -
2024-08-03 18:39:00,620 DEBUG Starting new HTTPS connection (1): bsmp24.openai.azure.com:443
2024-08-03 18:39:01,227 DEBUG https://bsmp24.openai.azure.com:443 "POST /openai/deployments/tts/audio/speech?api-version=2024-02-15-preview HTTP/11" 200 None
2024-08-03 18:39:01,633 INFO 127.0.0.1 - - [03/Aug/2024 18:39:01] "POST /text-to-speech HTTP/1.1" 200 -
2024-08-03 18:39:01,668 INFO 127.0.0.1 - - [03/Aug/2024 18:39:01] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2024-08-04 13:43:49,959 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-08-04 13:43:49,960 INFO [33mPress CTRL+C to quit[0m
2024-08-04 13:43:49,963 INFO  * Restarting with stat
2024-08-04 13:43:50,932 WARNING  * Debugger is active!
2024-08-04 13:43:50,935 INFO  * Debugger PIN: 116-389-750
2024-08-04 13:43:52,986 INFO 127.0.0.1 - - [04/Aug/2024 13:43:52] "GET / HTTP/1.1" 200 -
2024-08-04 13:43:53,106 INFO 127.0.0.1 - - [04/Aug/2024 13:43:53] "[36mGET /static/login_styles.css HTTP/1.1[0m" 304 -
2024-08-06 09:52:46,631 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-08-06 09:52:46,632 INFO [33mPress CTRL+C to quit[0m
2024-08-06 09:52:46,635 INFO  * Restarting with stat
2024-08-06 09:52:48,708 WARNING  * Debugger is active!
2024-08-06 09:52:48,716 INFO  * Debugger PIN: 527-252-607
2024-08-06 09:52:52,562 INFO 127.0.0.1 - - [06/Aug/2024 09:52:52] "GET / HTTP/1.1" 200 -
2024-08-06 09:52:53,036 INFO 127.0.0.1 - - [06/Aug/2024 09:52:53] "[36mGET /static/login_styles.css HTTP/1.1[0m" 304 -
2024-08-06 09:53:03,964 INFO 127.0.0.1 - - [06/Aug/2024 09:53:03] "POST /login HTTP/1.1" 200 -
2024-08-06 09:53:04,024 INFO 127.0.0.1 - - [06/Aug/2024 09:53:04] "GET /chat HTTP/1.1" 200 -
2024-08-06 09:53:04,097 INFO 127.0.0.1 - - [06/Aug/2024 09:53:04] "GET /static/styles.css HTTP/1.1" 200 -
2024-08-06 09:57:58,156 INFO 127.0.0.1 - - [06/Aug/2024 09:57:58] "GET /chat HTTP/1.1" 200 -
2024-08-06 09:57:58,200 INFO 127.0.0.1 - - [06/Aug/2024 09:57:58] "GET /static/styles.css HTTP/1.1" 200 -
2024-08-06 09:58:08,119 INFO 127.0.0.1 - - [06/Aug/2024 09:58:08] "GET /chat HTTP/1.1" 200 -
2024-08-06 09:58:08,163 INFO 127.0.0.1 - - [06/Aug/2024 09:58:08] "GET /static/styles.css HTTP/1.1" 200 -
2024-08-06 09:58:14,285 INFO 127.0.0.1 - - [06/Aug/2024 09:58:14] "[36mGET /static/styles.css HTTP/1.1[0m" 304 -
2024-08-06 09:59:00,010 INFO 127.0.0.1 - - [06/Aug/2024 09:59:00] "GET /chat HTTP/1.1" 200 -
2024-08-06 09:59:00,068 INFO 127.0.0.1 - - [06/Aug/2024 09:59:00] "GET /static/styles.css HTTP/1.1" 200 -
2024-08-06 09:59:06,222 INFO 127.0.0.1 - - [06/Aug/2024 09:59:06] "GET /chat HTTP/1.1" 200 -
2024-08-06 09:59:06,283 INFO 127.0.0.1 - - [06/Aug/2024 09:59:06] "GET /static/styles.css HTTP/1.1" 200 -
2024-08-06 09:59:49,007 INFO 127.0.0.1 - - [06/Aug/2024 09:59:49] "GET /chat HTTP/1.1" 200 -
2024-08-06 09:59:49,057 INFO 127.0.0.1 - - [06/Aug/2024 09:59:49] "GET /static/styles.css HTTP/1.1" 200 -
2024-08-06 09:59:57,219 INFO 127.0.0.1 - - [06/Aug/2024 09:59:57] "GET /chat HTTP/1.1" 200 -
2024-08-06 09:59:57,308 INFO 127.0.0.1 - - [06/Aug/2024 09:59:57] "GET /static/styles.css HTTP/1.1" 200 -
2024-08-06 10:01:09,023 INFO 127.0.0.1 - - [06/Aug/2024 10:01:09] "[36mGET /static/styles.css HTTP/1.1[0m" 304 -
2024-08-06 10:02:07,020 INFO 127.0.0.1 - - [06/Aug/2024 10:02:07] "GET /chat HTTP/1.1" 200 -
2024-08-06 10:02:07,076 INFO 127.0.0.1 - - [06/Aug/2024 10:02:07] "GET /static/styles.css HTTP/1.1" 200 -
2024-08-06 10:02:20,007 INFO 127.0.0.1 - - [06/Aug/2024 10:02:20] "GET /chat HTTP/1.1" 200 -
2024-08-06 10:02:20,086 INFO 127.0.0.1 - - [06/Aug/2024 10:02:20] "GET /static/styles.css HTTP/1.1" 200 -
2024-08-06 10:02:28,909 INFO 127.0.0.1 - - [06/Aug/2024 10:02:28] "GET /chat HTTP/1.1" 200 -
2024-08-06 10:02:28,962 INFO 127.0.0.1 - - [06/Aug/2024 10:02:28] "GET /static/styles.css HTTP/1.1" 200 -
2024-08-06 10:04:17,927 INFO 127.0.0.1 - - [06/Aug/2024 10:04:17] "GET /chat HTTP/1.1" 200 -
2024-08-06 10:04:17,972 INFO 127.0.0.1 - - [06/Aug/2024 10:04:17] "GET /static/styles.css HTTP/1.1" 200 -
2024-08-06 10:04:27,387 INFO 127.0.0.1 - - [06/Aug/2024 10:04:27] "GET /chat HTTP/1.1" 200 -
2024-08-06 10:04:27,434 INFO 127.0.0.1 - - [06/Aug/2024 10:04:27] "GET /static/styles.css HTTP/1.1" 200 -
2024-08-06 10:04:32,748 INFO 127.0.0.1 - - [06/Aug/2024 10:04:32] "GET /chat HTTP/1.1" 200 -
2024-08-06 10:04:32,807 INFO 127.0.0.1 - - [06/Aug/2024 10:04:32] "GET /static/styles.css HTTP/1.1" 200 -
2024-08-06 10:04:53,371 INFO 127.0.0.1 - - [06/Aug/2024 10:04:53] "GET /chat HTTP/1.1" 200 -
2024-08-06 10:04:53,406 INFO 127.0.0.1 - - [06/Aug/2024 10:04:53] "GET /static/styles.css HTTP/1.1" 200 -
2024-08-06 10:05:33,589 INFO 127.0.0.1 - - [06/Aug/2024 10:05:33] "GET /chat HTTP/1.1" 200 -
2024-08-06 10:05:33,624 INFO 127.0.0.1 - - [06/Aug/2024 10:05:33] "GET /static/styles.css HTTP/1.1" 200 -
2024-08-06 10:19:16,385 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Amigo, a fun and entertaining AI companion. you are the users friend and your job is to make them happy. act like a real friend and engage in fun conversations. Your job is to make your friend laugh and keep things light-hearted. Be witty and playful, sharing jokes and funny stories. keep a pleasant and engaging demeanor.kep your answer consise and understandable.Engage in cheerful banter and always aim to uplift your friend's mood."}, {'role': 'user', 'content': "hey what's up"}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 500, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-08-06 10:19:16,447 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-08-06 10:19:16,448 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-08-06 10:19:16,576 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000204E67B9A50>
2024-08-06 10:19:16,577 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x00000204E64F04D0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-08-06 10:19:16,640 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000204E67B9290>
2024-08-06 10:19:16,641 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-08-06 10:19:16,642 DEBUG send_request_headers.complete
2024-08-06 10:19:16,643 DEBUG send_request_body.started request=<Request [b'POST']>
2024-08-06 10:19:16,644 DEBUG send_request_body.complete
2024-08-06 10:19:16,644 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-08-06 10:19:17,285 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'971'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'cdf35a1a-21de-4566-a95a-9a0bdc2740c9'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'dee1349a-6cc1-4c21-9780-35377fdf7238'), (b'x-ms-client-request-id', b'cdf35a1a-21de-4566-a95a-9a0bdc2740c9'), (b'azureml-model-session', b'turbo-0613-bab128d8'), (b'Date', b'Tue, 06 Aug 2024 14:19:15 GMT')])
2024-08-06 10:19:17,288 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-08-06 10:19:17,289 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-08-06 10:19:17,291 DEBUG receive_response_body.complete
2024-08-06 10:19:17,291 DEBUG response_closed.started
2024-08-06 10:19:17,292 DEBUG response_closed.complete
2024-08-06 10:19:17,293 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '971', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'cdf35a1a-21de-4566-a95a-9a0bdc2740c9', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'dee1349a-6cc1-4c21-9780-35377fdf7238', 'x-ms-client-request-id': 'cdf35a1a-21de-4566-a95a-9a0bdc2740c9', 'azureml-model-session': 'turbo-0613-bab128d8', 'date': 'Tue, 06 Aug 2024 14:19:15 GMT'})
2024-08-06 10:19:17,295 DEBUG request_id: dee1349a-6cc1-4c21-9780-35377fdf7238
2024-08-06 10:19:17,303 INFO 127.0.0.1 - - [06/Aug/2024 10:19:17] "POST /chat HTTP/1.1" 200 -
2024-08-06 10:19:17,333 DEBUG Starting new HTTPS connection (1): bsmp24.openai.azure.com:443
2024-08-06 10:19:18,004 DEBUG https://bsmp24.openai.azure.com:443 "POST /openai/deployments/tts/audio/speech?api-version=2024-02-15-preview HTTP/11" 200 None
2024-08-06 10:19:19,721 INFO 127.0.0.1 - - [06/Aug/2024 10:19:19] "POST /text-to-speech HTTP/1.1" 200 -
2024-08-06 10:20:01,856 INFO 127.0.0.1 - - [06/Aug/2024 10:20:01] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2024-08-06 10:20:36,357 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Amigo, a fun and entertaining AI companion. you are the users friend and your job is to make them happy. act like a real friend and engage in fun conversations. Your job is to make your friend laugh and keep things light-hearted. Be witty and playful, sharing jokes and funny stories. keep a pleasant and engaging demeanor.kep your answer consise and understandable.Engage in cheerful banter and always aim to uplift your friend's mood."}, {'role': 'user', 'content': 'i have a busy day, but hanging with friends later. a bit stressed and excited'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 500, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-08-06 10:20:36,359 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-08-06 10:20:36,361 DEBUG close.started
2024-08-06 10:20:36,361 DEBUG close.complete
2024-08-06 10:20:36,362 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-08-06 10:20:36,474 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000204E67A96D0>
2024-08-06 10:20:36,475 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x00000204E64F04D0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-08-06 10:20:36,510 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000204E67AB2D0>
2024-08-06 10:20:36,511 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-08-06 10:20:36,511 DEBUG send_request_headers.complete
2024-08-06 10:20:36,512 DEBUG send_request_body.started request=<Request [b'POST']>
2024-08-06 10:20:36,512 DEBUG send_request_body.complete
2024-08-06 10:20:36,513 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-08-06 10:20:37,253 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'1146'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'aeafdb42-da41-43ea-82f6-2c3b9be24d9a'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'148'), (b'x-ratelimit-remaining-tokens', b'147700'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'4bc32073-3c41-4325-9299-f6788919e85a'), (b'x-ms-client-request-id', b'aeafdb42-da41-43ea-82f6-2c3b9be24d9a'), (b'azureml-model-session', b'turbo-0613-65eb5d6c'), (b'Date', b'Tue, 06 Aug 2024 14:20:36 GMT')])
2024-08-06 10:20:37,256 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-08-06 10:20:37,257 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-08-06 10:20:37,259 DEBUG receive_response_body.complete
2024-08-06 10:20:37,259 DEBUG response_closed.started
2024-08-06 10:20:37,260 DEBUG response_closed.complete
2024-08-06 10:20:37,261 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '1146', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'aeafdb42-da41-43ea-82f6-2c3b9be24d9a', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '148', 'x-ratelimit-remaining-tokens': '147700', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '4bc32073-3c41-4325-9299-f6788919e85a', 'x-ms-client-request-id': 'aeafdb42-da41-43ea-82f6-2c3b9be24d9a', 'azureml-model-session': 'turbo-0613-65eb5d6c', 'date': 'Tue, 06 Aug 2024 14:20:36 GMT'})
2024-08-06 10:20:37,263 DEBUG request_id: 4bc32073-3c41-4325-9299-f6788919e85a
2024-08-06 10:20:37,265 INFO 127.0.0.1 - - [06/Aug/2024 10:20:37] "POST /chat HTTP/1.1" 200 -
2024-08-06 10:20:37,290 DEBUG Starting new HTTPS connection (1): bsmp24.openai.azure.com:443
2024-08-06 10:20:38,284 DEBUG https://bsmp24.openai.azure.com:443 "POST /openai/deployments/tts/audio/speech?api-version=2024-02-15-preview HTTP/11" 200 None
2024-08-06 10:20:41,624 INFO 127.0.0.1 - - [06/Aug/2024 10:20:41] "POST /text-to-speech HTTP/1.1" 200 -
2024-08-06 11:16:43,948 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-08-06 11:16:43,950 INFO [33mPress CTRL+C to quit[0m
2024-08-06 11:16:43,952 INFO  * Restarting with stat
2024-08-06 11:16:44,806 WARNING  * Debugger is active!
2024-08-06 11:16:44,811 INFO  * Debugger PIN: 527-252-607
2024-08-06 11:17:02,241 INFO 127.0.0.1 - - [06/Aug/2024 11:17:02] "GET / HTTP/1.1" 200 -
2024-08-06 11:17:02,353 INFO 127.0.0.1 - - [06/Aug/2024 11:17:02] "[36mGET /static/login_styles.css HTTP/1.1[0m" 304 -
2024-08-06 11:17:11,503 INFO 127.0.0.1 - - [06/Aug/2024 11:17:11] "POST /login HTTP/1.1" 200 -
2024-08-06 11:17:11,564 INFO 127.0.0.1 - - [06/Aug/2024 11:17:11] "GET /chat HTTP/1.1" 200 -
2024-08-06 11:17:11,640 INFO 127.0.0.1 - - [06/Aug/2024 11:17:11] "GET /static/styles.css HTTP/1.1" 200 -
2024-08-06 11:17:11,642 INFO 127.0.0.1 - - [06/Aug/2024 11:17:11] "GET /static/visualizer.js HTTP/1.1" 200 -
2024-08-06 11:26:39,749 INFO 127.0.0.1 - - [06/Aug/2024 11:26:39] "GET /chat HTTP/1.1" 200 -
2024-08-06 11:26:39,817 INFO 127.0.0.1 - - [06/Aug/2024 11:26:39] "GET /static/styles.css HTTP/1.1" 200 -
2024-08-06 11:26:39,844 INFO 127.0.0.1 - - [06/Aug/2024 11:26:39] "[36mGET /static/visualizer.js HTTP/1.1[0m" 304 -
2024-08-06 11:27:06,351 INFO 127.0.0.1 - - [06/Aug/2024 11:27:06] "[36mGET /static/styles.css HTTP/1.1[0m" 304 -
2024-08-06 11:28:48,437 INFO 127.0.0.1 - - [06/Aug/2024 11:28:48] "GET /chat HTTP/1.1" 200 -
2024-08-06 11:28:48,485 INFO 127.0.0.1 - - [06/Aug/2024 11:28:48] "[36mGET /static/styles.css HTTP/1.1[0m" 304 -
2024-08-06 11:28:48,505 INFO 127.0.0.1 - - [06/Aug/2024 11:28:48] "[36mGET /static/visualizer.js HTTP/1.1[0m" 304 -
2024-08-06 11:29:20,433 INFO 127.0.0.1 - - [06/Aug/2024 11:29:20] "GET /chat HTTP/1.1" 200 -
2024-08-06 11:29:20,485 INFO 127.0.0.1 - - [06/Aug/2024 11:29:20] "[36mGET /static/styles.css HTTP/1.1[0m" 304 -
2024-08-06 11:29:20,487 INFO 127.0.0.1 - - [06/Aug/2024 11:29:20] "[36mGET /static/visualizer.js HTTP/1.1[0m" 304 -
2024-08-06 11:31:12,780 INFO 127.0.0.1 - - [06/Aug/2024 11:31:12] "GET /chat HTTP/1.1" 200 -
2024-08-06 11:31:12,863 INFO 127.0.0.1 - - [06/Aug/2024 11:31:12] "[36mGET /static/styles.css HTTP/1.1[0m" 304 -
2024-08-06 11:31:12,865 INFO 127.0.0.1 - - [06/Aug/2024 11:31:12] "[36mGET /static/visualizer.js HTTP/1.1[0m" 304 -
2024-08-06 11:31:37,534 ERROR Error in speech-to-text: [WinError 2] The system cannot find the file specified
2024-08-06 11:31:37,535 INFO 127.0.0.1 - - [06/Aug/2024 11:31:37] "[35m[1mPOST /voice-to-text HTTP/1.1[0m" 500 -
2024-08-06 11:31:37,603 INFO 127.0.0.1 - - [06/Aug/2024 11:31:37] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2024-08-06 11:34:30,105 INFO  * Detected change in 'C:\\Users\\ahmtt\\OneDrive\\Documents\\VS\\BAM_HACKATHON_2024\\secret.py', reloading
2024-08-06 11:34:30,250 INFO  * Restarting with stat
2024-08-06 11:34:31,729 WARNING  * Debugger is active!
2024-08-06 11:34:31,735 INFO  * Debugger PIN: 527-252-607
2024-08-06 12:38:23,702 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-08-06 12:38:23,703 INFO [33mPress CTRL+C to quit[0m
2024-08-06 12:38:23,706 INFO  * Restarting with stat
2024-08-06 12:38:24,402 WARNING  * Debugger is active!
2024-08-06 12:38:24,405 INFO  * Debugger PIN: 527-252-607
2024-08-06 12:38:27,559 INFO 127.0.0.1 - - [06/Aug/2024 12:38:27] "GET / HTTP/1.1" 200 -
2024-08-06 12:38:27,632 INFO 127.0.0.1 - - [06/Aug/2024 12:38:27] "[36mGET /static/login_styles.css HTTP/1.1[0m" 304 -
2024-08-06 12:38:38,534 INFO 127.0.0.1 - - [06/Aug/2024 12:38:38] "POST /login HTTP/1.1" 200 -
2024-08-06 12:38:38,566 INFO 127.0.0.1 - - [06/Aug/2024 12:38:38] "GET /chat HTTP/1.1" 200 -
2024-08-06 12:38:38,617 INFO 127.0.0.1 - - [06/Aug/2024 12:38:38] "GET /static/styles.css HTTP/1.1" 200 -
2024-08-06 12:38:38,618 INFO 127.0.0.1 - - [06/Aug/2024 12:38:38] "GET /static/visualizer.js HTTP/1.1" 200 -
2024-08-06 12:40:51,203 DEBUG Starting new HTTPS connection (1): https:443
2024-08-06 12:40:51,233 INFO 127.0.0.1 - - [06/Aug/2024 12:40:51] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2024-08-06 12:40:53,919 INFO 127.0.0.1 - - [06/Aug/2024 12:40:53] "POST /voice-to-text HTTP/1.1" 200 -
2024-08-06 12:40:58,972 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Amigo, a fun and entertaining AI companion. you are the users friend and your job is to make them happy. act like a real friend and engage in fun conversations. Your job is to make your friend laugh and keep things light-hearted. Be witty and playful, sharing jokes and funny stories. keep a pleasant and engaging demeanor.kep your answer consise and understandable.Engage in cheerful banter and always aim to uplift your friend's mood."}, {'role': 'user', 'content': 'undefined'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 500, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-08-06 12:40:59,021 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-08-06 12:40:59,022 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-08-06 12:40:59,145 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001499EA12F50>
2024-08-06 12:40:59,146 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001499E7EC4D0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-08-06 12:40:59,181 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001499EA125D0>
2024-08-06 12:40:59,182 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-08-06 12:40:59,183 DEBUG send_request_headers.complete
2024-08-06 12:40:59,183 DEBUG send_request_body.started request=<Request [b'POST']>
2024-08-06 12:40:59,184 DEBUG send_request_body.complete
2024-08-06 12:40:59,184 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-08-06 12:41:00,249 DEBUG Request options: {'method': 'post', 'url': '/deployments/gpt-35-turbo/chat/completions', 'headers': {'api-key': '7b7711c1bcd94b4899aaa1d796c4f7ae'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Amigo, a fun and entertaining AI companion. you are the users friend and your job is to make them happy. act like a real friend and engage in fun conversations. Your job is to make your friend laugh and keep things light-hearted. Be witty and playful, sharing jokes and funny stories. keep a pleasant and engaging demeanor.kep your answer consise and understandable.Engage in cheerful banter and always aim to uplift your friend's mood."}, {'role': 'user', 'content': 'undefined'}], 'model': 'gpt-35-turbo', 'frequency_penalty': 0, 'max_tokens': 500, 'presence_penalty': 0, 'temperature': 0.7, 'top_p': 0.95}}
2024-08-06 12:41:00,250 DEBUG Sending HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview
2024-08-06 12:41:00,251 DEBUG connect_tcp.started host='bsmp2023.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-08-06 12:41:00,283 DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001499EA3D090>
2024-08-06 12:41:00,283 DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x000001499E7EC4D0> server_hostname='bsmp2023.openai.azure.com' timeout=5.0
2024-08-06 12:41:00,315 DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001499EA3D050>
2024-08-06 12:41:00,316 DEBUG send_request_headers.started request=<Request [b'POST']>
2024-08-06 12:41:00,316 DEBUG send_request_headers.complete
2024-08-06 12:41:00,317 DEBUG send_request_body.started request=<Request [b'POST']>
2024-08-06 12:41:00,317 DEBUG send_request_body.complete
2024-08-06 12:41:00,318 DEBUG receive_response_headers.started request=<Request [b'POST']>
2024-08-06 12:41:00,589 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'869'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'ad1b2926-2c24-42ef-b797-67f91ef14556'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'148'), (b'x-ratelimit-remaining-tokens', b'149000'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'c3e109db-d101-4eaa-8764-2811a17b57e3'), (b'x-ms-client-request-id', b'ad1b2926-2c24-42ef-b797-67f91ef14556'), (b'azureml-model-session', b'turbo-0613-3e1cc6ec'), (b'Date', b'Tue, 06 Aug 2024 16:40:59 GMT')])
2024-08-06 12:41:00,591 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-08-06 12:41:00,592 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-08-06 12:41:00,592 DEBUG receive_response_body.complete
2024-08-06 12:41:00,593 DEBUG response_closed.started
2024-08-06 12:41:00,593 DEBUG response_closed.complete
2024-08-06 12:41:00,594 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '869', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': 'ad1b2926-2c24-42ef-b797-67f91ef14556', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '148', 'x-ratelimit-remaining-tokens': '149000', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': 'c3e109db-d101-4eaa-8764-2811a17b57e3', 'x-ms-client-request-id': 'ad1b2926-2c24-42ef-b797-67f91ef14556', 'azureml-model-session': 'turbo-0613-3e1cc6ec', 'date': 'Tue, 06 Aug 2024 16:40:59 GMT'})
2024-08-06 12:41:00,594 DEBUG request_id: c3e109db-d101-4eaa-8764-2811a17b57e3
2024-08-06 12:41:00,601 INFO 127.0.0.1 - - [06/Aug/2024 12:41:00] "POST /chat HTTP/1.1" 200 -
2024-08-06 12:41:00,611 DEBUG Starting new HTTPS connection (1): bsmp24.openai.azure.com:443
2024-08-06 12:41:00,937 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Cache-Control', b'no-cache, must-revalidate'), (b'Content-Length', b'1766'), (b'Content-Type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'apim-request-id', b'5567aaef-44bc-4757-a2e3-748d70ce1f72'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-ratelimit-remaining-tokens', b'149500'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'6bf1ea55-44ec-4aaf-bdb6-e216d2a4ca47'), (b'x-ms-client-request-id', b'5567aaef-44bc-4757-a2e3-748d70ce1f72'), (b'azureml-model-session', b'turbo-0613-bab128d8'), (b'Date', b'Tue, 06 Aug 2024 16:40:59 GMT')])
2024-08-06 12:41:00,938 INFO HTTP Request: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2024-08-06 12:41:00,939 DEBUG receive_response_body.started request=<Request [b'POST']>
2024-08-06 12:41:00,939 DEBUG receive_response_body.complete
2024-08-06 12:41:00,940 DEBUG response_closed.started
2024-08-06 12:41:00,940 DEBUG response_closed.complete
2024-08-06 12:41:00,941 DEBUG HTTP Response: POST https://bsmp2023.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-05-01-preview "200 OK" Headers({'cache-control': 'no-cache, must-revalidate', 'content-length': '1766', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '5567aaef-44bc-4757-a2e3-748d70ce1f72', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '149', 'x-ratelimit-remaining-tokens': '149500', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'x-request-id': '6bf1ea55-44ec-4aaf-bdb6-e216d2a4ca47', 'x-ms-client-request-id': '5567aaef-44bc-4757-a2e3-748d70ce1f72', 'azureml-model-session': 'turbo-0613-bab128d8', 'date': 'Tue, 06 Aug 2024 16:40:59 GMT'})
2024-08-06 12:41:00,941 DEBUG request_id: 6bf1ea55-44ec-4aaf-bdb6-e216d2a4ca47
2024-08-06 12:41:00,942 INFO 127.0.0.1 - - [06/Aug/2024 12:41:00] "POST /chat HTTP/1.1" 200 -
2024-08-06 12:41:00,949 DEBUG Starting new HTTPS connection (1): bsmp24.openai.azure.com:443
2024-08-06 12:41:01,258 DEBUG https://bsmp24.openai.azure.com:443 "POST /openai/deployments/tts/audio/speech?api-version=2024-02-15-preview HTTP/11" 200 None
2024-08-06 12:41:01,827 DEBUG https://bsmp24.openai.azure.com:443 "POST /openai/deployments/tts/audio/speech?api-version=2024-02-15-preview HTTP/11" 200 None
2024-08-06 12:41:01,842 INFO 127.0.0.1 - - [06/Aug/2024 12:41:01] "POST /text-to-speech HTTP/1.1" 200 -
2024-08-06 12:41:10,464 INFO 127.0.0.1 - - [06/Aug/2024 12:41:10] "POST /text-to-speech HTTP/1.1" 200 -
